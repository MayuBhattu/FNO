{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MayuBhattu/FNO/blob/main/FNO_Long_Range_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pi1m7BpzBWXy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JPlm05TXLU0-",
        "outputId": "7c98b96f-ad6b-431f-c540-0f937ac7e222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PATHS = {\n",
        "    \"MAYURESH\": {\n",
        "        \"data_path\": \"/content/drive/MyDrive/CS229 Project FNO/final_generation/simulation_results_final/\",\n",
        "         \"output_path\": \"/content/drive/MyDrive/CS229 Project FNO/tensors long range/\",\n",
        "    },\n",
        "    \"SHAUNAK\": {\n",
        "        \"data_path\": \"/content/drive/MyDrive/CS229 Project FNO/final_generation/simulation_results_final/\",\n",
        "        \"output_path\": \"/content/drive/MyDrive/CS229 Project FNO/tensors new/\",\n",
        "    }\n",
        "    }"
      ],
      "metadata": {
        "id": "bwSjoCfaMjDj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = \"MAYURESH\"\n",
        "data_path = USER_PATHS[user][\"data_path\"]\n",
        "output_path = USER_PATHS[user][\"output_path\"]"
      ],
      "metadata": {
        "id": "X56M6M2NOxD1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "static_files = sorted(glob.glob(data_path + \"static_data_sim*.csv\"))\n",
        "time_series_files = sorted(glob.glob(data_path + \"time_series_data_sim*.csv\"))\n",
        "\n",
        "print(len(static_files))\n",
        "print(len(time_series_files))\n",
        "\n",
        "assert(len(static_files) == len(time_series_files))\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "len(static_files)"
      ],
      "metadata": {
        "id": "1Pec_KA-Bgap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ac0746-95b0-445e-8ed6-23acdbe94bbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_points = 21  # Grid resolution\n",
        "num_steps = 200  # Time steps\n",
        "T_context = 10  # Number of past frames used as input\n",
        "input_channels = 6+T_context  # x, y, IC, Dirichlet mask, Neumann mask, BC values, last 3 frames"
      ],
      "metadata": {
        "id": "uQ7Xg9RtHeeY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (static_file, time_series_file) in enumerate(\n",
        "    tqdm(zip(static_files, time_series_files), total=len(static_files), desc=\"Generating Tensors\", dynamic_ncols=True)\n",
        "):\n",
        "    static_df = pd.read_csv(static_file)\n",
        "    time_series_df = pd.read_csv(time_series_file)\n",
        "\n",
        "    ic = static_df[\"Initial_Condition\"].values.reshape(num_points, num_points)\n",
        "    dirichlet_mask = static_df[\"Dirichlet_Mask\"].values.reshape(num_points, num_points)\n",
        "    neumann_mask = static_df[\"Neumann_Mask\"].values.reshape(num_points, num_points)\n",
        "    bc_values = static_df[\"BC_Value\"].values.reshape(num_points, num_points)\n",
        "\n",
        "    u_solution = time_series_df[\"u(x,y,t)\"].values.reshape(num_steps, num_points, num_points)\n",
        "    # u_solution = u_solution[:, :-1, :-1]  # Reshape into 20x20 (not needed anymore)\n",
        "\n",
        "    x_grid, y_grid = np.meshgrid(np.linspace(0, 1, num_points), np.linspace(0, 1, num_points))\n",
        "\n",
        "    local_X, local_Y = [], []\n",
        "\n",
        "    input_tensor = np.stack([\n",
        "        x_grid, y_grid, ic,\n",
        "        dirichlet_mask, neumann_mask, bc_values,\n",
        "        *u_solution[:T_context]\n",
        "    ], axis=0)  # Shape: (9, 20, 20)\n",
        "\n",
        "    output_tensor = u_solution[T_context:]  # Shape: (20, 20)\n",
        "    local_X.append(input_tensor)\n",
        "    local_Y.append(output_tensor)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor = torch.tensor(np.array(local_X), dtype=torch.float32)  # (steps, 9, 20, 20)\n",
        "    Y_tensor = torch.tensor(np.array(local_Y), dtype=torch.float32)  # (steps, 20, 20)\n",
        "\n",
        "    # ================= SAVE TO .PT =================\n",
        "    torch.save(X_tensor, os.path.join(output_path, f\"X_sim{i}.pt\"))\n",
        "    torch.save(Y_tensor, os.path.join(output_path, f\"Y_sim{i}.pt\"))\n",
        "\n",
        "print(\"âœ… All simulations saved as .pt files!\")"
      ],
      "metadata": {
        "id": "5sRiu_7QvuPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "57c5d704-9c71-4df3-f9d5-364433a0f6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Tensors:   1%|          | 10/1000 [02:13<3:39:56, 13.33s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1856d39a03bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[1;32m      4\u001b[0m     \u001b[0mstatic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtime_series_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_series_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatic_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Initial_Condition\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "seed = 42  # Chosen seed for reproducibility\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Apply CUDA-specific seed only if using GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n"
      ],
      "metadata": {
        "id": "5XaONIB8yrA-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = output_path\n",
        "\n",
        "x_files = sorted(glob.glob(train_path + \"X_sim*.pt\"))\n",
        "y_files = sorted(glob.glob(train_path + \"Y_sim*.pt\"))\n",
        "\n",
        "# Ensure both lists are of the same length\n",
        "assert len(x_files) == len(y_files), \"Mismatch in number of X and Y files!\"\n",
        "\n",
        "# Zip, shuffle, and unzip\n",
        "file_pairs = list(zip(x_files, y_files))\n",
        "random.shuffle(file_pairs)  # Shuffle the pairs together\n",
        "x_files, y_files = zip(*file_pairs)  # Unzip back into separate lists\n",
        "\n",
        "# Convert back to lists (since zip() returns tuples)\n",
        "x_files = list(x_files)\n",
        "y_files = list(y_files)\n",
        "\n",
        "n_train = 600\n",
        "n_test = 200\n",
        "n_valid = 1000 - n_train - n_test\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# def load_tensor(file):\n",
        "#     return torch.load(file, weights_only=False)\n",
        "\n",
        "# # Use threading to load multiple files in parallel\n",
        "# with ThreadPoolExecutor() as executor:\n",
        "#     X_train_tensors = list(executor.map(load_tensor, x_files[:n_train]))\n",
        "\n",
        "# X_train = torch.cat(X_train_tensors, dim=0)\n",
        "X_train = torch.cat([torch.load(f, weights_only=False) for f in x_files[:n_train]], dim=0)\n",
        "Y_train = torch.cat([torch.load(f, weights_only=False) for f in y_files[:n_train]], dim=0)\n",
        "\n",
        "X_val = torch.cat([torch.load(f, weights_only=False) for f in x_files[n_train:n_train+n_valid]], dim=0)\n",
        "Y_val = torch.cat([torch.load(f, weights_only=False) for f in y_files[n_train:n_train+n_valid]], dim=0)\n",
        "\n",
        "X_test = torch.cat([torch.load(f, weights_only=False) for f in x_files[n_train+n_valid:]], dim=0)\n",
        "Y_test = torch.cat([torch.load(f, weights_only=False) for f in y_files[n_train+n_valid:]], dim=0)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_dataset = TensorDataset(X_val, Y_val)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Loaded X_train: {X_train.shape}, Y_train: {Y_train.shape}\")\n",
        "# No. of simulations * (Examples per simulation)  = 600 * 196 = 117,600"
      ],
      "metadata": {
        "id": "p081Amf6CEKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995b3cec-f845-4bf6-c39f-25fb28156a4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded X_train: torch.Size([600, 16, 21, 21]), Y_train: torch.Size([600, 190, 21, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SpectralConv2d refers to the implementation of one Fourier layer\n",
        "class SpectralConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ft = torch.fft.rfftn(x, dim=[-2,-1])\n",
        "        out_ft = torch.zeros_like(x_ft)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights)\n",
        "        x = torch.fft.irfftn(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "# SimpleBlock2d contains our entire architecture\n",
        "class SimpleBlock2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(SimpleBlock2d, self).__init__()\n",
        "        # P-layer: convert to higher dimensional \"width\" channel space\n",
        "        self.fc0 = nn.Linear(input_channels, width)\n",
        "        self.fc_res = nn.Linear(T_context, num_steps - T_context)\n",
        "\n",
        "        # Fourier Layers\n",
        "        self.conv0 = SpectralConv2d(width, width, modes1, modes2)\n",
        "        self.conv1 = SpectralConv2d(width, width, modes1, modes2)\n",
        "        self.conv2 = SpectralConv2d(width, width, modes1, modes2)\n",
        "\n",
        "        # Local linear transforms W to be applied in parallel to Fourier Layers\n",
        "        self.w0 = nn.Conv1d(width, width, 1)\n",
        "        self.w1 = nn.Conv1d(width, width, 1)\n",
        "        self.w2 = nn.Conv1d(width, width, 1)\n",
        "\n",
        "        # Q-layer(/s): NN to project channel space back to a target dimension\n",
        "        # Q) Why 128? Why not 1 directly?\n",
        "        self.fc1 = nn.Linear(width, 128)\n",
        "        self.fc2 = nn.Linear(128, num_steps- T_context)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize, _, size_x, size_y = x.shape\n",
        "        # P-layer\n",
        "        #x_res = self.fc_res(x.permute(0, 2, 3, 1)[..., -T_context:]).squeeze()\n",
        "\n",
        "        x = self.fc0(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # First Fourier layer\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x.view(batchsize, -1, size_x * size_y)).view(batchsize, -1, size_x, size_y)\n",
        "        x =  F.relu(x1 + x2)\n",
        "\n",
        "        # Second Fourier layer\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x.view(batchsize, -1, size_x * size_y)).view(batchsize, -1, size_x, size_y)\n",
        "        x = F.relu(x1 + x2)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x.view(batchsize, -1, size_x * size_y)).view(batchsize, -1, size_x, size_y)\n",
        "        x = F.relu(x1 + x2)\n",
        "\n",
        "        # Q-layer(/s)\n",
        "        x = self.fc2(F.relu(self.fc1(x.permute(0, 2, 3, 1)))).permute(0, 3, 1, 2)\n",
        "        return x #+ x_res\n",
        "\n",
        "# Wrapper function for implementing our architecture\n",
        "class FNO(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO, self).__init__()\n",
        "        self.fno = SimpleBlock2d(modes1, modes2, width)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fno(x)"
      ],
      "metadata": {
        "id": "wDWmKHfTBnGu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(outputs, targets, inputs, lambda_d=0.1, lambda_n=0.1):\n",
        "    \"\"\"\n",
        "    Custom loss function incorporating Dirichlet and Neumann boundary conditions.\n",
        "\n",
        "    Parameters:\n",
        "    - outputs: Model predictions (batch_size, timesteps, grid_x, grid_y)\n",
        "    - targets: Ground truth (batch_size, timesteps, grid_x, grid_y)\n",
        "    - inputs: Input tensor (contains boundary masks and values)\n",
        "    - lambda_d: Weight for Dirichlet loss\n",
        "    - lambda_n: Weight for Neumann loss\n",
        "\n",
        "    Returns:\n",
        "    - Total loss combining MSE, Dirichlet, and Neumann constraints.\n",
        "    \"\"\"\n",
        "    mse_loss = F.mse_loss(outputs, targets)\n",
        "\n",
        "    # Extract boundary information from inputs\n",
        "    dirichlet_mask = inputs[:, 3, :, :].unsqueeze(1)  # (batch_size, 1, grid_x, grid_y)\n",
        "    neumann_mask = inputs[:, 4, :, :].unsqueeze(1)  # (batch_size, 1, grid_x, grid_y)\n",
        "    bc_values = inputs[:, 5, :, :].unsqueeze(1)  # (batch_size, 1, grid_x, grid_y) - Stores flux g(x,y)\n",
        "\n",
        "    # Expand masks to match outputs shape\n",
        "    dirichlet_mask = dirichlet_mask.expand(-1, outputs.shape[1], -1, -1)\n",
        "    bc_values = bc_values.expand(-1, outputs.shape[1], -1, -1)\n",
        "\n",
        "    # Dirichlet Loss: Enforce output values at Dirichlet points\n",
        "    dirichlet_loss = F.mse_loss(outputs * dirichlet_mask, bc_values * dirichlet_mask)\n",
        "\n",
        "    # Neumann Loss: Compute full spatial gradients\n",
        "    dx = 1.0 / outputs.shape[2]  # Assuming uniform grid\n",
        "    dy = 1.0 / outputs.shape[3]\n",
        "\n",
        "    # Compute finite difference gradients (centered differences where possible)\n",
        "    grad_x = torch.zeros_like(outputs)\n",
        "    grad_y = torch.zeros_like(outputs)\n",
        "\n",
        "    # Forward difference for left boundary\n",
        "    grad_x[:, :, 0, :] = (outputs[:, :, 0, :] - outputs[:, :, 1, :]) / dx\n",
        "    # Backward difference for right boundary\n",
        "    grad_x[:, :, -1, :] = (outputs[:, :, -1, :] - outputs[:, :, -2, :]) / dx\n",
        "\n",
        "    # Forward difference for bottom boundary\n",
        "    grad_y[:, :, :, 0] = (outputs[:, :, :, 0] - outputs[:, :, :, 1]) / dy\n",
        "    # Backward difference for top boundary\n",
        "    grad_y[:, :, :, -1] = (outputs[:, :, :, -1] - outputs[:, :, :, -2]) / dy\n",
        "\n",
        "    # Compute total Neumann loss at boundary points\n",
        "    grad_norm = grad_x + grad_y  # Combine all gradient components\n",
        "    neumann_loss = F.mse_loss(neumann_mask * grad_norm, neumann_mask * bc_values)\n",
        "\n",
        "    # Total Loss\n",
        "    total_loss = mse_loss + lambda_d * dirichlet_loss + lambda_n * neumann_loss\n",
        "\n",
        "    return total_loss\n"
      ],
      "metadata": {
        "id": "T7cRAjmyIjDp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modes, width = 11, 20 # modes > 11 don't work - maybe related to grid resolution being 20x20\n",
        "num_epochs = 2000\n",
        "\n",
        "model = FNO(modes, modes, width).to(\"cuda\")\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_loss_history = []\n",
        "valid_loss_history = []\n",
        "\n",
        "train_relative_loss_history = []\n",
        "valid_relative_loss_history = []\n",
        "\n",
        "window_size = 5  # Number of epochs for moving average\n",
        "loss_threshold = 0.25  # Stopping threshold for moving average loss\n",
        "val_loss_window = []  # Track last `window_size` validation losses\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_relative_loss = 0  # Initialize relative loss sum\n",
        "\n",
        "    # === Training Step ===\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        #loss = criterion(outputs, targets)\n",
        "        loss = custom_loss(outputs, targets, inputs, lambda_d=0.1, lambda_n=0.1)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Compute relative loss\n",
        "        relative_loss = torch.mean(torch.abs(outputs - targets) / (torch.abs(targets) + 1e-8))  # Avoid division by zero\n",
        "        total_relative_loss += relative_loss.item()\n",
        "\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "    epoch_loss_rel = total_relative_loss / len(train_loader)  # Average relative loss over batches\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_relative_loss_history.append(epoch_loss_rel)  # Store relative loss\n",
        "\n",
        "    # === Validation Step ===\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    relative_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_targets in valid_loader:\n",
        "            val_inputs, val_targets = val_inputs.to(\"cuda\"), val_targets.to(\"cuda\")\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss = criterion(val_outputs, val_targets)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            # Compute relative loss\n",
        "            relative_loss = torch.mean(torch.abs(val_outputs - val_targets) / (torch.abs(val_targets) + 1e-8))  # Avoid division by zero\n",
        "            relative_val_loss += relative_loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(valid_loader)\n",
        "    avg_val_loss_rel = relative_val_loss / len(valid_loader)\n",
        "    valid_loss_history.append(avg_val_loss) # Store for plotting\n",
        "    valid_relative_loss_history.append(avg_val_loss_rel)\n",
        "\n",
        "    val_loss_window.append(avg_val_loss_rel)\n",
        "    if len(val_loss_window) > window_size:\n",
        "        val_loss_window.pop(0)  # Keep only last `window_size` losses\n",
        "\n",
        "    # Compute moving average loss\n",
        "    moving_avg_loss = sum(val_loss_window) / len(val_loss_window)\n",
        "\n",
        "    print(f\"Moving Avg Val Loss: {moving_avg_loss:.6f}\")\n",
        "\n",
        "    # Stop training if moving average validation loss is below threshold\n",
        "    if moving_avg_loss < loss_threshold:\n",
        "        print(f\"Stopping early: Moving Avg Val Loss ({moving_avg_loss:.6f}) < Threshold ({loss_threshold})\")\n",
        "        break\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Rel Train Loss: {epoch_loss_rel*100:.2f}%, Rel Val Loss: {avg_val_loss_rel*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDkoQTqcioES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a294638-94bb-4911-c060-794d3caa8dc9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 334/2000, Train Loss: 0.001628, Val Loss: 0.055004\n",
            "Epoch 334/2000, Rel Train Loss: 74.41%, Rel Val Loss: 90.13%\n",
            "Moving Avg Val Loss: 0.971851\n",
            "Epoch 335/2000, Train Loss: 0.001834, Val Loss: 0.063739\n",
            "Epoch 335/2000, Rel Train Loss: 87.20%, Rel Val Loss: 114.02%\n",
            "Moving Avg Val Loss: 0.957622\n",
            "Epoch 336/2000, Train Loss: 0.003681, Val Loss: 0.054997\n",
            "Epoch 336/2000, Rel Train Loss: 111.27%, Rel Val Loss: 88.99%\n",
            "Moving Avg Val Loss: 0.952977\n",
            "Epoch 337/2000, Train Loss: 0.002664, Val Loss: 0.057600\n",
            "Epoch 337/2000, Rel Train Loss: 99.52%, Rel Val Loss: 90.94%\n",
            "Moving Avg Val Loss: 1.018041\n",
            "Epoch 338/2000, Train Loss: 0.002699, Val Loss: 0.058185\n",
            "Epoch 338/2000, Rel Train Loss: 129.28%, Rel Val Loss: 124.95%\n",
            "Moving Avg Val Loss: 1.010547\n",
            "Epoch 339/2000, Train Loss: 0.003940, Val Loss: 0.059669\n",
            "Epoch 339/2000, Rel Train Loss: 90.99%, Rel Val Loss: 86.38%\n",
            "Moving Avg Val Loss: 0.973018\n",
            "Epoch 340/2000, Train Loss: 0.002453, Val Loss: 0.056154\n",
            "Epoch 340/2000, Rel Train Loss: 93.61%, Rel Val Loss: 95.25%\n",
            "Moving Avg Val Loss: 1.075089\n",
            "Epoch 341/2000, Train Loss: 0.003696, Val Loss: 0.059683\n",
            "Epoch 341/2000, Rel Train Loss: 92.17%, Rel Val Loss: 140.03%\n",
            "Moving Avg Val Loss: 1.065675\n",
            "Epoch 342/2000, Train Loss: 0.002051, Val Loss: 0.057102\n",
            "Epoch 342/2000, Rel Train Loss: 90.74%, Rel Val Loss: 86.23%\n",
            "Moving Avg Val Loss: 0.990394\n",
            "Epoch 343/2000, Train Loss: 0.001562, Val Loss: 0.059028\n",
            "Epoch 343/2000, Rel Train Loss: 68.64%, Rel Val Loss: 87.31%\n",
            "Moving Avg Val Loss: 1.004822\n",
            "Epoch 344/2000, Train Loss: 0.003053, Val Loss: 0.056932\n",
            "Epoch 344/2000, Rel Train Loss: 71.68%, Rel Val Loss: 93.59%\n",
            "Moving Avg Val Loss: 1.028835\n",
            "Epoch 345/2000, Train Loss: 0.001910, Val Loss: 0.058407\n",
            "Epoch 345/2000, Rel Train Loss: 76.76%, Rel Val Loss: 107.26%\n",
            "Moving Avg Val Loss: 0.933177\n",
            "Epoch 346/2000, Train Loss: 0.001962, Val Loss: 0.054789\n",
            "Epoch 346/2000, Rel Train Loss: 71.22%, Rel Val Loss: 92.20%\n",
            "Moving Avg Val Loss: 0.996197\n",
            "Epoch 347/2000, Train Loss: 0.002614, Val Loss: 0.059627\n",
            "Epoch 347/2000, Rel Train Loss: 69.76%, Rel Val Loss: 117.74%\n",
            "Moving Avg Val Loss: 1.069468\n",
            "Epoch 348/2000, Train Loss: 0.003644, Val Loss: 0.057097\n",
            "Epoch 348/2000, Rel Train Loss: 112.43%, Rel Val Loss: 123.94%\n",
            "Moving Avg Val Loss: 1.092878\n",
            "Epoch 349/2000, Train Loss: 0.002105, Val Loss: 0.054856\n",
            "Epoch 349/2000, Rel Train Loss: 106.28%, Rel Val Loss: 105.30%\n",
            "Moving Avg Val Loss: 1.056269\n",
            "Epoch 350/2000, Train Loss: 0.001381, Val Loss: 0.055868\n",
            "Epoch 350/2000, Rel Train Loss: 74.10%, Rel Val Loss: 88.95%\n",
            "Moving Avg Val Loss: 1.056182\n",
            "Epoch 351/2000, Train Loss: 0.001462, Val Loss: 0.056824\n",
            "Epoch 351/2000, Rel Train Loss: 68.97%, Rel Val Loss: 92.15%\n",
            "Moving Avg Val Loss: 0.997073\n",
            "Epoch 352/2000, Train Loss: 0.002640, Val Loss: 0.055116\n",
            "Epoch 352/2000, Rel Train Loss: 72.62%, Rel Val Loss: 88.19%\n",
            "Moving Avg Val Loss: 1.006771\n",
            "Epoch 353/2000, Train Loss: 0.002668, Val Loss: 0.064359\n",
            "Epoch 353/2000, Rel Train Loss: 82.23%, Rel Val Loss: 128.79%\n",
            "Moving Avg Val Loss: 1.025262\n",
            "Epoch 354/2000, Train Loss: 0.004530, Val Loss: 0.059440\n",
            "Epoch 354/2000, Rel Train Loss: 88.33%, Rel Val Loss: 114.55%\n",
            "Moving Avg Val Loss: 1.014621\n",
            "Epoch 355/2000, Train Loss: 0.003438, Val Loss: 0.055505\n",
            "Epoch 355/2000, Rel Train Loss: 85.49%, Rel Val Loss: 83.63%\n",
            "Moving Avg Val Loss: 1.051651\n",
            "Epoch 356/2000, Train Loss: 0.002226, Val Loss: 0.056644\n",
            "Epoch 356/2000, Rel Train Loss: 70.79%, Rel Val Loss: 110.67%\n",
            "Moving Avg Val Loss: 1.050346\n",
            "Epoch 357/2000, Train Loss: 0.001581, Val Loss: 0.054660\n",
            "Epoch 357/2000, Rel Train Loss: 74.60%, Rel Val Loss: 87.54%\n",
            "Moving Avg Val Loss: 0.964572\n",
            "Epoch 358/2000, Train Loss: 0.002043, Val Loss: 0.060671\n",
            "Epoch 358/2000, Rel Train Loss: 73.32%, Rel Val Loss: 85.90%\n",
            "Moving Avg Val Loss: 1.049226\n",
            "Epoch 359/2000, Train Loss: 0.003744, Val Loss: 0.065813\n",
            "Epoch 359/2000, Rel Train Loss: 102.56%, Rel Val Loss: 156.87%\n",
            "Moving Avg Val Loss: 1.115280\n",
            "Epoch 360/2000, Train Loss: 0.006252, Val Loss: 0.065358\n",
            "Epoch 360/2000, Rel Train Loss: 150.67%, Rel Val Loss: 116.66%\n",
            "Moving Avg Val Loss: 1.191726\n",
            "Epoch 361/2000, Train Loss: 0.006059, Val Loss: 0.062978\n",
            "Epoch 361/2000, Rel Train Loss: 114.53%, Rel Val Loss: 148.89%\n",
            "Moving Avg Val Loss: 1.209304\n",
            "Epoch 362/2000, Train Loss: 0.004735, Val Loss: 0.055233\n",
            "Epoch 362/2000, Rel Train Loss: 119.14%, Rel Val Loss: 96.33%\n",
            "Moving Avg Val Loss: 1.224669\n",
            "Epoch 363/2000, Train Loss: 0.006081, Val Loss: 0.066466\n",
            "Epoch 363/2000, Rel Train Loss: 82.20%, Rel Val Loss: 93.59%\n",
            "Moving Avg Val Loss: 1.091560\n",
            "Epoch 364/2000, Train Loss: 0.004423, Val Loss: 0.055725\n",
            "Epoch 364/2000, Rel Train Loss: 94.53%, Rel Val Loss: 90.32%\n",
            "Moving Avg Val Loss: 1.021819\n",
            "Epoch 365/2000, Train Loss: 0.002285, Val Loss: 0.057563\n",
            "Epoch 365/2000, Rel Train Loss: 88.87%, Rel Val Loss: 81.79%\n",
            "Moving Avg Val Loss: 0.918681\n",
            "Epoch 366/2000, Train Loss: 0.002053, Val Loss: 0.062526\n",
            "Epoch 366/2000, Rel Train Loss: 77.10%, Rel Val Loss: 97.32%\n",
            "Moving Avg Val Loss: 0.912427\n",
            "Epoch 367/2000, Train Loss: 0.002630, Val Loss: 0.059099\n",
            "Epoch 367/2000, Rel Train Loss: 79.69%, Rel Val Loss: 93.20%\n",
            "Moving Avg Val Loss: 0.903705\n",
            "Epoch 368/2000, Train Loss: 0.002462, Val Loss: 0.058333\n",
            "Epoch 368/2000, Rel Train Loss: 86.48%, Rel Val Loss: 89.23%\n",
            "Moving Avg Val Loss: 0.907627\n",
            "Epoch 369/2000, Train Loss: 0.002142, Val Loss: 0.061741\n",
            "Epoch 369/2000, Rel Train Loss: 76.02%, Rel Val Loss: 92.28%\n",
            "Moving Avg Val Loss: 0.988012\n",
            "Epoch 370/2000, Train Loss: 0.003439, Val Loss: 0.058093\n",
            "Epoch 370/2000, Rel Train Loss: 73.90%, Rel Val Loss: 121.98%\n",
            "Moving Avg Val Loss: 1.114123\n",
            "Epoch 371/2000, Train Loss: 0.002812, Val Loss: 0.058348\n",
            "Epoch 371/2000, Rel Train Loss: 120.18%, Rel Val Loss: 160.38%\n",
            "Moving Avg Val Loss: 1.157677\n",
            "Epoch 372/2000, Train Loss: 0.003047, Val Loss: 0.064639\n",
            "Epoch 372/2000, Rel Train Loss: 97.83%, Rel Val Loss: 114.98%\n",
            "Moving Avg Val Loss: 1.275801\n",
            "Epoch 373/2000, Train Loss: 0.005636, Val Loss: 0.068839\n",
            "Epoch 373/2000, Rel Train Loss: 118.70%, Rel Val Loss: 148.29%\n",
            "Moving Avg Val Loss: 1.315414\n",
            "Epoch 374/2000, Train Loss: 0.012483, Val Loss: 0.058024\n",
            "Epoch 374/2000, Rel Train Loss: 154.96%, Rel Val Loss: 112.08%\n",
            "Moving Avg Val Loss: 1.254183\n",
            "Epoch 375/2000, Train Loss: 0.006177, Val Loss: 0.067289\n",
            "Epoch 375/2000, Rel Train Loss: 151.10%, Rel Val Loss: 91.37%\n",
            "Moving Avg Val Loss: 1.127394\n",
            "Epoch 376/2000, Train Loss: 0.005174, Val Loss: 0.058944\n",
            "Epoch 376/2000, Rel Train Loss: 110.43%, Rel Val Loss: 96.98%\n",
            "Moving Avg Val Loss: 1.118746\n",
            "Epoch 377/2000, Train Loss: 0.003507, Val Loss: 0.059915\n",
            "Epoch 377/2000, Rel Train Loss: 75.53%, Rel Val Loss: 110.65%\n",
            "Moving Avg Val Loss: 1.000539\n",
            "Epoch 378/2000, Train Loss: 0.004505, Val Loss: 0.056100\n",
            "Epoch 378/2000, Rel Train Loss: 95.35%, Rel Val Loss: 89.18%\n",
            "Moving Avg Val Loss: 0.960204\n",
            "Epoch 379/2000, Train Loss: 0.002468, Val Loss: 0.060183\n",
            "Epoch 379/2000, Rel Train Loss: 98.68%, Rel Val Loss: 91.92%\n",
            "Moving Avg Val Loss: 1.083401\n",
            "Epoch 380/2000, Train Loss: 0.005310, Val Loss: 0.072024\n",
            "Epoch 380/2000, Rel Train Loss: 114.16%, Rel Val Loss: 152.96%\n",
            "Moving Avg Val Loss: 1.612501\n",
            "Epoch 381/2000, Train Loss: 0.010800, Val Loss: 0.068876\n",
            "Epoch 381/2000, Rel Train Loss: 177.23%, Rel Val Loss: 361.53%\n",
            "Moving Avg Val Loss: 1.566354\n",
            "Epoch 382/2000, Train Loss: 0.009635, Val Loss: 0.059966\n",
            "Epoch 382/2000, Rel Train Loss: 254.30%, Rel Val Loss: 87.58%\n",
            "Moving Avg Val Loss: 1.611747\n",
            "Epoch 383/2000, Train Loss: 0.005137, Val Loss: 0.063027\n",
            "Epoch 383/2000, Rel Train Loss: 147.03%, Rel Val Loss: 111.88%\n",
            "Moving Avg Val Loss: 1.722569\n",
            "Epoch 384/2000, Train Loss: 0.004753, Val Loss: 0.061496\n",
            "Epoch 384/2000, Rel Train Loss: 126.40%, Rel Val Loss: 147.33%\n",
            "Moving Avg Val Loss: 1.589425\n",
            "Epoch 385/2000, Train Loss: 0.005251, Val Loss: 0.059023\n",
            "Epoch 385/2000, Rel Train Loss: 111.05%, Rel Val Loss: 86.39%\n",
            "Moving Avg Val Loss: 1.039554\n",
            "Epoch 386/2000, Train Loss: 0.003164, Val Loss: 0.061345\n",
            "Epoch 386/2000, Rel Train Loss: 73.79%, Rel Val Loss: 86.60%\n",
            "Moving Avg Val Loss: 1.112509\n",
            "Epoch 387/2000, Train Loss: 0.004001, Val Loss: 0.062095\n",
            "Epoch 387/2000, Rel Train Loss: 92.99%, Rel Val Loss: 124.06%\n",
            "Moving Avg Val Loss: 1.065447\n",
            "Epoch 388/2000, Train Loss: 0.003178, Val Loss: 0.056712\n",
            "Epoch 388/2000, Rel Train Loss: 77.84%, Rel Val Loss: 88.35%\n",
            "Moving Avg Val Loss: 0.933601\n",
            "Epoch 389/2000, Train Loss: 0.002857, Val Loss: 0.055236\n",
            "Epoch 389/2000, Rel Train Loss: 69.99%, Rel Val Loss: 81.41%\n",
            "Moving Avg Val Loss: 0.954041\n",
            "Epoch 390/2000, Train Loss: 0.002444, Val Loss: 0.054950\n",
            "Epoch 390/2000, Rel Train Loss: 73.09%, Rel Val Loss: 96.61%\n",
            "Moving Avg Val Loss: 0.963923\n",
            "Epoch 391/2000, Train Loss: 0.002414, Val Loss: 0.055698\n",
            "Epoch 391/2000, Rel Train Loss: 69.40%, Rel Val Loss: 91.54%\n",
            "Moving Avg Val Loss: 0.882667\n",
            "Epoch 392/2000, Train Loss: 0.002320, Val Loss: 0.056320\n",
            "Epoch 392/2000, Rel Train Loss: 71.68%, Rel Val Loss: 83.43%\n",
            "Moving Avg Val Loss: 0.896487\n",
            "Epoch 393/2000, Train Loss: 0.001559, Val Loss: 0.053707\n",
            "Epoch 393/2000, Rel Train Loss: 71.13%, Rel Val Loss: 95.26%\n",
            "Moving Avg Val Loss: 0.900593\n",
            "Epoch 394/2000, Train Loss: 0.001426, Val Loss: 0.056341\n",
            "Epoch 394/2000, Rel Train Loss: 64.59%, Rel Val Loss: 83.46%\n",
            "Moving Avg Val Loss: 0.883624\n",
            "Epoch 395/2000, Train Loss: 0.001580, Val Loss: 0.052355\n",
            "Epoch 395/2000, Rel Train Loss: 61.33%, Rel Val Loss: 88.13%\n",
            "Moving Avg Val Loss: 0.868466\n",
            "Epoch 396/2000, Train Loss: 0.001878, Val Loss: 0.058421\n",
            "Epoch 396/2000, Rel Train Loss: 72.77%, Rel Val Loss: 83.96%\n",
            "Moving Avg Val Loss: 0.868910\n",
            "Epoch 397/2000, Train Loss: 0.002116, Val Loss: 0.052499\n",
            "Epoch 397/2000, Rel Train Loss: 80.37%, Rel Val Loss: 83.65%\n",
            "Moving Avg Val Loss: 0.835516\n",
            "Epoch 398/2000, Train Loss: 0.001391, Val Loss: 0.055906\n",
            "Epoch 398/2000, Rel Train Loss: 66.54%, Rel Val Loss: 78.56%\n",
            "Moving Avg Val Loss: 0.831846\n",
            "Epoch 399/2000, Train Loss: 0.001378, Val Loss: 0.053628\n",
            "Epoch 399/2000, Rel Train Loss: 57.65%, Rel Val Loss: 81.62%\n",
            "Moving Avg Val Loss: 0.809092\n",
            "Epoch 400/2000, Train Loss: 0.001315, Val Loss: 0.051703\n",
            "Epoch 400/2000, Rel Train Loss: 59.03%, Rel Val Loss: 76.75%\n",
            "Moving Avg Val Loss: 0.800948\n",
            "Epoch 401/2000, Train Loss: 0.001201, Val Loss: 0.055086\n",
            "Epoch 401/2000, Rel Train Loss: 57.80%, Rel Val Loss: 79.89%\n",
            "Moving Avg Val Loss: 0.788324\n",
            "Epoch 402/2000, Train Loss: 0.001627, Val Loss: 0.054978\n",
            "Epoch 402/2000, Rel Train Loss: 59.31%, Rel Val Loss: 77.34%\n",
            "Moving Avg Val Loss: 0.794800\n",
            "Epoch 403/2000, Train Loss: 0.001894, Val Loss: 0.052529\n",
            "Epoch 403/2000, Rel Train Loss: 78.84%, Rel Val Loss: 81.80%\n",
            "Moving Avg Val Loss: 0.801875\n",
            "Epoch 404/2000, Train Loss: 0.001249, Val Loss: 0.055756\n",
            "Epoch 404/2000, Rel Train Loss: 60.69%, Rel Val Loss: 85.16%\n",
            "Moving Avg Val Loss: 0.820819\n",
            "Epoch 405/2000, Train Loss: 0.001198, Val Loss: 0.052513\n",
            "Epoch 405/2000, Rel Train Loss: 59.53%, Rel Val Loss: 86.22%\n",
            "Moving Avg Val Loss: 0.818713\n",
            "Epoch 406/2000, Train Loss: 0.001406, Val Loss: 0.055275\n",
            "Epoch 406/2000, Rel Train Loss: 61.86%, Rel Val Loss: 78.84%\n",
            "Moving Avg Val Loss: 0.831525\n",
            "Epoch 407/2000, Train Loss: 0.002304, Val Loss: 0.056018\n",
            "Epoch 407/2000, Rel Train Loss: 66.78%, Rel Val Loss: 83.74%\n",
            "Moving Avg Val Loss: 0.847192\n",
            "Epoch 408/2000, Train Loss: 0.002109, Val Loss: 0.055925\n",
            "Epoch 408/2000, Rel Train Loss: 62.71%, Rel Val Loss: 89.63%\n",
            "Moving Avg Val Loss: 0.832469\n",
            "Epoch 409/2000, Train Loss: 0.001187, Val Loss: 0.055498\n",
            "Epoch 409/2000, Rel Train Loss: 57.25%, Rel Val Loss: 77.80%\n",
            "Moving Avg Val Loss: 0.813078\n",
            "Epoch 410/2000, Train Loss: 0.001531, Val Loss: 0.054224\n",
            "Epoch 410/2000, Rel Train Loss: 58.90%, Rel Val Loss: 76.53%\n",
            "Moving Avg Val Loss: 0.831146\n",
            "Epoch 411/2000, Train Loss: 0.002601, Val Loss: 0.064921\n",
            "Epoch 411/2000, Rel Train Loss: 63.53%, Rel Val Loss: 87.87%\n",
            "Moving Avg Val Loss: 0.876502\n",
            "Epoch 412/2000, Train Loss: 0.003316, Val Loss: 0.052263\n",
            "Epoch 412/2000, Rel Train Loss: 95.10%, Rel Val Loss: 106.42%\n",
            "Moving Avg Val Loss: 0.869446\n",
            "Epoch 413/2000, Train Loss: 0.003903, Val Loss: 0.059004\n",
            "Epoch 413/2000, Rel Train Loss: 90.95%, Rel Val Loss: 86.11%\n",
            "Moving Avg Val Loss: 0.886667\n",
            "Epoch 414/2000, Train Loss: 0.006464, Val Loss: 0.055871\n",
            "Epoch 414/2000, Rel Train Loss: 80.48%, Rel Val Loss: 86.41%\n",
            "Moving Avg Val Loss: 0.907567\n",
            "Epoch 415/2000, Train Loss: 0.002462, Val Loss: 0.061005\n",
            "Epoch 415/2000, Rel Train Loss: 86.14%, Rel Val Loss: 86.98%\n",
            "Moving Avg Val Loss: 0.901351\n",
            "Epoch 416/2000, Train Loss: 0.001806, Val Loss: 0.053925\n",
            "Epoch 416/2000, Rel Train Loss: 65.69%, Rel Val Loss: 84.76%\n",
            "Moving Avg Val Loss: 0.858243\n",
            "Epoch 417/2000, Train Loss: 0.002591, Val Loss: 0.059969\n",
            "Epoch 417/2000, Rel Train Loss: 73.02%, Rel Val Loss: 84.87%\n",
            "Moving Avg Val Loss: 0.836623\n",
            "Epoch 418/2000, Train Loss: 0.002016, Val Loss: 0.051081\n",
            "Epoch 418/2000, Rel Train Loss: 68.76%, Rel Val Loss: 75.30%\n",
            "Moving Avg Val Loss: 0.826774\n",
            "Epoch 419/2000, Train Loss: 0.001669, Val Loss: 0.056041\n",
            "Epoch 419/2000, Rel Train Loss: 61.16%, Rel Val Loss: 81.49%\n",
            "Moving Avg Val Loss: 0.804269\n",
            "Epoch 420/2000, Train Loss: 0.001890, Val Loss: 0.052605\n",
            "Epoch 420/2000, Rel Train Loss: 67.09%, Rel Val Loss: 75.72%\n",
            "Moving Avg Val Loss: 0.796798\n",
            "Epoch 421/2000, Train Loss: 0.004809, Val Loss: 0.072659\n",
            "Epoch 421/2000, Rel Train Loss: 85.78%, Rel Val Loss: 81.03%\n",
            "Moving Avg Val Loss: 0.842332\n",
            "Epoch 422/2000, Train Loss: 0.005175, Val Loss: 0.055474\n",
            "Epoch 422/2000, Rel Train Loss: 134.72%, Rel Val Loss: 107.63%\n",
            "Moving Avg Val Loss: 0.922081\n",
            "Epoch 423/2000, Train Loss: 0.002787, Val Loss: 0.059502\n",
            "Epoch 423/2000, Rel Train Loss: 121.65%, Rel Val Loss: 115.17%\n",
            "Moving Avg Val Loss: 0.946905\n",
            "Epoch 424/2000, Train Loss: 0.001848, Val Loss: 0.055839\n",
            "Epoch 424/2000, Rel Train Loss: 72.48%, Rel Val Loss: 93.90%\n",
            "Moving Avg Val Loss: 0.948680\n",
            "Epoch 425/2000, Train Loss: 0.001844, Val Loss: 0.053789\n",
            "Epoch 425/2000, Rel Train Loss: 65.32%, Rel Val Loss: 76.61%\n",
            "Moving Avg Val Loss: 0.953605\n",
            "Epoch 426/2000, Train Loss: 0.001321, Val Loss: 0.051693\n",
            "Epoch 426/2000, Rel Train Loss: 56.68%, Rel Val Loss: 83.49%\n",
            "Moving Avg Val Loss: 0.933695\n",
            "Epoch 427/2000, Train Loss: 0.003352, Val Loss: 0.056112\n",
            "Epoch 427/2000, Rel Train Loss: 73.89%, Rel Val Loss: 97.68%\n",
            "Moving Avg Val Loss: 0.976344\n",
            "Epoch 428/2000, Train Loss: 0.002702, Val Loss: 0.060368\n",
            "Epoch 428/2000, Rel Train Loss: 81.76%, Rel Val Loss: 136.50%\n",
            "Moving Avg Val Loss: 0.936684\n",
            "Epoch 429/2000, Train Loss: 0.002557, Val Loss: 0.052191\n",
            "Epoch 429/2000, Rel Train Loss: 69.28%, Rel Val Loss: 74.07%\n",
            "Moving Avg Val Loss: 0.940142\n",
            "Epoch 430/2000, Train Loss: 0.001445, Val Loss: 0.057844\n",
            "Epoch 430/2000, Rel Train Loss: 57.28%, Rel Val Loss: 78.34%\n",
            "Moving Avg Val Loss: 0.935010\n",
            "Epoch 431/2000, Train Loss: 0.002078, Val Loss: 0.053633\n",
            "Epoch 431/2000, Rel Train Loss: 63.97%, Rel Val Loss: 80.92%\n",
            "Moving Avg Val Loss: 0.892715\n",
            "Epoch 432/2000, Train Loss: 0.001437, Val Loss: 0.055492\n",
            "Epoch 432/2000, Rel Train Loss: 65.36%, Rel Val Loss: 76.53%\n",
            "Moving Avg Val Loss: 0.787784\n",
            "Epoch 433/2000, Train Loss: 0.001167, Val Loss: 0.053046\n",
            "Epoch 433/2000, Rel Train Loss: 62.41%, Rel Val Loss: 84.03%\n",
            "Moving Avg Val Loss: 0.796052\n",
            "Epoch 434/2000, Train Loss: 0.001032, Val Loss: 0.053614\n",
            "Epoch 434/2000, Rel Train Loss: 56.77%, Rel Val Loss: 78.20%\n",
            "Moving Avg Val Loss: 0.794055\n",
            "Epoch 435/2000, Train Loss: 0.001232, Val Loss: 0.053467\n",
            "Epoch 435/2000, Rel Train Loss: 58.88%, Rel Val Loss: 77.34%\n",
            "Moving Avg Val Loss: 0.782333\n",
            "Epoch 436/2000, Train Loss: 0.001197, Val Loss: 0.054054\n",
            "Epoch 436/2000, Rel Train Loss: 57.00%, Rel Val Loss: 75.06%\n",
            "Moving Avg Val Loss: 0.782371\n",
            "Epoch 437/2000, Train Loss: 0.001446, Val Loss: 0.052253\n",
            "Epoch 437/2000, Rel Train Loss: 75.21%, Rel Val Loss: 76.55%\n",
            "Moving Avg Val Loss: 0.791807\n",
            "Epoch 438/2000, Train Loss: 0.001252, Val Loss: 0.053734\n",
            "Epoch 438/2000, Rel Train Loss: 74.32%, Rel Val Loss: 88.75%\n",
            "Moving Avg Val Loss: 0.790282\n",
            "Epoch 439/2000, Train Loss: 0.001196, Val Loss: 0.054963\n",
            "Epoch 439/2000, Rel Train Loss: 56.44%, Rel Val Loss: 77.44%\n",
            "Moving Avg Val Loss: 0.800558\n",
            "Epoch 440/2000, Train Loss: 0.001533, Val Loss: 0.054463\n",
            "Epoch 440/2000, Rel Train Loss: 64.61%, Rel Val Loss: 82.48%\n",
            "Moving Avg Val Loss: 0.834859\n",
            "Epoch 441/2000, Train Loss: 0.001327, Val Loss: 0.051367\n",
            "Epoch 441/2000, Rel Train Loss: 67.73%, Rel Val Loss: 92.21%\n",
            "Moving Avg Val Loss: 0.832443\n",
            "Epoch 442/2000, Train Loss: 0.001055, Val Loss: 0.052961\n",
            "Epoch 442/2000, Rel Train Loss: 58.30%, Rel Val Loss: 75.34%\n",
            "Moving Avg Val Loss: 0.801692\n",
            "Epoch 443/2000, Train Loss: 0.000998, Val Loss: 0.052992\n",
            "Epoch 443/2000, Rel Train Loss: 52.95%, Rel Val Loss: 73.37%\n",
            "Moving Avg Val Loss: 0.797484\n",
            "Epoch 444/2000, Train Loss: 0.001029, Val Loss: 0.051532\n",
            "Epoch 444/2000, Rel Train Loss: 55.66%, Rel Val Loss: 75.34%\n",
            "Moving Avg Val Loss: 0.825205\n",
            "Epoch 445/2000, Train Loss: 0.001659, Val Loss: 0.056030\n",
            "Epoch 445/2000, Rel Train Loss: 59.92%, Rel Val Loss: 96.34%\n",
            "Moving Avg Val Loss: 0.796843\n",
            "Epoch 446/2000, Train Loss: 0.001595, Val Loss: 0.053553\n",
            "Epoch 446/2000, Rel Train Loss: 60.58%, Rel Val Loss: 78.03%\n",
            "Moving Avg Val Loss: 0.800407\n",
            "Epoch 447/2000, Train Loss: 0.001622, Val Loss: 0.051658\n",
            "Epoch 447/2000, Rel Train Loss: 63.47%, Rel Val Loss: 77.12%\n",
            "Moving Avg Val Loss: 0.803097\n",
            "Epoch 448/2000, Train Loss: 0.002109, Val Loss: 0.058119\n",
            "Epoch 448/2000, Rel Train Loss: 66.64%, Rel Val Loss: 74.72%\n",
            "Moving Avg Val Loss: 0.894560\n",
            "Epoch 449/2000, Train Loss: 0.003129, Val Loss: 0.076793\n",
            "Epoch 449/2000, Rel Train Loss: 69.13%, Rel Val Loss: 121.07%\n",
            "Moving Avg Val Loss: 1.029064\n",
            "Epoch 450/2000, Train Loss: 0.007464, Val Loss: 0.060315\n",
            "Epoch 450/2000, Rel Train Loss: 184.84%, Rel Val Loss: 163.59%\n",
            "Moving Avg Val Loss: 1.233287\n",
            "Epoch 451/2000, Train Loss: 0.004071, Val Loss: 0.058289\n",
            "Epoch 451/2000, Rel Train Loss: 124.08%, Rel Val Loss: 180.14%\n",
            "Moving Avg Val Loss: 1.286464\n",
            "Epoch 452/2000, Train Loss: 0.002939, Val Loss: 0.056152\n",
            "Epoch 452/2000, Rel Train Loss: 99.77%, Rel Val Loss: 103.71%\n",
            "Moving Avg Val Loss: 1.293613\n",
            "Epoch 453/2000, Train Loss: 0.001505, Val Loss: 0.051654\n",
            "Epoch 453/2000, Rel Train Loss: 64.10%, Rel Val Loss: 78.29%\n",
            "Moving Avg Val Loss: 1.238677\n",
            "Epoch 454/2000, Train Loss: 0.001646, Val Loss: 0.057552\n",
            "Epoch 454/2000, Rel Train Loss: 62.38%, Rel Val Loss: 93.60%\n",
            "Moving Avg Val Loss: 1.064500\n",
            "Epoch 455/2000, Train Loss: 0.001623, Val Loss: 0.052479\n",
            "Epoch 455/2000, Rel Train Loss: 63.93%, Rel Val Loss: 76.50%\n",
            "Moving Avg Val Loss: 0.889126\n",
            "Epoch 456/2000, Train Loss: 0.001577, Val Loss: 0.053899\n",
            "Epoch 456/2000, Rel Train Loss: 58.43%, Rel Val Loss: 92.46%\n",
            "Moving Avg Val Loss: 0.828049\n",
            "Epoch 457/2000, Train Loss: 0.001381, Val Loss: 0.055480\n",
            "Epoch 457/2000, Rel Train Loss: 60.38%, Rel Val Loss: 73.17%\n",
            "Moving Avg Val Loss: 0.815762\n",
            "Epoch 458/2000, Train Loss: 0.001271, Val Loss: 0.052962\n",
            "Epoch 458/2000, Rel Train Loss: 60.46%, Rel Val Loss: 72.15%\n",
            "Moving Avg Val Loss: 0.772909\n",
            "Epoch 459/2000, Train Loss: 0.001352, Val Loss: 0.054511\n",
            "Epoch 459/2000, Rel Train Loss: 55.04%, Rel Val Loss: 72.17%\n",
            "Moving Avg Val Loss: 0.792556\n",
            "Epoch 460/2000, Train Loss: 0.002154, Val Loss: 0.053229\n",
            "Epoch 460/2000, Rel Train Loss: 71.43%, Rel Val Loss: 86.33%\n",
            "Moving Avg Val Loss: 1.176698\n",
            "Epoch 461/2000, Train Loss: 0.010914, Val Loss: 0.068581\n",
            "Epoch 461/2000, Rel Train Loss: 135.39%, Rel Val Loss: 284.53%\n",
            "Moving Avg Val Loss: 1.567504\n",
            "Epoch 462/2000, Train Loss: 0.011542, Val Loss: 0.063185\n",
            "Epoch 462/2000, Rel Train Loss: 215.37%, Rel Val Loss: 268.58%\n",
            "Moving Avg Val Loss: 1.878369\n",
            "Epoch 463/2000, Train Loss: 0.010516, Val Loss: 0.056408\n",
            "Epoch 463/2000, Rel Train Loss: 240.27%, Rel Val Loss: 227.58%\n",
            "Moving Avg Val Loss: 1.902411\n",
            "Epoch 464/2000, Train Loss: 0.005880, Val Loss: 0.065470\n",
            "Epoch 464/2000, Rel Train Loss: 133.69%, Rel Val Loss: 84.19%\n",
            "Moving Avg Val Loss: 1.876973\n",
            "Epoch 465/2000, Train Loss: 0.008259, Val Loss: 0.055454\n",
            "Epoch 465/2000, Rel Train Loss: 98.01%, Rel Val Loss: 73.61%\n",
            "Moving Avg Val Loss: 1.622846\n",
            "Epoch 466/2000, Train Loss: 0.006190, Val Loss: 0.070613\n",
            "Epoch 466/2000, Rel Train Loss: 105.64%, Rel Val Loss: 157.46%\n",
            "Moving Avg Val Loss: 1.234472\n",
            "Epoch 467/2000, Train Loss: 0.009118, Val Loss: 0.051644\n",
            "Epoch 467/2000, Rel Train Loss: 98.66%, Rel Val Loss: 74.39%\n",
            "Moving Avg Val Loss: 0.951635\n",
            "Epoch 468/2000, Train Loss: 0.008427, Val Loss: 0.061540\n",
            "Epoch 468/2000, Rel Train Loss: 90.17%, Rel Val Loss: 86.16%\n",
            "Moving Avg Val Loss: 0.999524\n",
            "Epoch 469/2000, Train Loss: 0.005290, Val Loss: 0.052901\n",
            "Epoch 469/2000, Rel Train Loss: 88.12%, Rel Val Loss: 108.14%\n",
            "Moving Avg Val Loss: 1.023116\n",
            "Epoch 470/2000, Train Loss: 0.005464, Val Loss: 0.061399\n",
            "Epoch 470/2000, Rel Train Loss: 95.89%, Rel Val Loss: 85.40%\n",
            "Moving Avg Val Loss: 0.864038\n",
            "Epoch 471/2000, Train Loss: 0.001808, Val Loss: 0.051871\n",
            "Epoch 471/2000, Rel Train Loss: 76.44%, Rel Val Loss: 77.92%\n",
            "Moving Avg Val Loss: 0.867452\n",
            "Epoch 472/2000, Train Loss: 0.001971, Val Loss: 0.057418\n",
            "Epoch 472/2000, Rel Train Loss: 60.77%, Rel Val Loss: 76.10%\n",
            "Moving Avg Val Loss: 0.896058\n",
            "Epoch 473/2000, Train Loss: 0.001825, Val Loss: 0.052271\n",
            "Epoch 473/2000, Rel Train Loss: 65.01%, Rel Val Loss: 100.47%\n",
            "Moving Avg Val Loss: 0.830091\n",
            "Epoch 474/2000, Train Loss: 0.002337, Val Loss: 0.055339\n",
            "Epoch 474/2000, Rel Train Loss: 69.01%, Rel Val Loss: 75.15%\n",
            "Moving Avg Val Loss: 0.798429\n",
            "Epoch 475/2000, Train Loss: 0.002669, Val Loss: 0.055187\n",
            "Epoch 475/2000, Rel Train Loss: 66.29%, Rel Val Loss: 69.57%\n",
            "Moving Avg Val Loss: 0.812153\n",
            "Epoch 476/2000, Train Loss: 0.002444, Val Loss: 0.051029\n",
            "Epoch 476/2000, Rel Train Loss: 67.88%, Rel Val Loss: 84.79%\n",
            "Moving Avg Val Loss: 0.803269\n",
            "Epoch 477/2000, Train Loss: 0.001262, Val Loss: 0.054481\n",
            "Epoch 477/2000, Rel Train Loss: 58.46%, Rel Val Loss: 71.66%\n",
            "Moving Avg Val Loss: 0.757250\n",
            "Epoch 478/2000, Train Loss: 0.001079, Val Loss: 0.051149\n",
            "Epoch 478/2000, Rel Train Loss: 55.37%, Rel Val Loss: 77.46%\n",
            "Moving Avg Val Loss: 0.747829\n",
            "Epoch 479/2000, Train Loss: 0.001178, Val Loss: 0.054539\n",
            "Epoch 479/2000, Rel Train Loss: 54.51%, Rel Val Loss: 70.44%\n",
            "Moving Avg Val Loss: 0.762783\n",
            "Epoch 480/2000, Train Loss: 0.001886, Val Loss: 0.051887\n",
            "Epoch 480/2000, Rel Train Loss: 59.58%, Rel Val Loss: 77.05%\n",
            "Moving Avg Val Loss: 0.739412\n",
            "Epoch 481/2000, Train Loss: 0.001350, Val Loss: 0.053850\n",
            "Epoch 481/2000, Rel Train Loss: 62.22%, Rel Val Loss: 73.10%\n",
            "Moving Avg Val Loss: 0.733802\n",
            "Epoch 482/2000, Train Loss: 0.001072, Val Loss: 0.052920\n",
            "Epoch 482/2000, Rel Train Loss: 56.23%, Rel Val Loss: 68.85%\n",
            "Moving Avg Val Loss: 0.763860\n",
            "Epoch 483/2000, Train Loss: 0.001088, Val Loss: 0.055673\n",
            "Epoch 483/2000, Rel Train Loss: 57.94%, Rel Val Loss: 92.48%\n",
            "Moving Avg Val Loss: 0.766952\n",
            "Epoch 484/2000, Train Loss: 0.001853, Val Loss: 0.054467\n",
            "Epoch 484/2000, Rel Train Loss: 60.59%, Rel Val Loss: 71.99%\n",
            "Moving Avg Val Loss: 0.752187\n",
            "Epoch 485/2000, Train Loss: 0.001367, Val Loss: 0.051586\n",
            "Epoch 485/2000, Rel Train Loss: 61.61%, Rel Val Loss: 69.67%\n",
            "Moving Avg Val Loss: 0.750189\n",
            "Epoch 486/2000, Train Loss: 0.001144, Val Loss: 0.053012\n",
            "Epoch 486/2000, Rel Train Loss: 56.18%, Rel Val Loss: 72.10%\n",
            "Moving Avg Val Loss: 0.767138\n",
            "Epoch 487/2000, Train Loss: 0.001130, Val Loss: 0.054729\n",
            "Epoch 487/2000, Rel Train Loss: 55.40%, Rel Val Loss: 77.32%\n",
            "Moving Avg Val Loss: 0.718761\n",
            "Epoch 488/2000, Train Loss: 0.001338, Val Loss: 0.051163\n",
            "Epoch 488/2000, Rel Train Loss: 61.93%, Rel Val Loss: 68.30%\n",
            "Moving Avg Val Loss: 0.786062\n",
            "Epoch 489/2000, Train Loss: 0.005929, Val Loss: 0.058212\n",
            "Epoch 489/2000, Rel Train Loss: 70.96%, Rel Val Loss: 105.64%\n",
            "Moving Avg Val Loss: 0.804254\n",
            "Epoch 490/2000, Train Loss: 0.005608, Val Loss: 0.059787\n",
            "Epoch 490/2000, Rel Train Loss: 115.86%, Rel Val Loss: 78.76%\n",
            "Moving Avg Val Loss: 1.009122\n",
            "Epoch 491/2000, Train Loss: 0.004553, Val Loss: 0.062512\n",
            "Epoch 491/2000, Rel Train Loss: 127.55%, Rel Val Loss: 174.54%\n",
            "Moving Avg Val Loss: 1.008071\n",
            "Epoch 492/2000, Train Loss: 0.002643, Val Loss: 0.059929\n",
            "Epoch 492/2000, Rel Train Loss: 95.28%, Rel Val Loss: 76.80%\n",
            "Moving Avg Val Loss: 1.008179\n",
            "Epoch 493/2000, Train Loss: 0.001834, Val Loss: 0.054223\n",
            "Epoch 493/2000, Rel Train Loss: 60.11%, Rel Val Loss: 68.35%\n",
            "Moving Avg Val Loss: 0.963018\n",
            "Epoch 494/2000, Train Loss: 0.001629, Val Loss: 0.052192\n",
            "Epoch 494/2000, Rel Train Loss: 59.09%, Rel Val Loss: 83.06%\n",
            "Moving Avg Val Loss: 0.943129\n",
            "Epoch 495/2000, Train Loss: 0.001063, Val Loss: 0.053095\n",
            "Epoch 495/2000, Rel Train Loss: 56.67%, Rel Val Loss: 68.82%\n",
            "Moving Avg Val Loss: 0.726998\n",
            "Epoch 496/2000, Train Loss: 0.000890, Val Loss: 0.051889\n",
            "Epoch 496/2000, Rel Train Loss: 52.02%, Rel Val Loss: 66.47%\n",
            "Moving Avg Val Loss: 0.709307\n",
            "Epoch 497/2000, Train Loss: 0.000866, Val Loss: 0.051443\n",
            "Epoch 497/2000, Rel Train Loss: 50.85%, Rel Val Loss: 67.95%\n",
            "Moving Avg Val Loss: 0.707418\n",
            "Epoch 498/2000, Train Loss: 0.001543, Val Loss: 0.052982\n",
            "Epoch 498/2000, Rel Train Loss: 56.31%, Rel Val Loss: 67.41%\n",
            "Moving Avg Val Loss: 0.707582\n",
            "Epoch 499/2000, Train Loss: 0.001588, Val Loss: 0.054997\n",
            "Epoch 499/2000, Rel Train Loss: 60.50%, Rel Val Loss: 83.14%\n",
            "Moving Avg Val Loss: 0.716856\n",
            "Epoch 500/2000, Train Loss: 0.001511, Val Loss: 0.052780\n",
            "Epoch 500/2000, Rel Train Loss: 58.01%, Rel Val Loss: 73.46%\n",
            "Moving Avg Val Loss: 0.718851\n",
            "Epoch 501/2000, Train Loss: 0.001277, Val Loss: 0.050252\n",
            "Epoch 501/2000, Rel Train Loss: 55.23%, Rel Val Loss: 67.47%\n",
            "Moving Avg Val Loss: 0.749269\n",
            "Epoch 502/2000, Train Loss: 0.001555, Val Loss: 0.057311\n",
            "Epoch 502/2000, Rel Train Loss: 62.73%, Rel Val Loss: 83.16%\n",
            "Moving Avg Val Loss: 0.775841\n",
            "Epoch 503/2000, Train Loss: 0.001687, Val Loss: 0.051468\n",
            "Epoch 503/2000, Rel Train Loss: 59.29%, Rel Val Loss: 80.69%\n",
            "Moving Avg Val Loss: 0.786308\n",
            "Epoch 504/2000, Train Loss: 0.002003, Val Loss: 0.054106\n",
            "Epoch 504/2000, Rel Train Loss: 56.96%, Rel Val Loss: 88.38%\n",
            "Moving Avg Val Loss: 0.815202\n",
            "Epoch 505/2000, Train Loss: 0.002929, Val Loss: 0.055636\n",
            "Epoch 505/2000, Rel Train Loss: 74.34%, Rel Val Loss: 87.90%\n",
            "Moving Avg Val Loss: 0.910804\n",
            "Epoch 506/2000, Train Loss: 0.003140, Val Loss: 0.058136\n",
            "Epoch 506/2000, Rel Train Loss: 79.80%, Rel Val Loss: 115.27%\n",
            "Moving Avg Val Loss: 0.876562\n",
            "Epoch 507/2000, Train Loss: 0.001426, Val Loss: 0.052348\n",
            "Epoch 507/2000, Rel Train Loss: 67.92%, Rel Val Loss: 66.04%\n",
            "Moving Avg Val Loss: 0.863019\n",
            "Epoch 508/2000, Train Loss: 0.000999, Val Loss: 0.053869\n",
            "Epoch 508/2000, Rel Train Loss: 55.05%, Rel Val Loss: 73.92%\n",
            "Moving Avg Val Loss: 0.818846\n",
            "Epoch 509/2000, Train Loss: 0.000906, Val Loss: 0.052644\n",
            "Epoch 509/2000, Rel Train Loss: 52.76%, Rel Val Loss: 66.29%\n",
            "Moving Avg Val Loss: 0.772199\n",
            "Epoch 510/2000, Train Loss: 0.000979, Val Loss: 0.051324\n",
            "Epoch 510/2000, Rel Train Loss: 52.83%, Rel Val Loss: 64.58%\n",
            "Moving Avg Val Loss: 0.728573\n",
            "Epoch 511/2000, Train Loss: 0.001250, Val Loss: 0.053928\n",
            "Epoch 511/2000, Rel Train Loss: 53.08%, Rel Val Loss: 93.46%\n",
            "Moving Avg Val Loss: 0.775974\n",
            "Epoch 512/2000, Train Loss: 0.002061, Val Loss: 0.057013\n",
            "Epoch 512/2000, Rel Train Loss: 60.89%, Rel Val Loss: 89.74%\n",
            "Moving Avg Val Loss: 0.800953\n",
            "Epoch 513/2000, Train Loss: 0.002748, Val Loss: 0.056350\n",
            "Epoch 513/2000, Rel Train Loss: 88.10%, Rel Val Loss: 86.41%\n",
            "Moving Avg Val Loss: 0.851571\n",
            "Epoch 514/2000, Train Loss: 0.004149, Val Loss: 0.061286\n",
            "Epoch 514/2000, Rel Train Loss: 87.93%, Rel Val Loss: 91.60%\n",
            "Moving Avg Val Loss: 0.857150\n",
            "Epoch 515/2000, Train Loss: 0.002993, Val Loss: 0.049833\n",
            "Epoch 515/2000, Rel Train Loss: 77.93%, Rel Val Loss: 67.37%\n",
            "Moving Avg Val Loss: 0.875803\n",
            "Epoch 516/2000, Train Loss: 0.001891, Val Loss: 0.061082\n",
            "Epoch 516/2000, Rel Train Loss: 71.24%, Rel Val Loss: 102.78%\n",
            "Moving Avg Val Loss: 0.834399\n",
            "Epoch 517/2000, Train Loss: 0.001302, Val Loss: 0.049625\n",
            "Epoch 517/2000, Rel Train Loss: 58.03%, Rel Val Loss: 69.04%\n",
            "Moving Avg Val Loss: 0.800180\n",
            "Epoch 518/2000, Train Loss: 0.001477, Val Loss: 0.054919\n",
            "Epoch 518/2000, Rel Train Loss: 60.78%, Rel Val Loss: 69.30%\n",
            "Moving Avg Val Loss: 0.838204\n",
            "Epoch 519/2000, Train Loss: 0.001363, Val Loss: 0.054282\n",
            "Epoch 519/2000, Rel Train Loss: 67.94%, Rel Val Loss: 110.61%\n",
            "Moving Avg Val Loss: 0.839573\n",
            "Epoch 520/2000, Train Loss: 0.001100, Val Loss: 0.049798\n",
            "Epoch 520/2000, Rel Train Loss: 68.32%, Rel Val Loss: 68.05%\n",
            "Moving Avg Val Loss: 0.765125\n",
            "Epoch 521/2000, Train Loss: 0.001247, Val Loss: 0.053778\n",
            "Epoch 521/2000, Rel Train Loss: 59.54%, Rel Val Loss: 65.56%\n",
            "Moving Avg Val Loss: 0.761304\n",
            "Epoch 522/2000, Train Loss: 0.000975, Val Loss: 0.048674\n",
            "Epoch 522/2000, Rel Train Loss: 57.14%, Rel Val Loss: 67.13%\n",
            "Moving Avg Val Loss: 0.751795\n",
            "Epoch 523/2000, Train Loss: 0.001175, Val Loss: 0.052983\n",
            "Epoch 523/2000, Rel Train Loss: 53.01%, Rel Val Loss: 64.55%\n",
            "Moving Avg Val Loss: 0.665242\n",
            "Epoch 524/2000, Train Loss: 0.000993, Val Loss: 0.050491\n",
            "Epoch 524/2000, Rel Train Loss: 56.20%, Rel Val Loss: 67.33%\n",
            "Moving Avg Val Loss: 0.655770\n",
            "Epoch 525/2000, Train Loss: 0.000833, Val Loss: 0.053070\n",
            "Epoch 525/2000, Rel Train Loss: 51.81%, Rel Val Loss: 63.32%\n",
            "Moving Avg Val Loss: 0.659359\n",
            "Epoch 526/2000, Train Loss: 0.000797, Val Loss: 0.051701\n",
            "Epoch 526/2000, Rel Train Loss: 50.53%, Rel Val Loss: 67.35%\n",
            "Moving Avg Val Loss: 0.664149\n",
            "Epoch 527/2000, Train Loss: 0.000934, Val Loss: 0.051375\n",
            "Epoch 527/2000, Rel Train Loss: 53.38%, Rel Val Loss: 69.52%\n",
            "Moving Avg Val Loss: 0.666771\n",
            "Epoch 528/2000, Train Loss: 0.001107, Val Loss: 0.052318\n",
            "Epoch 528/2000, Rel Train Loss: 54.61%, Rel Val Loss: 65.86%\n",
            "Moving Avg Val Loss: 0.703288\n",
            "Epoch 529/2000, Train Loss: 0.001248, Val Loss: 0.053068\n",
            "Epoch 529/2000, Rel Train Loss: 49.86%, Rel Val Loss: 85.59%\n",
            "Moving Avg Val Loss: 0.738203\n",
            "Epoch 530/2000, Train Loss: 0.001943, Val Loss: 0.050717\n",
            "Epoch 530/2000, Rel Train Loss: 67.43%, Rel Val Loss: 80.78%\n",
            "Moving Avg Val Loss: 0.740523\n",
            "Epoch 531/2000, Train Loss: 0.001370, Val Loss: 0.053917\n",
            "Epoch 531/2000, Rel Train Loss: 66.00%, Rel Val Loss: 68.51%\n",
            "Moving Avg Val Loss: 0.788914\n",
            "Epoch 532/2000, Train Loss: 0.001894, Val Loss: 0.050807\n",
            "Epoch 532/2000, Rel Train Loss: 68.00%, Rel Val Loss: 93.72%\n",
            "Moving Avg Val Loss: 0.798824\n",
            "Epoch 533/2000, Train Loss: 0.001549, Val Loss: 0.058922\n",
            "Epoch 533/2000, Rel Train Loss: 58.16%, Rel Val Loss: 70.81%\n",
            "Moving Avg Val Loss: 0.778746\n",
            "Epoch 534/2000, Train Loss: 0.003375, Val Loss: 0.053068\n",
            "Epoch 534/2000, Rel Train Loss: 78.41%, Rel Val Loss: 75.55%\n",
            "Moving Avg Val Loss: 0.860498\n",
            "Epoch 535/2000, Train Loss: 0.004284, Val Loss: 0.062133\n",
            "Epoch 535/2000, Rel Train Loss: 84.01%, Rel Val Loss: 121.65%\n",
            "Moving Avg Val Loss: 1.004616\n",
            "Epoch 536/2000, Train Loss: 0.006941, Val Loss: 0.052899\n",
            "Epoch 536/2000, Rel Train Loss: 96.12%, Rel Val Loss: 140.57%\n",
            "Moving Avg Val Loss: 1.008327\n",
            "Epoch 537/2000, Train Loss: 0.003789, Val Loss: 0.058226\n",
            "Epoch 537/2000, Rel Train Loss: 101.41%, Rel Val Loss: 95.57%\n",
            "Moving Avg Val Loss: 1.000618\n",
            "Epoch 538/2000, Train Loss: 0.001636, Val Loss: 0.053998\n",
            "Epoch 538/2000, Rel Train Loss: 82.90%, Rel Val Loss: 66.96%\n",
            "Moving Avg Val Loss: 0.991677\n",
            "Epoch 539/2000, Train Loss: 0.001852, Val Loss: 0.049896\n",
            "Epoch 539/2000, Rel Train Loss: 60.27%, Rel Val Loss: 71.08%\n",
            "Moving Avg Val Loss: 0.972979\n",
            "Epoch 540/2000, Train Loss: 0.002385, Val Loss: 0.060364\n",
            "Epoch 540/2000, Rel Train Loss: 72.53%, Rel Val Loss: 112.30%\n",
            "Moving Avg Val Loss: 0.928939\n",
            "Epoch 541/2000, Train Loss: 0.006431, Val Loss: 0.052194\n",
            "Epoch 541/2000, Rel Train Loss: 99.24%, Rel Val Loss: 118.55%\n",
            "Moving Avg Val Loss: 0.957910\n",
            "Epoch 542/2000, Train Loss: 0.004296, Val Loss: 0.056319\n",
            "Epoch 542/2000, Rel Train Loss: 95.75%, Rel Val Loss: 110.06%\n",
            "Moving Avg Val Loss: 0.969612\n",
            "Epoch 543/2000, Train Loss: 0.003560, Val Loss: 0.056544\n",
            "Epoch 543/2000, Rel Train Loss: 105.60%, Rel Val Loss: 72.81%\n",
            "Moving Avg Val Loss: 0.965921\n",
            "Epoch 544/2000, Train Loss: 0.001587, Val Loss: 0.049791\n",
            "Epoch 544/2000, Rel Train Loss: 69.71%, Rel Val Loss: 69.24%\n",
            "Moving Avg Val Loss: 0.881905\n",
            "Epoch 545/2000, Train Loss: 0.002770, Val Loss: 0.060640\n",
            "Epoch 545/2000, Rel Train Loss: 62.01%, Rel Val Loss: 70.29%\n",
            "Moving Avg Val Loss: 0.917016\n",
            "Epoch 546/2000, Train Loss: 0.003715, Val Loss: 0.053858\n",
            "Epoch 546/2000, Rel Train Loss: 106.48%, Rel Val Loss: 136.11%\n",
            "Moving Avg Val Loss: 0.827864\n",
            "Epoch 547/2000, Train Loss: 0.002486, Val Loss: 0.054295\n",
            "Epoch 547/2000, Rel Train Loss: 76.66%, Rel Val Loss: 65.48%\n",
            "Moving Avg Val Loss: 0.880447\n",
            "Epoch 548/2000, Train Loss: 0.002808, Val Loss: 0.052856\n",
            "Epoch 548/2000, Rel Train Loss: 64.33%, Rel Val Loss: 99.10%\n",
            "Moving Avg Val Loss: 1.033219\n",
            "Epoch 549/2000, Train Loss: 0.002998, Val Loss: 0.054940\n",
            "Epoch 549/2000, Rel Train Loss: 94.94%, Rel Val Loss: 145.62%\n",
            "Moving Avg Val Loss: 1.085625\n",
            "Epoch 550/2000, Train Loss: 0.003270, Val Loss: 0.057345\n",
            "Epoch 550/2000, Rel Train Loss: 90.68%, Rel Val Loss: 96.50%\n",
            "Moving Avg Val Loss: 1.064943\n",
            "Epoch 551/2000, Train Loss: 0.003363, Val Loss: 0.056373\n",
            "Epoch 551/2000, Rel Train Loss: 95.48%, Rel Val Loss: 125.77%\n",
            "Moving Avg Val Loss: 1.097509\n",
            "Epoch 552/2000, Train Loss: 0.005857, Val Loss: 0.057530\n",
            "Epoch 552/2000, Rel Train Loss: 70.94%, Rel Val Loss: 81.77%\n",
            "Moving Avg Val Loss: 1.122980\n",
            "Epoch 553/2000, Train Loss: 0.002184, Val Loss: 0.049139\n",
            "Epoch 553/2000, Rel Train Loss: 86.32%, Rel Val Loss: 111.83%\n",
            "Moving Avg Val Loss: 0.970377\n",
            "Epoch 554/2000, Train Loss: 0.001715, Val Loss: 0.057084\n",
            "Epoch 554/2000, Rel Train Loss: 74.43%, Rel Val Loss: 69.32%\n",
            "Moving Avg Val Loss: 0.914902\n",
            "Epoch 555/2000, Train Loss: 0.004416, Val Loss: 0.053337\n",
            "Epoch 555/2000, Rel Train Loss: 76.09%, Rel Val Loss: 68.76%\n",
            "Moving Avg Val Loss: 0.985293\n",
            "Epoch 556/2000, Train Loss: 0.003917, Val Loss: 0.056818\n",
            "Epoch 556/2000, Rel Train Loss: 101.80%, Rel Val Loss: 160.96%\n",
            "Moving Avg Val Loss: 0.993432\n",
            "Epoch 557/2000, Train Loss: 0.008067, Val Loss: 0.051860\n",
            "Epoch 557/2000, Rel Train Loss: 116.89%, Rel Val Loss: 85.84%\n",
            "Moving Avg Val Loss: 0.903953\n",
            "Epoch 558/2000, Train Loss: 0.002125, Val Loss: 0.057257\n",
            "Epoch 558/2000, Rel Train Loss: 82.66%, Rel Val Loss: 67.10%\n",
            "Moving Avg Val Loss: 0.953474\n",
            "Epoch 559/2000, Train Loss: 0.002654, Val Loss: 0.051648\n",
            "Epoch 559/2000, Rel Train Loss: 71.73%, Rel Val Loss: 94.08%\n",
            "Moving Avg Val Loss: 0.975451\n",
            "Epoch 560/2000, Train Loss: 0.002619, Val Loss: 0.055123\n",
            "Epoch 560/2000, Rel Train Loss: 73.81%, Rel Val Loss: 79.75%\n",
            "Moving Avg Val Loss: 0.803827\n",
            "Epoch 561/2000, Train Loss: 0.002634, Val Loss: 0.050906\n",
            "Epoch 561/2000, Rel Train Loss: 70.62%, Rel Val Loss: 75.15%\n",
            "Moving Avg Val Loss: 0.757122\n",
            "Epoch 562/2000, Train Loss: 0.001621, Val Loss: 0.051543\n",
            "Epoch 562/2000, Rel Train Loss: 64.08%, Rel Val Loss: 62.48%\n",
            "Moving Avg Val Loss: 0.748487\n",
            "Epoch 563/2000, Train Loss: 0.001279, Val Loss: 0.053045\n",
            "Epoch 563/2000, Rel Train Loss: 52.68%, Rel Val Loss: 62.78%\n",
            "Moving Avg Val Loss: 0.738240\n",
            "Epoch 564/2000, Train Loss: 0.001999, Val Loss: 0.053748\n",
            "Epoch 564/2000, Rel Train Loss: 58.83%, Rel Val Loss: 88.96%\n",
            "Moving Avg Val Loss: 0.722695\n",
            "Epoch 565/2000, Train Loss: 0.002369, Val Loss: 0.055398\n",
            "Epoch 565/2000, Rel Train Loss: 68.29%, Rel Val Loss: 71.98%\n",
            "Moving Avg Val Loss: 0.787029\n",
            "Epoch 566/2000, Train Loss: 0.003142, Val Loss: 0.068840\n",
            "Epoch 566/2000, Rel Train Loss: 97.96%, Rel Val Loss: 107.32%\n",
            "Moving Avg Val Loss: 1.050419\n",
            "Epoch 567/2000, Train Loss: 0.008873, Val Loss: 0.055865\n",
            "Epoch 567/2000, Rel Train Loss: 133.20%, Rel Val Loss: 194.18%\n",
            "Moving Avg Val Loss: 1.105814\n",
            "Epoch 568/2000, Train Loss: 0.002985, Val Loss: 0.054569\n",
            "Epoch 568/2000, Rel Train Loss: 126.22%, Rel Val Loss: 90.48%\n",
            "Moving Avg Val Loss: 1.098270\n",
            "Epoch 569/2000, Train Loss: 0.001509, Val Loss: 0.051878\n",
            "Epoch 569/2000, Rel Train Loss: 73.26%, Rel Val Loss: 85.19%\n",
            "Moving Avg Val Loss: 1.080359\n",
            "Epoch 570/2000, Train Loss: 0.001222, Val Loss: 0.050640\n",
            "Epoch 570/2000, Rel Train Loss: 63.11%, Rel Val Loss: 63.02%\n",
            "Moving Avg Val Loss: 1.018544\n",
            "Epoch 571/2000, Train Loss: 0.002814, Val Loss: 0.054038\n",
            "Epoch 571/2000, Rel Train Loss: 80.79%, Rel Val Loss: 76.41%\n",
            "Moving Avg Val Loss: 0.812403\n",
            "Epoch 572/2000, Train Loss: 0.001640, Val Loss: 0.050378\n",
            "Epoch 572/2000, Rel Train Loss: 78.90%, Rel Val Loss: 91.11%\n",
            "Moving Avg Val Loss: 0.752497\n",
            "Epoch 573/2000, Train Loss: 0.001127, Val Loss: 0.052889\n",
            "Epoch 573/2000, Rel Train Loss: 55.01%, Rel Val Loss: 60.52%\n",
            "Moving Avg Val Loss: 0.701735\n",
            "Epoch 574/2000, Train Loss: 0.000941, Val Loss: 0.051393\n",
            "Epoch 574/2000, Rel Train Loss: 55.68%, Rel Val Loss: 59.81%\n",
            "Moving Avg Val Loss: 0.692460\n",
            "Epoch 575/2000, Train Loss: 0.000802, Val Loss: 0.052543\n",
            "Epoch 575/2000, Rel Train Loss: 53.79%, Rel Val Loss: 58.38%\n",
            "Moving Avg Val Loss: 0.664206\n",
            "Epoch 576/2000, Train Loss: 0.001411, Val Loss: 0.053108\n",
            "Epoch 576/2000, Rel Train Loss: 53.66%, Rel Val Loss: 62.28%\n",
            "Moving Avg Val Loss: 0.604629\n",
            "Epoch 577/2000, Train Loss: 0.002049, Val Loss: 0.048770\n",
            "Epoch 577/2000, Rel Train Loss: 61.76%, Rel Val Loss: 61.32%\n",
            "Moving Avg Val Loss: 0.616398\n",
            "Epoch 578/2000, Train Loss: 0.001855, Val Loss: 0.055747\n",
            "Epoch 578/2000, Rel Train Loss: 64.68%, Rel Val Loss: 66.41%\n",
            "Moving Avg Val Loss: 0.641232\n",
            "Epoch 579/2000, Train Loss: 0.001472, Val Loss: 0.047372\n",
            "Epoch 579/2000, Rel Train Loss: 61.46%, Rel Val Loss: 72.22%\n",
            "Moving Avg Val Loss: 0.684562\n",
            "Epoch 580/2000, Train Loss: 0.001405, Val Loss: 0.055789\n",
            "Epoch 580/2000, Rel Train Loss: 58.13%, Rel Val Loss: 80.05%\n",
            "Moving Avg Val Loss: 0.703512\n",
            "Epoch 581/2000, Train Loss: 0.002144, Val Loss: 0.053019\n",
            "Epoch 581/2000, Rel Train Loss: 70.49%, Rel Val Loss: 71.76%\n",
            "Moving Avg Val Loss: 0.704955\n",
            "Epoch 582/2000, Train Loss: 0.001602, Val Loss: 0.054537\n",
            "Epoch 582/2000, Rel Train Loss: 61.23%, Rel Val Loss: 62.04%\n",
            "Moving Avg Val Loss: 0.717567\n",
            "Epoch 583/2000, Train Loss: 0.001553, Val Loss: 0.054926\n",
            "Epoch 583/2000, Rel Train Loss: 53.58%, Rel Val Loss: 72.71%\n",
            "Moving Avg Val Loss: 0.751237\n",
            "Epoch 584/2000, Train Loss: 0.001825, Val Loss: 0.062592\n",
            "Epoch 584/2000, Rel Train Loss: 60.28%, Rel Val Loss: 89.06%\n",
            "Moving Avg Val Loss: 0.780761\n",
            "Epoch 585/2000, Train Loss: 0.011447, Val Loss: 0.069320\n",
            "Epoch 585/2000, Rel Train Loss: 142.80%, Rel Val Loss: 94.81%\n",
            "Moving Avg Val Loss: 0.897052\n",
            "Epoch 586/2000, Train Loss: 0.004901, Val Loss: 0.053736\n",
            "Epoch 586/2000, Rel Train Loss: 135.05%, Rel Val Loss: 129.90%\n",
            "Moving Avg Val Loss: 0.922172\n",
            "Epoch 587/2000, Train Loss: 0.003786, Val Loss: 0.059522\n",
            "Epoch 587/2000, Rel Train Loss: 70.78%, Rel Val Loss: 74.60%\n",
            "Moving Avg Val Loss: 0.919088\n",
            "Epoch 588/2000, Train Loss: 0.002022, Val Loss: 0.048949\n",
            "Epoch 588/2000, Rel Train Loss: 74.70%, Rel Val Loss: 71.17%\n",
            "Moving Avg Val Loss: 0.888950\n",
            "Epoch 589/2000, Train Loss: 0.001871, Val Loss: 0.061513\n",
            "Epoch 589/2000, Rel Train Loss: 74.97%, Rel Val Loss: 73.99%\n",
            "Moving Avg Val Loss: 0.871931\n",
            "Epoch 590/2000, Train Loss: 0.002972, Val Loss: 0.050078\n",
            "Epoch 590/2000, Rel Train Loss: 76.73%, Rel Val Loss: 86.30%\n",
            "Moving Avg Val Loss: 0.782053\n",
            "Epoch 591/2000, Train Loss: 0.001603, Val Loss: 0.053930\n",
            "Epoch 591/2000, Rel Train Loss: 77.51%, Rel Val Loss: 84.96%\n",
            "Moving Avg Val Loss: 0.758170\n",
            "Epoch 592/2000, Train Loss: 0.001551, Val Loss: 0.059606\n",
            "Epoch 592/2000, Rel Train Loss: 61.36%, Rel Val Loss: 62.66%\n",
            "Moving Avg Val Loss: 0.919395\n",
            "Epoch 593/2000, Train Loss: 0.005312, Val Loss: 0.061276\n",
            "Epoch 593/2000, Rel Train Loss: 83.45%, Rel Val Loss: 151.78%\n",
            "Moving Avg Val Loss: 0.933533\n",
            "Epoch 594/2000, Train Loss: 0.002703, Val Loss: 0.048720\n",
            "Epoch 594/2000, Rel Train Loss: 95.85%, Rel Val Loss: 81.06%\n",
            "Moving Avg Val Loss: 0.930626\n",
            "Epoch 595/2000, Train Loss: 0.001507, Val Loss: 0.052299\n",
            "Epoch 595/2000, Rel Train Loss: 68.50%, Rel Val Loss: 84.85%\n",
            "Moving Avg Val Loss: 0.897738\n",
            "Epoch 596/2000, Train Loss: 0.001428, Val Loss: 0.050935\n",
            "Epoch 596/2000, Rel Train Loss: 61.56%, Rel Val Loss: 68.52%\n",
            "Moving Avg Val Loss: 0.896203\n",
            "Epoch 597/2000, Train Loss: 0.002464, Val Loss: 0.056635\n",
            "Epoch 597/2000, Rel Train Loss: 56.70%, Rel Val Loss: 61.89%\n",
            "Moving Avg Val Loss: 0.707369\n",
            "Epoch 598/2000, Train Loss: 0.001481, Val Loss: 0.049289\n",
            "Epoch 598/2000, Rel Train Loss: 55.98%, Rel Val Loss: 57.37%\n",
            "Moving Avg Val Loss: 0.670648\n",
            "Epoch 599/2000, Train Loss: 0.000888, Val Loss: 0.051627\n",
            "Epoch 599/2000, Rel Train Loss: 49.98%, Rel Val Loss: 62.70%\n",
            "Moving Avg Val Loss: 0.634401\n",
            "Epoch 600/2000, Train Loss: 0.000917, Val Loss: 0.049150\n",
            "Epoch 600/2000, Rel Train Loss: 50.95%, Rel Val Loss: 66.72%\n",
            "Moving Avg Val Loss: 0.616404\n",
            "Epoch 601/2000, Train Loss: 0.000898, Val Loss: 0.053363\n",
            "Epoch 601/2000, Rel Train Loss: 50.65%, Rel Val Loss: 59.52%\n",
            "Moving Avg Val Loss: 0.610275\n",
            "Epoch 602/2000, Train Loss: 0.001131, Val Loss: 0.052065\n",
            "Epoch 602/2000, Rel Train Loss: 51.70%, Rel Val Loss: 58.83%\n",
            "Moving Avg Val Loss: 0.626133\n",
            "Epoch 603/2000, Train Loss: 0.001298, Val Loss: 0.051830\n",
            "Epoch 603/2000, Rel Train Loss: 55.96%, Rel Val Loss: 65.30%\n",
            "Moving Avg Val Loss: 0.625786\n",
            "Epoch 604/2000, Train Loss: 0.001573, Val Loss: 0.055870\n",
            "Epoch 604/2000, Rel Train Loss: 55.11%, Rel Val Loss: 62.52%\n",
            "Moving Avg Val Loss: 0.652289\n",
            "Epoch 605/2000, Train Loss: 0.001832, Val Loss: 0.050543\n",
            "Epoch 605/2000, Rel Train Loss: 73.06%, Rel Val Loss: 79.98%\n",
            "Moving Avg Val Loss: 0.660060\n",
            "Epoch 606/2000, Train Loss: 0.001340, Val Loss: 0.053527\n",
            "Epoch 606/2000, Rel Train Loss: 57.56%, Rel Val Loss: 63.41%\n",
            "Moving Avg Val Loss: 0.698686\n",
            "Epoch 607/2000, Train Loss: 0.002250, Val Loss: 0.054309\n",
            "Epoch 607/2000, Rel Train Loss: 60.23%, Rel Val Loss: 78.14%\n",
            "Moving Avg Val Loss: 0.794824\n",
            "Epoch 608/2000, Train Loss: 0.001744, Val Loss: 0.057105\n",
            "Epoch 608/2000, Rel Train Loss: 68.56%, Rel Val Loss: 113.36%\n",
            "Moving Avg Val Loss: 0.859865\n",
            "Epoch 609/2000, Train Loss: 0.003215, Val Loss: 0.056112\n",
            "Epoch 609/2000, Rel Train Loss: 82.15%, Rel Val Loss: 95.04%\n",
            "Moving Avg Val Loss: 0.855649\n",
            "Epoch 610/2000, Train Loss: 0.001406, Val Loss: 0.049663\n",
            "Epoch 610/2000, Rel Train Loss: 69.44%, Rel Val Loss: 77.87%\n",
            "Moving Avg Val Loss: 0.843245\n",
            "Epoch 611/2000, Train Loss: 0.000895, Val Loss: 0.050730\n",
            "Epoch 611/2000, Rel Train Loss: 49.86%, Rel Val Loss: 57.20%\n",
            "Moving Avg Val Loss: 0.804837\n",
            "Epoch 612/2000, Train Loss: 0.000721, Val Loss: 0.050235\n",
            "Epoch 612/2000, Rel Train Loss: 47.27%, Rel Val Loss: 58.94%\n",
            "Moving Avg Val Loss: 0.692373\n",
            "Epoch 613/2000, Train Loss: 0.000687, Val Loss: 0.051047\n",
            "Epoch 613/2000, Rel Train Loss: 45.62%, Rel Val Loss: 57.13%\n",
            "Moving Avg Val Loss: 0.645770\n",
            "Epoch 614/2000, Train Loss: 0.000824, Val Loss: 0.051879\n",
            "Epoch 614/2000, Rel Train Loss: 52.24%, Rel Val Loss: 71.74%\n",
            "Moving Avg Val Loss: 0.605134\n",
            "Epoch 615/2000, Train Loss: 0.000892, Val Loss: 0.052333\n",
            "Epoch 615/2000, Rel Train Loss: 52.48%, Rel Val Loss: 57.55%\n",
            "Moving Avg Val Loss: 0.603489\n",
            "Epoch 616/2000, Train Loss: 0.000717, Val Loss: 0.050658\n",
            "Epoch 616/2000, Rel Train Loss: 48.28%, Rel Val Loss: 56.38%\n",
            "Moving Avg Val Loss: 0.600455\n",
            "Epoch 617/2000, Train Loss: 0.000847, Val Loss: 0.050116\n",
            "Epoch 617/2000, Rel Train Loss: 49.66%, Rel Val Loss: 57.42%\n",
            "Moving Avg Val Loss: 0.692100\n",
            "Epoch 618/2000, Train Loss: 0.002789, Val Loss: 0.053659\n",
            "Epoch 618/2000, Rel Train Loss: 63.17%, Rel Val Loss: 102.95%\n",
            "Moving Avg Val Loss: 0.670685\n",
            "Epoch 619/2000, Train Loss: 0.001958, Val Loss: 0.053472\n",
            "Epoch 619/2000, Rel Train Loss: 67.76%, Rel Val Loss: 61.04%\n",
            "Moving Avg Val Loss: 0.674940\n",
            "Epoch 620/2000, Train Loss: 0.001411, Val Loss: 0.053688\n",
            "Epoch 620/2000, Rel Train Loss: 51.49%, Rel Val Loss: 59.68%\n",
            "Moving Avg Val Loss: 0.682562\n",
            "Epoch 621/2000, Train Loss: 0.002282, Val Loss: 0.052801\n",
            "Epoch 621/2000, Rel Train Loss: 69.03%, Rel Val Loss: 60.19%\n",
            "Moving Avg Val Loss: 0.684078\n",
            "Epoch 622/2000, Train Loss: 0.001751, Val Loss: 0.055396\n",
            "Epoch 622/2000, Rel Train Loss: 58.55%, Rel Val Loss: 58.18%\n",
            "Moving Avg Val Loss: 0.619783\n",
            "Epoch 623/2000, Train Loss: 0.000937, Val Loss: 0.049851\n",
            "Epoch 623/2000, Rel Train Loss: 55.74%, Rel Val Loss: 70.81%\n",
            "Moving Avg Val Loss: 0.619337\n",
            "Epoch 624/2000, Train Loss: 0.000871, Val Loss: 0.051739\n",
            "Epoch 624/2000, Rel Train Loss: 48.42%, Rel Val Loss: 60.81%\n",
            "Moving Avg Val Loss: 0.633155\n",
            "Epoch 625/2000, Train Loss: 0.000743, Val Loss: 0.048894\n",
            "Epoch 625/2000, Rel Train Loss: 51.81%, Rel Val Loss: 66.59%\n",
            "Moving Avg Val Loss: 0.631319\n",
            "Epoch 626/2000, Train Loss: 0.000758, Val Loss: 0.052008\n",
            "Epoch 626/2000, Rel Train Loss: 48.62%, Rel Val Loss: 59.28%\n",
            "Moving Avg Val Loss: 0.627498\n",
            "Epoch 627/2000, Train Loss: 0.000801, Val Loss: 0.050392\n",
            "Epoch 627/2000, Rel Train Loss: 49.20%, Rel Val Loss: 56.27%\n",
            "Moving Avg Val Loss: 0.646294\n",
            "Epoch 628/2000, Train Loss: 0.001836, Val Loss: 0.052719\n",
            "Epoch 628/2000, Rel Train Loss: 53.07%, Rel Val Loss: 80.20%\n",
            "Moving Avg Val Loss: 0.725724\n",
            "Epoch 629/2000, Train Loss: 0.001212, Val Loss: 0.051760\n",
            "Epoch 629/2000, Rel Train Loss: 72.11%, Rel Val Loss: 100.53%\n",
            "Moving Avg Val Loss: 0.709026\n",
            "Epoch 630/2000, Train Loss: 0.000986, Val Loss: 0.052609\n",
            "Epoch 630/2000, Rel Train Loss: 56.81%, Rel Val Loss: 58.24%\n",
            "Moving Avg Val Loss: 0.719855\n",
            "Epoch 631/2000, Train Loss: 0.001209, Val Loss: 0.052424\n",
            "Epoch 631/2000, Rel Train Loss: 55.52%, Rel Val Loss: 64.69%\n",
            "Moving Avg Val Loss: 0.724598\n",
            "Epoch 632/2000, Train Loss: 0.000833, Val Loss: 0.052134\n",
            "Epoch 632/2000, Rel Train Loss: 53.00%, Rel Val Loss: 58.64%\n",
            "Moving Avg Val Loss: 0.682580\n",
            "Epoch 633/2000, Train Loss: 0.000720, Val Loss: 0.050552\n",
            "Epoch 633/2000, Rel Train Loss: 49.76%, Rel Val Loss: 59.20%\n",
            "Moving Avg Val Loss: 0.592922\n",
            "Epoch 634/2000, Train Loss: 0.000777, Val Loss: 0.050469\n",
            "Epoch 634/2000, Rel Train Loss: 48.66%, Rel Val Loss: 55.70%\n",
            "Moving Avg Val Loss: 0.626092\n",
            "Epoch 635/2000, Train Loss: 0.001037, Val Loss: 0.049915\n",
            "Epoch 635/2000, Rel Train Loss: 55.55%, Rel Val Loss: 74.82%\n",
            "Moving Avg Val Loss: 0.620818\n",
            "Epoch 636/2000, Train Loss: 0.000858, Val Loss: 0.054158\n",
            "Epoch 636/2000, Rel Train Loss: 51.79%, Rel Val Loss: 62.05%\n",
            "Moving Avg Val Loss: 0.622620\n",
            "Epoch 637/2000, Train Loss: 0.000786, Val Loss: 0.049706\n",
            "Epoch 637/2000, Rel Train Loss: 52.24%, Rel Val Loss: 59.54%\n",
            "Moving Avg Val Loss: 0.625400\n",
            "Epoch 638/2000, Train Loss: 0.000789, Val Loss: 0.051395\n",
            "Epoch 638/2000, Rel Train Loss: 47.91%, Rel Val Loss: 60.59%\n",
            "Moving Avg Val Loss: 0.625563\n",
            "Epoch 639/2000, Train Loss: 0.000792, Val Loss: 0.048669\n",
            "Epoch 639/2000, Rel Train Loss: 50.91%, Rel Val Loss: 55.78%\n",
            "Moving Avg Val Loss: 0.591477\n",
            "Epoch 640/2000, Train Loss: 0.000753, Val Loss: 0.052290\n",
            "Epoch 640/2000, Rel Train Loss: 53.29%, Rel Val Loss: 57.78%\n",
            "Moving Avg Val Loss: 0.583349\n",
            "Epoch 641/2000, Train Loss: 0.001331, Val Loss: 0.054955\n",
            "Epoch 641/2000, Rel Train Loss: 53.30%, Rel Val Loss: 57.99%\n",
            "Moving Avg Val Loss: 0.588506\n",
            "Epoch 642/2000, Train Loss: 0.001179, Val Loss: 0.046601\n",
            "Epoch 642/2000, Rel Train Loss: 55.97%, Rel Val Loss: 62.12%\n",
            "Moving Avg Val Loss: 0.602705\n",
            "Epoch 643/2000, Train Loss: 0.001362, Val Loss: 0.059734\n",
            "Epoch 643/2000, Rel Train Loss: 55.38%, Rel Val Loss: 67.69%\n",
            "Moving Avg Val Loss: 0.616654\n",
            "Epoch 644/2000, Train Loss: 0.001941, Val Loss: 0.048144\n",
            "Epoch 644/2000, Rel Train Loss: 58.55%, Rel Val Loss: 62.75%\n",
            "Moving Avg Val Loss: 0.622561\n",
            "Epoch 645/2000, Train Loss: 0.002821, Val Loss: 0.057580\n",
            "Epoch 645/2000, Rel Train Loss: 62.05%, Rel Val Loss: 60.73%\n",
            "Moving Avg Val Loss: 0.625503\n",
            "Epoch 646/2000, Train Loss: 0.002546, Val Loss: 0.047826\n",
            "Epoch 646/2000, Rel Train Loss: 87.36%, Rel Val Loss: 59.46%\n",
            "Moving Avg Val Loss: 0.624612\n",
            "Epoch 647/2000, Train Loss: 0.001889, Val Loss: 0.060260\n",
            "Epoch 647/2000, Rel Train Loss: 102.08%, Rel Val Loss: 61.67%\n",
            "Moving Avg Val Loss: 0.608244\n",
            "Epoch 648/2000, Train Loss: 0.003675, Val Loss: 0.059385\n",
            "Epoch 648/2000, Rel Train Loss: 64.72%, Rel Val Loss: 59.50%\n",
            "Moving Avg Val Loss: 1.048297\n",
            "Epoch 649/2000, Train Loss: 0.007210, Val Loss: 0.059121\n",
            "Epoch 649/2000, Rel Train Loss: 114.18%, Rel Val Loss: 282.78%\n",
            "Moving Avg Val Loss: 1.108600\n",
            "Epoch 650/2000, Train Loss: 0.008011, Val Loss: 0.050159\n",
            "Epoch 650/2000, Rel Train Loss: 189.76%, Rel Val Loss: 90.88%\n",
            "Moving Avg Val Loss: 1.241610\n",
            "Epoch 651/2000, Train Loss: 0.004510, Val Loss: 0.057633\n",
            "Epoch 651/2000, Rel Train Loss: 169.54%, Rel Val Loss: 125.97%\n",
            "Moving Avg Val Loss: 1.253719\n",
            "Epoch 652/2000, Train Loss: 0.002637, Val Loss: 0.048995\n",
            "Epoch 652/2000, Rel Train Loss: 93.79%, Rel Val Loss: 67.73%\n",
            "Moving Avg Val Loss: 1.267926\n",
            "Epoch 653/2000, Train Loss: 0.001281, Val Loss: 0.050481\n",
            "Epoch 653/2000, Rel Train Loss: 77.18%, Rel Val Loss: 66.60%\n",
            "Moving Avg Val Loss: 0.836003\n",
            "Epoch 654/2000, Train Loss: 0.001194, Val Loss: 0.048233\n",
            "Epoch 654/2000, Rel Train Loss: 62.64%, Rel Val Loss: 66.82%\n",
            "Moving Avg Val Loss: 0.800868\n",
            "Epoch 655/2000, Train Loss: 0.001512, Val Loss: 0.049607\n",
            "Epoch 655/2000, Rel Train Loss: 51.17%, Rel Val Loss: 73.32%\n",
            "Moving Avg Val Loss: 0.680511\n",
            "Epoch 656/2000, Train Loss: 0.002976, Val Loss: 0.052317\n",
            "Epoch 656/2000, Rel Train Loss: 67.45%, Rel Val Loss: 65.79%\n",
            "Moving Avg Val Loss: 0.658522\n",
            "Epoch 657/2000, Train Loss: 0.000912, Val Loss: 0.047954\n",
            "Epoch 657/2000, Rel Train Loss: 56.37%, Rel Val Loss: 56.73%\n",
            "Moving Avg Val Loss: 0.641269\n",
            "Epoch 658/2000, Train Loss: 0.000805, Val Loss: 0.048584\n",
            "Epoch 658/2000, Rel Train Loss: 46.81%, Rel Val Loss: 57.98%\n",
            "Moving Avg Val Loss: 0.619374\n",
            "Epoch 659/2000, Train Loss: 0.000846, Val Loss: 0.049606\n",
            "Epoch 659/2000, Rel Train Loss: 50.21%, Rel Val Loss: 55.87%\n",
            "Moving Avg Val Loss: 0.582244\n",
            "Epoch 660/2000, Train Loss: 0.001201, Val Loss: 0.047577\n",
            "Epoch 660/2000, Rel Train Loss: 52.81%, Rel Val Loss: 54.75%\n",
            "Moving Avg Val Loss: 0.558992\n",
            "Epoch 661/2000, Train Loss: 0.000755, Val Loss: 0.050352\n",
            "Epoch 661/2000, Rel Train Loss: 47.99%, Rel Val Loss: 54.16%\n",
            "Moving Avg Val Loss: 0.577128\n",
            "Epoch 662/2000, Train Loss: 0.000768, Val Loss: 0.048440\n",
            "Epoch 662/2000, Rel Train Loss: 48.80%, Rel Val Loss: 65.80%\n",
            "Moving Avg Val Loss: 0.571404\n",
            "Epoch 663/2000, Train Loss: 0.000741, Val Loss: 0.049145\n",
            "Epoch 663/2000, Rel Train Loss: 44.57%, Rel Val Loss: 55.12%\n",
            "Moving Avg Val Loss: 0.569391\n",
            "Epoch 664/2000, Train Loss: 0.000663, Val Loss: 0.048768\n",
            "Epoch 664/2000, Rel Train Loss: 45.17%, Rel Val Loss: 54.87%\n",
            "Moving Avg Val Loss: 0.565140\n",
            "Epoch 665/2000, Train Loss: 0.000865, Val Loss: 0.048388\n",
            "Epoch 665/2000, Rel Train Loss: 53.60%, Rel Val Loss: 52.63%\n",
            "Moving Avg Val Loss: 0.562374\n",
            "Epoch 666/2000, Train Loss: 0.000994, Val Loss: 0.051882\n",
            "Epoch 666/2000, Rel Train Loss: 44.96%, Rel Val Loss: 52.78%\n",
            "Moving Avg Val Loss: 0.623342\n",
            "Epoch 667/2000, Train Loss: 0.001550, Val Loss: 0.047236\n",
            "Epoch 667/2000, Rel Train Loss: 60.54%, Rel Val Loss: 96.28%\n",
            "Moving Avg Val Loss: 0.634623\n",
            "Epoch 668/2000, Train Loss: 0.001099, Val Loss: 0.053102\n",
            "Epoch 668/2000, Rel Train Loss: 64.41%, Rel Val Loss: 60.76%\n",
            "Moving Avg Val Loss: 0.652991\n",
            "Epoch 669/2000, Train Loss: 0.000961, Val Loss: 0.051816\n",
            "Epoch 669/2000, Rel Train Loss: 62.17%, Rel Val Loss: 64.05%\n",
            "Moving Avg Val Loss: 0.658292\n",
            "Epoch 670/2000, Train Loss: 0.002340, Val Loss: 0.053794\n",
            "Epoch 670/2000, Rel Train Loss: 84.74%, Rel Val Loss: 55.28%\n",
            "Moving Avg Val Loss: 0.724960\n",
            "Epoch 671/2000, Train Loss: 0.001958, Val Loss: 0.054253\n",
            "Epoch 671/2000, Rel Train Loss: 68.40%, Rel Val Loss: 86.11%\n",
            "Moving Avg Val Loss: 0.645420\n",
            "Epoch 672/2000, Train Loss: 0.001583, Val Loss: 0.051801\n",
            "Epoch 672/2000, Rel Train Loss: 65.87%, Rel Val Loss: 56.52%\n",
            "Moving Avg Val Loss: 0.634162\n",
            "Epoch 673/2000, Train Loss: 0.001295, Val Loss: 0.050430\n",
            "Epoch 673/2000, Rel Train Loss: 50.20%, Rel Val Loss: 55.13%\n",
            "Moving Avg Val Loss: 0.612351\n",
            "Epoch 674/2000, Train Loss: 0.001106, Val Loss: 0.049746\n",
            "Epoch 674/2000, Rel Train Loss: 62.19%, Rel Val Loss: 53.14%\n",
            "Moving Avg Val Loss: 0.621987\n",
            "Epoch 675/2000, Train Loss: 0.001034, Val Loss: 0.049674\n",
            "Epoch 675/2000, Rel Train Loss: 50.42%, Rel Val Loss: 60.10%\n",
            "Moving Avg Val Loss: 0.573175\n",
            "Epoch 676/2000, Train Loss: 0.001951, Val Loss: 0.050937\n",
            "Epoch 676/2000, Rel Train Loss: 70.90%, Rel Val Loss: 61.71%\n",
            "Moving Avg Val Loss: 0.568229\n",
            "Epoch 677/2000, Train Loss: 0.001173, Val Loss: 0.047588\n",
            "Epoch 677/2000, Rel Train Loss: 57.70%, Rel Val Loss: 54.04%\n",
            "Moving Avg Val Loss: 0.572929\n",
            "Epoch 678/2000, Train Loss: 0.001755, Val Loss: 0.055499\n",
            "Epoch 678/2000, Rel Train Loss: 59.79%, Rel Val Loss: 57.48%\n",
            "Moving Avg Val Loss: 0.595831\n",
            "Epoch 679/2000, Train Loss: 0.001330, Val Loss: 0.046706\n",
            "Epoch 679/2000, Rel Train Loss: 57.77%, Rel Val Loss: 64.59%\n",
            "Moving Avg Val Loss: 0.587397\n",
            "Epoch 680/2000, Train Loss: 0.000904, Val Loss: 0.052832\n",
            "Epoch 680/2000, Rel Train Loss: 51.99%, Rel Val Loss: 55.88%\n",
            "Moving Avg Val Loss: 0.570940\n",
            "Epoch 681/2000, Train Loss: 0.000718, Val Loss: 0.049363\n",
            "Epoch 681/2000, Rel Train Loss: 46.38%, Rel Val Loss: 53.48%\n",
            "Moving Avg Val Loss: 0.643697\n",
            "Epoch 682/2000, Train Loss: 0.001286, Val Loss: 0.049495\n",
            "Epoch 682/2000, Rel Train Loss: 51.30%, Rel Val Loss: 90.42%\n",
            "Moving Avg Val Loss: 0.641826\n",
            "Epoch 683/2000, Train Loss: 0.000920, Val Loss: 0.050345\n",
            "Epoch 683/2000, Rel Train Loss: 58.70%, Rel Val Loss: 56.54%\n",
            "Moving Avg Val Loss: 0.632617\n",
            "Epoch 684/2000, Train Loss: 0.000770, Val Loss: 0.046900\n",
            "Epoch 684/2000, Rel Train Loss: 55.69%, Rel Val Loss: 59.99%\n",
            "Moving Avg Val Loss: 0.627832\n",
            "Epoch 685/2000, Train Loss: 0.000640, Val Loss: 0.049955\n",
            "Epoch 685/2000, Rel Train Loss: 54.47%, Rel Val Loss: 53.49%\n",
            "Moving Avg Val Loss: 0.628006\n",
            "Epoch 686/2000, Train Loss: 0.000597, Val Loss: 0.049509\n",
            "Epoch 686/2000, Rel Train Loss: 44.57%, Rel Val Loss: 53.56%\n",
            "Moving Avg Val Loss: 0.555687\n",
            "Epoch 687/2000, Train Loss: 0.000646, Val Loss: 0.048888\n",
            "Epoch 687/2000, Rel Train Loss: 43.48%, Rel Val Loss: 54.26%\n",
            "Moving Avg Val Loss: 0.548236\n",
            "Epoch 688/2000, Train Loss: 0.000772, Val Loss: 0.049974\n",
            "Epoch 688/2000, Rel Train Loss: 50.30%, Rel Val Loss: 52.82%\n",
            "Moving Avg Val Loss: 0.531803\n",
            "Epoch 689/2000, Train Loss: 0.000635, Val Loss: 0.050961\n",
            "Epoch 689/2000, Rel Train Loss: 43.44%, Rel Val Loss: 51.77%\n",
            "Moving Avg Val Loss: 0.538569\n",
            "Epoch 690/2000, Train Loss: 0.000966, Val Loss: 0.052384\n",
            "Epoch 690/2000, Rel Train Loss: 50.09%, Rel Val Loss: 56.87%\n",
            "Moving Avg Val Loss: 0.649340\n",
            "Epoch 691/2000, Train Loss: 0.004021, Val Loss: 0.058458\n",
            "Epoch 691/2000, Rel Train Loss: 101.63%, Rel Val Loss: 108.95%\n",
            "Moving Avg Val Loss: 0.723093\n",
            "Epoch 692/2000, Train Loss: 0.002614, Val Loss: 0.054592\n",
            "Epoch 692/2000, Rel Train Loss: 93.11%, Rel Val Loss: 91.14%\n",
            "Moving Avg Val Loss: 0.743457\n",
            "Epoch 693/2000, Train Loss: 0.001729, Val Loss: 0.048506\n",
            "Epoch 693/2000, Rel Train Loss: 54.50%, Rel Val Loss: 63.00%\n",
            "Moving Avg Val Loss: 0.756130\n",
            "Epoch 694/2000, Train Loss: 0.001102, Val Loss: 0.053779\n",
            "Epoch 694/2000, Rel Train Loss: 64.21%, Rel Val Loss: 58.11%\n",
            "Moving Avg Val Loss: 0.780722\n",
            "Epoch 695/2000, Train Loss: 0.001438, Val Loss: 0.048927\n",
            "Epoch 695/2000, Rel Train Loss: 50.08%, Rel Val Loss: 69.16%\n",
            "Moving Avg Val Loss: 0.709592\n",
            "Epoch 696/2000, Train Loss: 0.002338, Val Loss: 0.052696\n",
            "Epoch 696/2000, Rel Train Loss: 83.86%, Rel Val Loss: 73.38%\n",
            "Moving Avg Val Loss: 0.677283\n",
            "Epoch 697/2000, Train Loss: 0.001400, Val Loss: 0.047477\n",
            "Epoch 697/2000, Rel Train Loss: 66.27%, Rel Val Loss: 74.98%\n",
            "Moving Avg Val Loss: 0.664317\n",
            "Epoch 698/2000, Train Loss: 0.002679, Val Loss: 0.055840\n",
            "Epoch 698/2000, Rel Train Loss: 77.34%, Rel Val Loss: 56.52%\n",
            "Moving Avg Val Loss: 0.716610\n",
            "Epoch 699/2000, Train Loss: 0.006482, Val Loss: 0.052878\n",
            "Epoch 699/2000, Rel Train Loss: 73.68%, Rel Val Loss: 84.26%\n",
            "Moving Avg Val Loss: 0.745800\n",
            "Epoch 700/2000, Train Loss: 0.002448, Val Loss: 0.054104\n",
            "Epoch 700/2000, Rel Train Loss: 64.44%, Rel Val Loss: 83.76%\n",
            "Moving Avg Val Loss: 0.825699\n",
            "Epoch 701/2000, Train Loss: 0.006284, Val Loss: 0.055568\n",
            "Epoch 701/2000, Rel Train Loss: 109.09%, Rel Val Loss: 113.33%\n",
            "Moving Avg Val Loss: 0.801938\n",
            "Epoch 702/2000, Train Loss: 0.002365, Val Loss: 0.063561\n",
            "Epoch 702/2000, Rel Train Loss: 92.83%, Rel Val Loss: 63.10%\n",
            "Moving Avg Val Loss: 0.848277\n",
            "Epoch 703/2000, Train Loss: 0.006709, Val Loss: 0.051122\n",
            "Epoch 703/2000, Rel Train Loss: 77.74%, Rel Val Loss: 79.68%\n",
            "Moving Avg Val Loss: 0.801507\n",
            "Epoch 704/2000, Train Loss: 0.001226, Val Loss: 0.049002\n",
            "Epoch 704/2000, Rel Train Loss: 50.14%, Rel Val Loss: 60.87%\n",
            "Moving Avg Val Loss: 0.741196\n",
            "Epoch 705/2000, Train Loss: 0.000784, Val Loss: 0.045835\n",
            "Epoch 705/2000, Rel Train Loss: 45.16%, Rel Val Loss: 53.60%\n",
            "Moving Avg Val Loss: 0.621655\n",
            "Epoch 706/2000, Train Loss: 0.000791, Val Loss: 0.049987\n",
            "Epoch 706/2000, Rel Train Loss: 46.48%, Rel Val Loss: 53.56%\n",
            "Moving Avg Val Loss: 0.598466\n",
            "Epoch 707/2000, Train Loss: 0.000709, Val Loss: 0.047823\n",
            "Epoch 707/2000, Rel Train Loss: 46.93%, Rel Val Loss: 51.51%\n",
            "Moving Avg Val Loss: 0.543760\n",
            "Epoch 708/2000, Train Loss: 0.000680, Val Loss: 0.048797\n",
            "Epoch 708/2000, Rel Train Loss: 44.42%, Rel Val Loss: 52.33%\n",
            "Moving Avg Val Loss: 0.543030\n",
            "Epoch 709/2000, Train Loss: 0.000588, Val Loss: 0.049010\n",
            "Epoch 709/2000, Rel Train Loss: 45.36%, Rel Val Loss: 60.51%\n",
            "Moving Avg Val Loss: 0.545056\n",
            "Epoch 710/2000, Train Loss: 0.000732, Val Loss: 0.049977\n",
            "Epoch 710/2000, Rel Train Loss: 43.81%, Rel Val Loss: 54.62%\n",
            "Moving Avg Val Loss: 0.546151\n",
            "Epoch 711/2000, Train Loss: 0.001476, Val Loss: 0.049128\n",
            "Epoch 711/2000, Rel Train Loss: 46.66%, Rel Val Loss: 54.11%\n",
            "Moving Avg Val Loss: 0.550663\n",
            "Epoch 712/2000, Train Loss: 0.004848, Val Loss: 0.058694\n",
            "Epoch 712/2000, Rel Train Loss: 64.50%, Rel Val Loss: 53.76%\n",
            "Moving Avg Val Loss: 0.550676\n",
            "Epoch 713/2000, Train Loss: 0.002684, Val Loss: 0.048986\n",
            "Epoch 713/2000, Rel Train Loss: 91.85%, Rel Val Loss: 52.34%\n",
            "Moving Avg Val Loss: 0.543129\n",
            "Epoch 714/2000, Train Loss: 0.002829, Val Loss: 0.046790\n",
            "Epoch 714/2000, Rel Train Loss: 71.89%, Rel Val Loss: 56.73%\n",
            "Moving Avg Val Loss: 0.776424\n",
            "Epoch 715/2000, Train Loss: 0.007589, Val Loss: 0.067443\n",
            "Epoch 715/2000, Rel Train Loss: 94.53%, Rel Val Loss: 171.26%\n",
            "Moving Avg Val Loss: 0.844924\n",
            "Epoch 716/2000, Train Loss: 0.006252, Val Loss: 0.060030\n",
            "Epoch 716/2000, Rel Train Loss: 178.21%, Rel Val Loss: 88.36%\n",
            "Moving Avg Val Loss: 1.364334\n",
            "Epoch 717/2000, Train Loss: 0.010655, Val Loss: 0.075877\n",
            "Epoch 717/2000, Rel Train Loss: 207.18%, Rel Val Loss: 313.47%\n",
            "Moving Avg Val Loss: 1.918006\n",
            "Epoch 718/2000, Train Loss: 0.013076, Val Loss: 0.059397\n",
            "Epoch 718/2000, Rel Train Loss: 259.09%, Rel Val Loss: 329.17%\n",
            "Moving Avg Val Loss: 2.040321\n",
            "Epoch 719/2000, Train Loss: 0.004764, Val Loss: 0.055609\n",
            "Epoch 719/2000, Rel Train Loss: 167.14%, Rel Val Loss: 117.89%\n",
            "Moving Avg Val Loss: 1.802135\n",
            "Epoch 720/2000, Train Loss: 0.001950, Val Loss: 0.047665\n",
            "Epoch 720/2000, Rel Train Loss: 66.59%, Rel Val Loss: 52.17%\n",
            "Moving Avg Val Loss: 1.755885\n",
            "Epoch 721/2000, Train Loss: 0.002443, Val Loss: 0.045181\n",
            "Epoch 721/2000, Rel Train Loss: 65.54%, Rel Val Loss: 65.24%\n",
            "Moving Avg Val Loss: 1.249260\n",
            "Epoch 722/2000, Train Loss: 0.001824, Val Loss: 0.062328\n",
            "Epoch 722/2000, Rel Train Loss: 58.55%, Rel Val Loss: 60.16%\n",
            "Moving Avg Val Loss: 0.733799\n",
            "Epoch 723/2000, Train Loss: 0.005811, Val Loss: 0.047037\n",
            "Epoch 723/2000, Rel Train Loss: 67.95%, Rel Val Loss: 71.44%\n",
            "Moving Avg Val Loss: 0.609418\n",
            "Epoch 724/2000, Train Loss: 0.003773, Val Loss: 0.054685\n",
            "Epoch 724/2000, Rel Train Loss: 66.39%, Rel Val Loss: 55.70%\n",
            "Moving Avg Val Loss: 0.607472\n",
            "Epoch 725/2000, Train Loss: 0.002431, Val Loss: 0.047289\n",
            "Epoch 725/2000, Rel Train Loss: 49.94%, Rel Val Loss: 51.20%\n",
            "Moving Avg Val Loss: 0.613327\n",
            "Epoch 726/2000, Train Loss: 0.002460, Val Loss: 0.050611\n",
            "Epoch 726/2000, Rel Train Loss: 70.23%, Rel Val Loss: 68.16%\n",
            "Moving Avg Val Loss: 0.661640\n",
            "Epoch 727/2000, Train Loss: 0.003867, Val Loss: 0.047039\n",
            "Epoch 727/2000, Rel Train Loss: 69.92%, Rel Val Loss: 84.31%\n",
            "Moving Avg Val Loss: 0.621656\n",
            "Epoch 728/2000, Train Loss: 0.001621, Val Loss: 0.048626\n",
            "Epoch 728/2000, Rel Train Loss: 56.22%, Rel Val Loss: 51.45%\n",
            "Moving Avg Val Loss: 0.612000\n",
            "Epoch 729/2000, Train Loss: 0.001477, Val Loss: 0.043532\n",
            "Epoch 729/2000, Rel Train Loss: 55.13%, Rel Val Loss: 50.87%\n",
            "Moving Avg Val Loss: 0.640097\n",
            "Epoch 730/2000, Train Loss: 0.001501, Val Loss: 0.054159\n",
            "Epoch 730/2000, Rel Train Loss: 51.77%, Rel Val Loss: 65.25%\n",
            "Moving Avg Val Loss: 0.721520\n",
            "Epoch 731/2000, Train Loss: 0.002284, Val Loss: 0.060920\n",
            "Epoch 731/2000, Rel Train Loss: 62.69%, Rel Val Loss: 108.88%\n",
            "Moving Avg Val Loss: 0.679824\n",
            "Epoch 732/2000, Train Loss: 0.006117, Val Loss: 0.047457\n",
            "Epoch 732/2000, Rel Train Loss: 84.66%, Rel Val Loss: 63.47%\n",
            "Moving Avg Val Loss: 0.704410\n",
            "Epoch 733/2000, Train Loss: 0.003300, Val Loss: 0.054093\n",
            "Epoch 733/2000, Rel Train Loss: 78.33%, Rel Val Loss: 63.75%\n",
            "Moving Avg Val Loss: 0.713258\n",
            "Epoch 734/2000, Train Loss: 0.001511, Val Loss: 0.044376\n",
            "Epoch 734/2000, Rel Train Loss: 58.45%, Rel Val Loss: 55.29%\n",
            "Moving Avg Val Loss: 0.704274\n",
            "Epoch 735/2000, Train Loss: 0.001467, Val Loss: 0.054096\n",
            "Epoch 735/2000, Rel Train Loss: 50.92%, Rel Val Loss: 60.76%\n",
            "Moving Avg Val Loss: 0.638193\n",
            "Epoch 736/2000, Train Loss: 0.003501, Val Loss: 0.046956\n",
            "Epoch 736/2000, Rel Train Loss: 61.81%, Rel Val Loss: 75.84%\n",
            "Moving Avg Val Loss: 0.661301\n",
            "Epoch 737/2000, Train Loss: 0.009450, Val Loss: 0.056001\n",
            "Epoch 737/2000, Rel Train Loss: 77.39%, Rel Val Loss: 75.02%\n",
            "Moving Avg Val Loss: 0.687160\n",
            "Epoch 738/2000, Train Loss: 0.002824, Val Loss: 0.049046\n",
            "Epoch 738/2000, Rel Train Loss: 95.19%, Rel Val Loss: 76.67%\n",
            "Moving Avg Val Loss: 0.711261\n",
            "Epoch 739/2000, Train Loss: 0.003018, Val Loss: 0.053439\n",
            "Epoch 739/2000, Rel Train Loss: 83.73%, Rel Val Loss: 67.35%\n",
            "Moving Avg Val Loss: 0.764463\n",
            "Epoch 740/2000, Train Loss: 0.001990, Val Loss: 0.042967\n",
            "Epoch 740/2000, Rel Train Loss: 56.14%, Rel Val Loss: 87.36%\n",
            "Moving Avg Val Loss: 0.726982\n",
            "Epoch 741/2000, Train Loss: 0.001366, Val Loss: 0.050594\n",
            "Epoch 741/2000, Rel Train Loss: 57.09%, Rel Val Loss: 57.09%\n",
            "Moving Avg Val Loss: 0.739030\n",
            "Epoch 742/2000, Train Loss: 0.002038, Val Loss: 0.041958\n",
            "Epoch 742/2000, Rel Train Loss: 52.95%, Rel Val Loss: 81.04%\n",
            "Moving Avg Val Loss: 0.736289\n",
            "Epoch 743/2000, Train Loss: 0.002967, Val Loss: 0.051525\n",
            "Epoch 743/2000, Rel Train Loss: 65.66%, Rel Val Loss: 75.30%\n",
            "Moving Avg Val Loss: 0.712388\n",
            "Epoch 744/2000, Train Loss: 0.001373, Val Loss: 0.048569\n",
            "Epoch 744/2000, Rel Train Loss: 59.88%, Rel Val Loss: 55.40%\n",
            "Moving Avg Val Loss: 0.646985\n",
            "Epoch 745/2000, Train Loss: 0.001879, Val Loss: 0.048323\n",
            "Epoch 745/2000, Rel Train Loss: 49.88%, Rel Val Loss: 54.65%\n",
            "Moving Avg Val Loss: 0.649301\n",
            "Epoch 746/2000, Train Loss: 0.001245, Val Loss: 0.048655\n",
            "Epoch 746/2000, Rel Train Loss: 58.46%, Rel Val Loss: 58.25%\n",
            "Moving Avg Val Loss: 0.586710\n",
            "Epoch 747/2000, Train Loss: 0.000777, Val Loss: 0.044071\n",
            "Epoch 747/2000, Rel Train Loss: 48.24%, Rel Val Loss: 49.75%\n",
            "Moving Avg Val Loss: 0.546501\n",
            "Epoch 748/2000, Train Loss: 0.000794, Val Loss: 0.048026\n",
            "Epoch 748/2000, Rel Train Loss: 48.49%, Rel Val Loss: 55.20%\n",
            "Moving Avg Val Loss: 0.537827\n",
            "Epoch 749/2000, Train Loss: 0.000750, Val Loss: 0.046509\n",
            "Epoch 749/2000, Rel Train Loss: 43.44%, Rel Val Loss: 51.06%\n",
            "Moving Avg Val Loss: 0.543957\n",
            "Epoch 750/2000, Train Loss: 0.000691, Val Loss: 0.046988\n",
            "Epoch 750/2000, Rel Train Loss: 44.27%, Rel Val Loss: 57.72%\n",
            "Moving Avg Val Loss: 0.526967\n",
            "Epoch 751/2000, Train Loss: 0.000815, Val Loss: 0.049277\n",
            "Epoch 751/2000, Rel Train Loss: 44.41%, Rel Val Loss: 49.76%\n",
            "Moving Avg Val Loss: 0.527468\n",
            "Epoch 752/2000, Train Loss: 0.000974, Val Loss: 0.047937\n",
            "Epoch 752/2000, Rel Train Loss: 44.81%, Rel Val Loss: 50.00%\n",
            "Moving Avg Val Loss: 0.564131\n",
            "Epoch 753/2000, Train Loss: 0.001120, Val Loss: 0.049934\n",
            "Epoch 753/2000, Rel Train Loss: 58.11%, Rel Val Loss: 73.53%\n",
            "Moving Avg Val Loss: 0.720743\n",
            "Epoch 754/2000, Train Loss: 0.004575, Val Loss: 0.059652\n",
            "Epoch 754/2000, Rel Train Loss: 102.87%, Rel Val Loss: 129.36%\n",
            "Moving Avg Val Loss: 0.759547\n",
            "Epoch 755/2000, Train Loss: 0.003207, Val Loss: 0.049653\n",
            "Epoch 755/2000, Rel Train Loss: 97.61%, Rel Val Loss: 77.12%\n",
            "Moving Avg Val Loss: 0.797617\n",
            "Epoch 756/2000, Train Loss: 0.004302, Val Loss: 0.063398\n",
            "Epoch 756/2000, Rel Train Loss: 71.07%, Rel Val Loss: 68.79%\n",
            "Moving Avg Val Loss: 0.852003\n",
            "Epoch 757/2000, Train Loss: 0.006376, Val Loss: 0.052974\n",
            "Epoch 757/2000, Rel Train Loss: 98.57%, Rel Val Loss: 77.19%\n",
            "Moving Avg Val Loss: 1.050329\n",
            "Epoch 758/2000, Train Loss: 0.005141, Val Loss: 0.065401\n",
            "Epoch 758/2000, Rel Train Loss: 147.81%, Rel Val Loss: 172.69%\n",
            "Moving Avg Val Loss: 0.900447\n",
            "Epoch 759/2000, Train Loss: 0.004591, Val Loss: 0.060850\n",
            "Epoch 759/2000, Rel Train Loss: 106.92%, Rel Val Loss: 54.42%\n",
            "Moving Avg Val Loss: 0.920220\n",
            "Epoch 760/2000, Train Loss: 0.003207, Val Loss: 0.048144\n",
            "Epoch 760/2000, Rel Train Loss: 69.46%, Rel Val Loss: 87.01%\n",
            "Moving Avg Val Loss: 0.907615\n",
            "Epoch 761/2000, Train Loss: 0.001493, Val Loss: 0.056835\n",
            "Epoch 761/2000, Rel Train Loss: 66.80%, Rel Val Loss: 62.49%\n",
            "Moving Avg Val Loss: 0.857186\n",
            "Epoch 762/2000, Train Loss: 0.003211, Val Loss: 0.044532\n",
            "Epoch 762/2000, Rel Train Loss: 63.80%, Rel Val Loss: 51.98%\n",
            "Moving Avg Val Loss: 0.618261\n",
            "Epoch 763/2000, Train Loss: 0.002051, Val Loss: 0.048456\n",
            "Epoch 763/2000, Rel Train Loss: 67.16%, Rel Val Loss: 53.23%\n",
            "Moving Avg Val Loss: 0.615448\n",
            "Epoch 764/2000, Train Loss: 0.001142, Val Loss: 0.049076\n",
            "Epoch 764/2000, Rel Train Loss: 51.38%, Rel Val Loss: 53.02%\n",
            "Moving Avg Val Loss: 0.578330\n",
            "Epoch 765/2000, Train Loss: 0.001337, Val Loss: 0.049395\n",
            "Epoch 765/2000, Rel Train Loss: 52.73%, Rel Val Loss: 68.45%\n",
            "Moving Avg Val Loss: 0.668897\n",
            "Epoch 766/2000, Train Loss: 0.002365, Val Loss: 0.056533\n",
            "Epoch 766/2000, Rel Train Loss: 97.00%, Rel Val Loss: 107.77%\n",
            "Moving Avg Val Loss: 0.708728\n",
            "Epoch 767/2000, Train Loss: 0.001789, Val Loss: 0.048347\n",
            "Epoch 767/2000, Rel Train Loss: 92.37%, Rel Val Loss: 71.89%\n",
            "Moving Avg Val Loss: 0.749261\n",
            "Epoch 768/2000, Train Loss: 0.001338, Val Loss: 0.050085\n",
            "Epoch 768/2000, Rel Train Loss: 72.08%, Rel Val Loss: 73.50%\n",
            "Moving Avg Val Loss: 0.762052\n",
            "Epoch 769/2000, Train Loss: 0.001542, Val Loss: 0.044713\n",
            "Epoch 769/2000, Rel Train Loss: 49.53%, Rel Val Loss: 59.41%\n",
            "Moving Avg Val Loss: 0.735983\n",
            "Epoch 770/2000, Train Loss: 0.001655, Val Loss: 0.051517\n",
            "Epoch 770/2000, Rel Train Loss: 59.07%, Rel Val Loss: 55.41%\n",
            "Moving Avg Val Loss: 0.639892\n",
            "Epoch 771/2000, Train Loss: 0.001153, Val Loss: 0.046013\n",
            "Epoch 771/2000, Rel Train Loss: 46.50%, Rel Val Loss: 59.73%\n",
            "Moving Avg Val Loss: 0.607966\n",
            "Epoch 772/2000, Train Loss: 0.001044, Val Loss: 0.048017\n",
            "Epoch 772/2000, Rel Train Loss: 55.39%, Rel Val Loss: 55.93%\n",
            "Moving Avg Val Loss: 0.572265\n",
            "Epoch 773/2000, Train Loss: 0.001620, Val Loss: 0.050307\n",
            "Epoch 773/2000, Rel Train Loss: 47.68%, Rel Val Loss: 55.65%\n",
            "Moving Avg Val Loss: 0.568491\n",
            "Epoch 774/2000, Train Loss: 0.001095, Val Loss: 0.044601\n",
            "Epoch 774/2000, Rel Train Loss: 49.52%, Rel Val Loss: 57.52%\n",
            "Moving Avg Val Loss: 0.564121\n",
            "Epoch 775/2000, Train Loss: 0.001295, Val Loss: 0.051378\n",
            "Epoch 775/2000, Rel Train Loss: 53.11%, Rel Val Loss: 53.23%\n",
            "Moving Avg Val Loss: 0.554426\n",
            "Epoch 776/2000, Train Loss: 0.000804, Val Loss: 0.047472\n",
            "Epoch 776/2000, Rel Train Loss: 57.96%, Rel Val Loss: 54.88%\n",
            "Moving Avg Val Loss: 0.543233\n",
            "Epoch 777/2000, Train Loss: 0.000635, Val Loss: 0.048328\n",
            "Epoch 777/2000, Rel Train Loss: 47.20%, Rel Val Loss: 50.33%\n",
            "Moving Avg Val Loss: 0.536999\n",
            "Epoch 778/2000, Train Loss: 0.000547, Val Loss: 0.046007\n",
            "Epoch 778/2000, Rel Train Loss: 43.66%, Rel Val Loss: 52.53%\n",
            "Moving Avg Val Loss: 0.519778\n",
            "Epoch 779/2000, Train Loss: 0.000584, Val Loss: 0.047337\n",
            "Epoch 779/2000, Rel Train Loss: 41.95%, Rel Val Loss: 48.91%\n",
            "Moving Avg Val Loss: 0.521406\n",
            "Epoch 780/2000, Train Loss: 0.000716, Val Loss: 0.046400\n",
            "Epoch 780/2000, Rel Train Loss: 44.92%, Rel Val Loss: 54.04%\n",
            "Moving Avg Val Loss: 0.510822\n",
            "Epoch 781/2000, Train Loss: 0.000798, Val Loss: 0.048635\n",
            "Epoch 781/2000, Rel Train Loss: 44.99%, Rel Val Loss: 49.59%\n",
            "Moving Avg Val Loss: 0.507818\n",
            "Epoch 782/2000, Train Loss: 0.000772, Val Loss: 0.046012\n",
            "Epoch 782/2000, Rel Train Loss: 47.95%, Rel Val Loss: 48.83%\n",
            "Moving Avg Val Loss: 0.548476\n",
            "Epoch 783/2000, Train Loss: 0.001779, Val Loss: 0.047605\n",
            "Epoch 783/2000, Rel Train Loss: 49.55%, Rel Val Loss: 72.86%\n",
            "Moving Avg Val Loss: 0.555315\n",
            "Epoch 784/2000, Train Loss: 0.001069, Val Loss: 0.049139\n",
            "Epoch 784/2000, Rel Train Loss: 56.76%, Rel Val Loss: 52.33%\n",
            "Moving Avg Val Loss: 0.541894\n",
            "Epoch 785/2000, Train Loss: 0.000597, Val Loss: 0.048454\n",
            "Epoch 785/2000, Rel Train Loss: 46.53%, Rel Val Loss: 47.33%\n",
            "Moving Avg Val Loss: 0.554358\n",
            "Epoch 786/2000, Train Loss: 0.000736, Val Loss: 0.049161\n",
            "Epoch 786/2000, Rel Train Loss: 47.04%, Rel Val Loss: 55.82%\n",
            "Moving Avg Val Loss: 0.615431\n",
            "Epoch 787/2000, Train Loss: 0.001979, Val Loss: 0.055094\n",
            "Epoch 787/2000, Rel Train Loss: 51.60%, Rel Val Loss: 79.37%\n",
            "Moving Avg Val Loss: 0.574548\n",
            "Epoch 788/2000, Train Loss: 0.001809, Val Loss: 0.047036\n",
            "Epoch 788/2000, Rel Train Loss: 63.00%, Rel Val Loss: 52.42%\n",
            "Moving Avg Val Loss: 0.571860\n",
            "Epoch 789/2000, Train Loss: 0.000955, Val Loss: 0.049758\n",
            "Epoch 789/2000, Rel Train Loss: 47.77%, Rel Val Loss: 50.99%\n",
            "Moving Avg Val Loss: 0.582088\n",
            "Epoch 790/2000, Train Loss: 0.000800, Val Loss: 0.046218\n",
            "Epoch 790/2000, Rel Train Loss: 54.31%, Rel Val Loss: 52.45%\n",
            "Moving Avg Val Loss: 0.587806\n",
            "Epoch 791/2000, Train Loss: 0.000785, Val Loss: 0.048171\n",
            "Epoch 791/2000, Rel Train Loss: 42.11%, Rel Val Loss: 58.68%\n",
            "Moving Avg Val Loss: 0.527109\n",
            "Epoch 792/2000, Train Loss: 0.000671, Val Loss: 0.047712\n",
            "Epoch 792/2000, Rel Train Loss: 46.34%, Rel Val Loss: 49.02%\n",
            "Moving Avg Val Loss: 0.521596\n",
            "Epoch 793/2000, Train Loss: 0.000921, Val Loss: 0.048577\n",
            "Epoch 793/2000, Rel Train Loss: 49.39%, Rel Val Loss: 49.66%\n",
            "Moving Avg Val Loss: 0.515936\n",
            "Epoch 794/2000, Train Loss: 0.000717, Val Loss: 0.046995\n",
            "Epoch 794/2000, Rel Train Loss: 48.96%, Rel Val Loss: 48.16%\n",
            "Moving Avg Val Loss: 0.537790\n",
            "Epoch 795/2000, Train Loss: 0.001409, Val Loss: 0.054464\n",
            "Epoch 795/2000, Rel Train Loss: 51.56%, Rel Val Loss: 63.37%\n",
            "Moving Avg Val Loss: 0.660239\n",
            "Epoch 796/2000, Train Loss: 0.003551, Val Loss: 0.052618\n",
            "Epoch 796/2000, Rel Train Loss: 74.77%, Rel Val Loss: 119.90%\n",
            "Moving Avg Val Loss: 0.673647\n",
            "Epoch 797/2000, Train Loss: 0.001591, Val Loss: 0.046082\n",
            "Epoch 797/2000, Rel Train Loss: 80.02%, Rel Val Loss: 55.72%\n",
            "Moving Avg Val Loss: 0.708208\n",
            "Epoch 798/2000, Train Loss: 0.001013, Val Loss: 0.052025\n",
            "Epoch 798/2000, Rel Train Loss: 47.23%, Rel Val Loss: 66.94%\n",
            "Moving Avg Val Loss: 0.708739\n",
            "Epoch 799/2000, Train Loss: 0.000725, Val Loss: 0.046253\n",
            "Epoch 799/2000, Rel Train Loss: 48.81%, Rel Val Loss: 48.42%\n",
            "Moving Avg Val Loss: 0.681496\n",
            "Epoch 800/2000, Train Loss: 0.000755, Val Loss: 0.047487\n",
            "Epoch 800/2000, Rel Train Loss: 43.80%, Rel Val Loss: 49.75%\n",
            "Moving Avg Val Loss: 0.539475\n",
            "Epoch 801/2000, Train Loss: 0.001327, Val Loss: 0.046823\n",
            "Epoch 801/2000, Rel Train Loss: 55.55%, Rel Val Loss: 48.89%\n",
            "Moving Avg Val Loss: 0.526615\n",
            "Epoch 802/2000, Train Loss: 0.001185, Val Loss: 0.050518\n",
            "Epoch 802/2000, Rel Train Loss: 51.56%, Rel Val Loss: 49.29%\n",
            "Moving Avg Val Loss: 0.566226\n",
            "Epoch 803/2000, Train Loss: 0.001188, Val Loss: 0.048977\n",
            "Epoch 803/2000, Rel Train Loss: 54.54%, Rel Val Loss: 86.75%\n",
            "Moving Avg Val Loss: 0.574754\n",
            "Epoch 804/2000, Train Loss: 0.001460, Val Loss: 0.050271\n",
            "Epoch 804/2000, Rel Train Loss: 50.76%, Rel Val Loss: 52.69%\n",
            "Moving Avg Val Loss: 0.601961\n",
            "Epoch 805/2000, Train Loss: 0.001096, Val Loss: 0.044835\n",
            "Epoch 805/2000, Rel Train Loss: 56.55%, Rel Val Loss: 63.36%\n",
            "Moving Avg Val Loss: 0.609341\n",
            "Epoch 806/2000, Train Loss: 0.000963, Val Loss: 0.052430\n",
            "Epoch 806/2000, Rel Train Loss: 50.16%, Rel Val Loss: 52.58%\n",
            "Moving Avg Val Loss: 0.616856\n",
            "Epoch 807/2000, Train Loss: 0.000654, Val Loss: 0.047533\n",
            "Epoch 807/2000, Rel Train Loss: 41.24%, Rel Val Loss: 53.05%\n",
            "Moving Avg Val Loss: 0.538750\n",
            "Epoch 808/2000, Train Loss: 0.000659, Val Loss: 0.050522\n",
            "Epoch 808/2000, Rel Train Loss: 43.72%, Rel Val Loss: 47.69%\n",
            "Moving Avg Val Loss: 0.564521\n",
            "Epoch 809/2000, Train Loss: 0.000913, Val Loss: 0.051886\n",
            "Epoch 809/2000, Rel Train Loss: 48.10%, Rel Val Loss: 65.57%\n",
            "Moving Avg Val Loss: 0.535616\n",
            "Epoch 810/2000, Train Loss: 0.001479, Val Loss: 0.047261\n",
            "Epoch 810/2000, Rel Train Loss: 55.81%, Rel Val Loss: 48.90%\n",
            "Moving Avg Val Loss: 0.529031\n",
            "Epoch 811/2000, Train Loss: 0.001732, Val Loss: 0.052578\n",
            "Epoch 811/2000, Rel Train Loss: 63.92%, Rel Val Loss: 49.29%\n",
            "Moving Avg Val Loss: 0.539599\n",
            "Epoch 812/2000, Train Loss: 0.001406, Val Loss: 0.046970\n",
            "Epoch 812/2000, Rel Train Loss: 61.23%, Rel Val Loss: 58.34%\n",
            "Moving Avg Val Loss: 0.627758\n",
            "Epoch 813/2000, Train Loss: 0.004081, Val Loss: 0.055762\n",
            "Epoch 813/2000, Rel Train Loss: 53.76%, Rel Val Loss: 91.77%\n",
            "Moving Avg Val Loss: 0.675734\n",
            "Epoch 814/2000, Train Loss: 0.006877, Val Loss: 0.067327\n",
            "Epoch 814/2000, Rel Train Loss: 97.99%, Rel Val Loss: 89.56%\n",
            "Moving Avg Val Loss: 1.005493\n",
            "Epoch 815/2000, Train Loss: 0.005938, Val Loss: 0.056037\n",
            "Epoch 815/2000, Rel Train Loss: 149.82%, Rel Val Loss: 213.78%\n",
            "Moving Avg Val Loss: 1.099391\n",
            "Epoch 816/2000, Train Loss: 0.003072, Val Loss: 0.053069\n",
            "Epoch 816/2000, Rel Train Loss: 137.80%, Rel Val Loss: 96.24%\n",
            "Moving Avg Val Loss: 1.099071\n",
            "Epoch 817/2000, Train Loss: 0.002853, Val Loss: 0.054305\n",
            "Epoch 817/2000, Rel Train Loss: 76.10%, Rel Val Loss: 58.18%\n",
            "Moving Avg Val Loss: 1.072221\n",
            "Epoch 818/2000, Train Loss: 0.007307, Val Loss: 0.064704\n",
            "Epoch 818/2000, Rel Train Loss: 87.24%, Rel Val Loss: 78.35%\n",
            "Moving Avg Val Loss: 1.096896\n",
            "Epoch 819/2000, Train Loss: 0.008424, Val Loss: 0.049085\n",
            "Epoch 819/2000, Rel Train Loss: 145.77%, Rel Val Loss: 101.90%\n",
            "Moving Avg Val Loss: 1.016418\n",
            "Epoch 820/2000, Train Loss: 0.004022, Val Loss: 0.052719\n",
            "Epoch 820/2000, Rel Train Loss: 146.31%, Rel Val Loss: 173.54%\n",
            "Moving Avg Val Loss: 1.073619\n",
            "Epoch 821/2000, Train Loss: 0.003271, Val Loss: 0.047382\n",
            "Epoch 821/2000, Rel Train Loss: 104.88%, Rel Val Loss: 124.84%\n",
            "Moving Avg Val Loss: 1.077501\n",
            "Epoch 822/2000, Train Loss: 0.003018, Val Loss: 0.053132\n",
            "Epoch 822/2000, Rel Train Loss: 81.63%, Rel Val Loss: 60.12%\n",
            "Moving Avg Val Loss: 1.060627\n",
            "Epoch 823/2000, Train Loss: 0.002630, Val Loss: 0.046468\n",
            "Epoch 823/2000, Rel Train Loss: 59.76%, Rel Val Loss: 69.91%\n",
            "Moving Avg Val Loss: 0.958637\n",
            "Epoch 824/2000, Train Loss: 0.003049, Val Loss: 0.053234\n",
            "Epoch 824/2000, Rel Train Loss: 81.84%, Rel Val Loss: 50.91%\n",
            "Moving Avg Val Loss: 0.712712\n",
            "Epoch 825/2000, Train Loss: 0.001291, Val Loss: 0.044120\n",
            "Epoch 825/2000, Rel Train Loss: 54.15%, Rel Val Loss: 50.58%\n",
            "Moving Avg Val Loss: 0.616495\n",
            "Epoch 826/2000, Train Loss: 0.001827, Val Loss: 0.054919\n",
            "Epoch 826/2000, Rel Train Loss: 52.18%, Rel Val Loss: 76.73%\n",
            "Moving Avg Val Loss: 0.622637\n",
            "Epoch 827/2000, Train Loss: 0.002245, Val Loss: 0.044685\n",
            "Epoch 827/2000, Rel Train Loss: 71.86%, Rel Val Loss: 63.19%\n",
            "Moving Avg Val Loss: 0.597382\n",
            "Epoch 828/2000, Train Loss: 0.002141, Val Loss: 0.049079\n",
            "Epoch 828/2000, Rel Train Loss: 72.61%, Rel Val Loss: 57.29%\n",
            "Moving Avg Val Loss: 0.592039\n",
            "Epoch 829/2000, Train Loss: 0.002324, Val Loss: 0.051696\n",
            "Epoch 829/2000, Rel Train Loss: 51.00%, Rel Val Loss: 48.23%\n",
            "Moving Avg Val Loss: 0.759775\n",
            "Epoch 830/2000, Train Loss: 0.003279, Val Loss: 0.050033\n",
            "Epoch 830/2000, Rel Train Loss: 91.66%, Rel Val Loss: 134.45%\n",
            "Moving Avg Val Loss: 0.707674\n",
            "Epoch 831/2000, Train Loss: 0.002157, Val Loss: 0.049346\n",
            "Epoch 831/2000, Rel Train Loss: 75.64%, Rel Val Loss: 50.68%\n",
            "Moving Avg Val Loss: 0.676564\n",
            "Epoch 832/2000, Train Loss: 0.000751, Val Loss: 0.046678\n",
            "Epoch 832/2000, Rel Train Loss: 49.04%, Rel Val Loss: 47.63%\n",
            "Moving Avg Val Loss: 0.659638\n",
            "Epoch 833/2000, Train Loss: 0.000744, Val Loss: 0.045852\n",
            "Epoch 833/2000, Rel Train Loss: 43.89%, Rel Val Loss: 48.82%\n",
            "Moving Avg Val Loss: 0.653024\n",
            "Epoch 834/2000, Train Loss: 0.000533, Val Loss: 0.045609\n",
            "Epoch 834/2000, Rel Train Loss: 40.75%, Rel Val Loss: 44.93%\n",
            "Moving Avg Val Loss: 0.483058\n",
            "Epoch 835/2000, Train Loss: 0.000686, Val Loss: 0.046800\n",
            "Epoch 835/2000, Rel Train Loss: 41.69%, Rel Val Loss: 49.47%\n",
            "Moving Avg Val Loss: 0.473367\n",
            "Epoch 836/2000, Train Loss: 0.000552, Val Loss: 0.044797\n",
            "Epoch 836/2000, Rel Train Loss: 39.99%, Rel Val Loss: 45.84%\n",
            "Moving Avg Val Loss: 0.474886\n",
            "Epoch 837/2000, Train Loss: 0.000509, Val Loss: 0.046974\n",
            "Epoch 837/2000, Rel Train Loss: 41.10%, Rel Val Loss: 48.39%\n",
            "Moving Avg Val Loss: 0.466016\n",
            "Epoch 838/2000, Train Loss: 0.000470, Val Loss: 0.045275\n",
            "Epoch 838/2000, Rel Train Loss: 42.53%, Rel Val Loss: 44.39%\n",
            "Moving Avg Val Loss: 0.470841\n",
            "Epoch 839/2000, Train Loss: 0.000452, Val Loss: 0.046079\n",
            "Epoch 839/2000, Rel Train Loss: 40.18%, Rel Val Loss: 47.34%\n",
            "Moving Avg Val Loss: 0.461555\n",
            "Epoch 840/2000, Train Loss: 0.000448, Val Loss: 0.044956\n",
            "Epoch 840/2000, Rel Train Loss: 40.08%, Rel Val Loss: 44.82%\n",
            "Moving Avg Val Loss: 0.459728\n",
            "Epoch 841/2000, Train Loss: 0.000500, Val Loss: 0.045160\n",
            "Epoch 841/2000, Rel Train Loss: 42.17%, Rel Val Loss: 44.92%\n",
            "Moving Avg Val Loss: 0.461292\n",
            "Epoch 842/2000, Train Loss: 0.000604, Val Loss: 0.046753\n",
            "Epoch 842/2000, Rel Train Loss: 41.01%, Rel Val Loss: 49.17%\n",
            "Moving Avg Val Loss: 0.469380\n",
            "Epoch 843/2000, Train Loss: 0.000711, Val Loss: 0.046167\n",
            "Epoch 843/2000, Rel Train Loss: 43.03%, Rel Val Loss: 48.43%\n",
            "Moving Avg Val Loss: 0.466777\n",
            "Epoch 844/2000, Train Loss: 0.000548, Val Loss: 0.045354\n",
            "Epoch 844/2000, Rel Train Loss: 40.12%, Rel Val Loss: 46.04%\n",
            "Moving Avg Val Loss: 0.472851\n",
            "Epoch 845/2000, Train Loss: 0.000472, Val Loss: 0.047096\n",
            "Epoch 845/2000, Rel Train Loss: 42.13%, Rel Val Loss: 47.86%\n",
            "Moving Avg Val Loss: 0.479178\n",
            "Epoch 846/2000, Train Loss: 0.000455, Val Loss: 0.044894\n",
            "Epoch 846/2000, Rel Train Loss: 38.60%, Rel Val Loss: 48.09%\n",
            "Moving Avg Val Loss: 0.479857\n",
            "Epoch 847/2000, Train Loss: 0.000450, Val Loss: 0.045746\n",
            "Epoch 847/2000, Rel Train Loss: 40.00%, Rel Val Loss: 49.51%\n",
            "Moving Avg Val Loss: 0.473884\n",
            "Epoch 848/2000, Train Loss: 0.000430, Val Loss: 0.046219\n",
            "Epoch 848/2000, Rel Train Loss: 41.34%, Rel Val Loss: 45.44%\n",
            "Moving Avg Val Loss: 0.558109\n",
            "Epoch 849/2000, Train Loss: 0.001037, Val Loss: 0.050691\n",
            "Epoch 849/2000, Rel Train Loss: 47.76%, Rel Val Loss: 88.15%\n",
            "Moving Avg Val Loss: 0.608475\n",
            "Epoch 850/2000, Train Loss: 0.002658, Val Loss: 0.052302\n",
            "Epoch 850/2000, Rel Train Loss: 61.29%, Rel Val Loss: 73.04%\n",
            "Moving Avg Val Loss: 0.615304\n",
            "Epoch 851/2000, Train Loss: 0.001569, Val Loss: 0.049701\n",
            "Epoch 851/2000, Rel Train Loss: 59.98%, Rel Val Loss: 51.50%\n",
            "Moving Avg Val Loss: 0.644271\n",
            "Epoch 852/2000, Train Loss: 0.001714, Val Loss: 0.061516\n",
            "Epoch 852/2000, Rel Train Loss: 57.05%, Rel Val Loss: 64.00%\n",
            "Moving Avg Val Loss: 0.661430\n",
            "Epoch 853/2000, Train Loss: 0.002844, Val Loss: 0.044046\n",
            "Epoch 853/2000, Rel Train Loss: 53.94%, Rel Val Loss: 54.02%\n",
            "Moving Avg Val Loss: 0.600471\n",
            "Epoch 854/2000, Train Loss: 0.000825, Val Loss: 0.050534\n",
            "Epoch 854/2000, Rel Train Loss: 49.61%, Rel Val Loss: 57.67%\n",
            "Moving Avg Val Loss: 0.554438\n",
            "Epoch 855/2000, Train Loss: 0.000797, Val Loss: 0.042619\n",
            "Epoch 855/2000, Rel Train Loss: 46.04%, Rel Val Loss: 50.03%\n",
            "Moving Avg Val Loss: 0.546079\n",
            "Epoch 856/2000, Train Loss: 0.000772, Val Loss: 0.039742\n",
            "Epoch 856/2000, Rel Train Loss: 45.08%, Rel Val Loss: 47.32%\n",
            "Moving Avg Val Loss: 0.514620\n",
            "Epoch 857/2000, Train Loss: 0.000886, Val Loss: 0.046125\n",
            "Epoch 857/2000, Rel Train Loss: 45.75%, Rel Val Loss: 48.27%\n",
            "Moving Avg Val Loss: 0.531712\n",
            "Epoch 858/2000, Train Loss: 0.001118, Val Loss: 0.039498\n",
            "Epoch 858/2000, Rel Train Loss: 55.23%, Rel Val Loss: 62.57%\n",
            "Moving Avg Val Loss: 0.522710\n",
            "Epoch 859/2000, Train Loss: 0.000900, Val Loss: 0.045186\n",
            "Epoch 859/2000, Rel Train Loss: 48.59%, Rel Val Loss: 53.17%\n",
            "Moving Avg Val Loss: 0.516508\n",
            "Epoch 860/2000, Train Loss: 0.000615, Val Loss: 0.044271\n",
            "Epoch 860/2000, Rel Train Loss: 42.13%, Rel Val Loss: 46.93%\n",
            "Moving Avg Val Loss: 0.511275\n",
            "Epoch 861/2000, Train Loss: 0.000669, Val Loss: 0.042480\n",
            "Epoch 861/2000, Rel Train Loss: 40.12%, Rel Val Loss: 44.70%\n",
            "Moving Avg Val Loss: 0.509208\n",
            "Epoch 862/2000, Train Loss: 0.000563, Val Loss: 0.045366\n",
            "Epoch 862/2000, Rel Train Loss: 42.46%, Rel Val Loss: 47.23%\n",
            "Moving Avg Val Loss: 0.497427\n",
            "Epoch 863/2000, Train Loss: 0.000592, Val Loss: 0.042604\n",
            "Epoch 863/2000, Rel Train Loss: 42.11%, Rel Val Loss: 56.68%\n",
            "Moving Avg Val Loss: 0.480980\n",
            "Epoch 864/2000, Train Loss: 0.000494, Val Loss: 0.044541\n",
            "Epoch 864/2000, Rel Train Loss: 40.29%, Rel Val Loss: 44.95%\n",
            "Moving Avg Val Loss: 0.480256\n",
            "Epoch 865/2000, Train Loss: 0.000435, Val Loss: 0.043374\n",
            "Epoch 865/2000, Rel Train Loss: 39.62%, Rel Val Loss: 46.56%\n",
            "Moving Avg Val Loss: 0.484879\n",
            "Epoch 866/2000, Train Loss: 0.000403, Val Loss: 0.044365\n",
            "Epoch 866/2000, Rel Train Loss: 39.07%, Rel Val Loss: 47.02%\n",
            "Moving Avg Val Loss: 0.483255\n",
            "Epoch 867/2000, Train Loss: 0.000409, Val Loss: 0.042727\n",
            "Epoch 867/2000, Rel Train Loss: 38.26%, Rel Val Loss: 46.42%\n",
            "Moving Avg Val Loss: 0.463142\n",
            "Epoch 868/2000, Train Loss: 0.000437, Val Loss: 0.043989\n",
            "Epoch 868/2000, Rel Train Loss: 39.71%, Rel Val Loss: 46.62%\n",
            "Moving Avg Val Loss: 0.463925\n",
            "Epoch 869/2000, Train Loss: 0.000464, Val Loss: 0.043744\n",
            "Epoch 869/2000, Rel Train Loss: 41.42%, Rel Val Loss: 45.34%\n",
            "Moving Avg Val Loss: 0.463531\n",
            "Epoch 870/2000, Train Loss: 0.000429, Val Loss: 0.044277\n",
            "Epoch 870/2000, Rel Train Loss: 38.67%, Rel Val Loss: 46.37%\n",
            "Moving Avg Val Loss: 0.458948\n",
            "Epoch 871/2000, Train Loss: 0.000420, Val Loss: 0.043654\n",
            "Epoch 871/2000, Rel Train Loss: 38.72%, Rel Val Loss: 44.72%\n",
            "Moving Avg Val Loss: 0.454977\n",
            "Epoch 872/2000, Train Loss: 0.000440, Val Loss: 0.044595\n",
            "Epoch 872/2000, Rel Train Loss: 38.62%, Rel Val Loss: 44.44%\n",
            "Moving Avg Val Loss: 0.459125\n",
            "Epoch 873/2000, Train Loss: 0.000393, Val Loss: 0.043554\n",
            "Epoch 873/2000, Rel Train Loss: 38.02%, Rel Val Loss: 48.70%\n",
            "Moving Avg Val Loss: 0.459397\n",
            "Epoch 874/2000, Train Loss: 0.000402, Val Loss: 0.044716\n",
            "Epoch 874/2000, Rel Train Loss: 38.16%, Rel Val Loss: 45.47%\n",
            "Moving Avg Val Loss: 0.455888\n",
            "Epoch 875/2000, Train Loss: 0.000446, Val Loss: 0.043521\n",
            "Epoch 875/2000, Rel Train Loss: 38.85%, Rel Val Loss: 44.61%\n",
            "Moving Avg Val Loss: 0.465975\n",
            "Epoch 876/2000, Train Loss: 0.000671, Val Loss: 0.045371\n",
            "Epoch 876/2000, Rel Train Loss: 41.22%, Rel Val Loss: 49.77%\n",
            "Moving Avg Val Loss: 0.478158\n",
            "Epoch 877/2000, Train Loss: 0.000836, Val Loss: 0.047068\n",
            "Epoch 877/2000, Rel Train Loss: 44.76%, Rel Val Loss: 50.53%\n",
            "Moving Avg Val Loss: 0.513497\n",
            "Epoch 878/2000, Train Loss: 0.000964, Val Loss: 0.043140\n",
            "Epoch 878/2000, Rel Train Loss: 48.27%, Rel Val Loss: 66.37%\n",
            "Moving Avg Val Loss: 0.526616\n",
            "Epoch 879/2000, Train Loss: 0.002685, Val Loss: 0.049768\n",
            "Epoch 879/2000, Rel Train Loss: 118.01%, Rel Val Loss: 52.03%\n",
            "Moving Avg Val Loss: 0.552848\n",
            "Epoch 880/2000, Train Loss: 0.002637, Val Loss: 0.046809\n",
            "Epoch 880/2000, Rel Train Loss: 71.68%, Rel Val Loss: 57.73%\n",
            "Moving Avg Val Loss: 0.637603\n",
            "Epoch 881/2000, Train Loss: 0.008273, Val Loss: 0.076822\n",
            "Epoch 881/2000, Rel Train Loss: 75.24%, Rel Val Loss: 92.14%\n",
            "Moving Avg Val Loss: 0.920252\n",
            "Epoch 882/2000, Train Loss: 0.010531, Val Loss: 0.056773\n",
            "Epoch 882/2000, Rel Train Loss: 120.06%, Rel Val Loss: 191.85%\n",
            "Moving Avg Val Loss: 0.969896\n",
            "Epoch 883/2000, Train Loss: 0.003448, Val Loss: 0.053437\n",
            "Epoch 883/2000, Rel Train Loss: 101.42%, Rel Val Loss: 91.19%\n",
            "Moving Avg Val Loss: 1.154072\n",
            "Epoch 884/2000, Train Loss: 0.002175, Val Loss: 0.050369\n",
            "Epoch 884/2000, Rel Train Loss: 81.73%, Rel Val Loss: 144.12%\n",
            "Moving Avg Val Loss: 1.216693\n",
            "Epoch 885/2000, Train Loss: 0.002101, Val Loss: 0.044211\n",
            "Epoch 885/2000, Rel Train Loss: 87.93%, Rel Val Loss: 89.04%\n",
            "Moving Avg Val Loss: 1.181538\n",
            "Epoch 886/2000, Train Loss: 0.004213, Val Loss: 0.056552\n",
            "Epoch 886/2000, Rel Train Loss: 68.73%, Rel Val Loss: 74.57%\n",
            "Moving Avg Val Loss: 1.019924\n",
            "Epoch 887/2000, Train Loss: 0.004658, Val Loss: 0.041056\n",
            "Epoch 887/2000, Rel Train Loss: 83.47%, Rel Val Loss: 111.04%\n",
            "Moving Avg Val Loss: 0.955784\n",
            "Epoch 888/2000, Train Loss: 0.003075, Val Loss: 0.051541\n",
            "Epoch 888/2000, Rel Train Loss: 93.84%, Rel Val Loss: 59.12%\n",
            "Moving Avg Val Loss: 0.814477\n",
            "Epoch 889/2000, Train Loss: 0.002946, Val Loss: 0.046754\n",
            "Epoch 889/2000, Rel Train Loss: 55.91%, Rel Val Loss: 73.47%\n",
            "Moving Avg Val Loss: 0.762150\n",
            "Epoch 890/2000, Train Loss: 0.003291, Val Loss: 0.052736\n",
            "Epoch 890/2000, Rel Train Loss: 68.67%, Rel Val Loss: 62.88%\n",
            "Moving Avg Val Loss: 0.720574\n",
            "Epoch 891/2000, Train Loss: 0.001713, Val Loss: 0.041750\n",
            "Epoch 891/2000, Rel Train Loss: 54.10%, Rel Val Loss: 53.78%\n",
            "Moving Avg Val Loss: 0.609302\n",
            "Epoch 892/2000, Train Loss: 0.001227, Val Loss: 0.055564\n",
            "Epoch 892/2000, Rel Train Loss: 50.41%, Rel Val Loss: 55.41%\n",
            "Moving Avg Val Loss: 0.605331\n",
            "Epoch 893/2000, Train Loss: 0.001720, Val Loss: 0.040244\n",
            "Epoch 893/2000, Rel Train Loss: 69.20%, Rel Val Loss: 57.13%\n",
            "Moving Avg Val Loss: 0.574961\n",
            "Epoch 894/2000, Train Loss: 0.001560, Val Loss: 0.053273\n",
            "Epoch 894/2000, Rel Train Loss: 49.56%, Rel Val Loss: 58.28%\n",
            "Moving Avg Val Loss: 0.571698\n",
            "Epoch 895/2000, Train Loss: 0.001367, Val Loss: 0.045393\n",
            "Epoch 895/2000, Rel Train Loss: 53.78%, Rel Val Loss: 61.24%\n",
            "Moving Avg Val Loss: 0.555342\n",
            "Epoch 896/2000, Train Loss: 0.000623, Val Loss: 0.043928\n",
            "Epoch 896/2000, Rel Train Loss: 43.99%, Rel Val Loss: 45.60%\n",
            "Moving Avg Val Loss: 0.536978\n",
            "Epoch 897/2000, Train Loss: 0.000682, Val Loss: 0.044500\n",
            "Epoch 897/2000, Rel Train Loss: 49.71%, Rel Val Loss: 46.23%\n",
            "Moving Avg Val Loss: 0.523339\n",
            "Epoch 898/2000, Train Loss: 0.000532, Val Loss: 0.044014\n",
            "Epoch 898/2000, Rel Train Loss: 46.24%, Rel Val Loss: 50.31%\n",
            "Moving Avg Val Loss: 0.491989\n",
            "Epoch 899/2000, Train Loss: 0.000489, Val Loss: 0.044961\n",
            "Epoch 899/2000, Rel Train Loss: 39.83%, Rel Val Loss: 42.61%\n",
            "Moving Avg Val Loss: 0.463774\n",
            "Epoch 900/2000, Train Loss: 0.000856, Val Loss: 0.042157\n",
            "Epoch 900/2000, Rel Train Loss: 39.13%, Rel Val Loss: 47.14%\n",
            "Moving Avg Val Loss: 0.489523\n",
            "Epoch 901/2000, Train Loss: 0.001114, Val Loss: 0.047430\n",
            "Epoch 901/2000, Rel Train Loss: 44.96%, Rel Val Loss: 58.48%\n",
            "Moving Avg Val Loss: 0.505885\n",
            "Epoch 902/2000, Train Loss: 0.001690, Val Loss: 0.046883\n",
            "Epoch 902/2000, Rel Train Loss: 49.43%, Rel Val Loss: 54.41%\n",
            "Moving Avg Val Loss: 0.513618\n",
            "Epoch 903/2000, Train Loss: 0.003316, Val Loss: 0.051342\n",
            "Epoch 903/2000, Rel Train Loss: 88.90%, Rel Val Loss: 54.18%\n",
            "Moving Avg Val Loss: 0.723440\n",
            "Epoch 904/2000, Train Loss: 0.003496, Val Loss: 0.045212\n",
            "Epoch 904/2000, Rel Train Loss: 88.17%, Rel Val Loss: 147.52%\n",
            "Moving Avg Val Loss: 0.743796\n",
            "Epoch 905/2000, Train Loss: 0.003729, Val Loss: 0.058583\n",
            "Epoch 905/2000, Rel Train Loss: 87.76%, Rel Val Loss: 57.31%\n",
            "Moving Avg Val Loss: 0.774645\n",
            "Epoch 906/2000, Train Loss: 0.003312, Val Loss: 0.048455\n",
            "Epoch 906/2000, Rel Train Loss: 71.64%, Rel Val Loss: 73.90%\n",
            "Moving Avg Val Loss: 0.797896\n",
            "Epoch 907/2000, Train Loss: 0.001361, Val Loss: 0.048049\n",
            "Epoch 907/2000, Rel Train Loss: 62.36%, Rel Val Loss: 66.03%\n",
            "Moving Avg Val Loss: 0.778250\n",
            "Epoch 908/2000, Train Loss: 0.000900, Val Loss: 0.046728\n",
            "Epoch 908/2000, Rel Train Loss: 51.70%, Rel Val Loss: 44.36%\n",
            "Moving Avg Val Loss: 0.576179\n",
            "Epoch 909/2000, Train Loss: 0.000699, Val Loss: 0.043112\n",
            "Epoch 909/2000, Rel Train Loss: 43.15%, Rel Val Loss: 46.48%\n",
            "Moving Avg Val Loss: 0.556630\n",
            "Epoch 910/2000, Train Loss: 0.000803, Val Loss: 0.047550\n",
            "Epoch 910/2000, Rel Train Loss: 42.11%, Rel Val Loss: 47.54%\n",
            "Moving Avg Val Loss: 0.500751\n",
            "Epoch 911/2000, Train Loss: 0.000632, Val Loss: 0.043231\n",
            "Epoch 911/2000, Rel Train Loss: 38.68%, Rel Val Loss: 45.96%\n",
            "Moving Avg Val Loss: 0.459757\n",
            "Epoch 912/2000, Train Loss: 0.000538, Val Loss: 0.043427\n",
            "Epoch 912/2000, Rel Train Loss: 40.88%, Rel Val Loss: 45.54%\n",
            "Moving Avg Val Loss: 0.462380\n",
            "Epoch 913/2000, Train Loss: 0.000445, Val Loss: 0.045110\n",
            "Epoch 913/2000, Rel Train Loss: 38.68%, Rel Val Loss: 45.67%\n",
            "Moving Avg Val Loss: 0.471678\n",
            "Epoch 914/2000, Train Loss: 0.000449, Val Loss: 0.044343\n",
            "Epoch 914/2000, Rel Train Loss: 39.67%, Rel Val Loss: 51.13%\n",
            "Moving Avg Val Loss: 0.465010\n",
            "Epoch 915/2000, Train Loss: 0.000683, Val Loss: 0.044336\n",
            "Epoch 915/2000, Rel Train Loss: 40.00%, Rel Val Loss: 44.21%\n",
            "Moving Avg Val Loss: 0.473433\n",
            "Epoch 916/2000, Train Loss: 0.000509, Val Loss: 0.044713\n",
            "Epoch 916/2000, Rel Train Loss: 38.69%, Rel Val Loss: 50.17%\n",
            "Moving Avg Val Loss: 0.470916\n",
            "Epoch 917/2000, Train Loss: 0.000518, Val Loss: 0.043560\n",
            "Epoch 917/2000, Rel Train Loss: 38.59%, Rel Val Loss: 44.28%\n",
            "Moving Avg Val Loss: 0.498056\n",
            "Epoch 918/2000, Train Loss: 0.000597, Val Loss: 0.045688\n",
            "Epoch 918/2000, Rel Train Loss: 42.51%, Rel Val Loss: 59.24%\n",
            "Moving Avg Val Loss: 0.485061\n",
            "Epoch 919/2000, Train Loss: 0.000909, Val Loss: 0.045609\n",
            "Epoch 919/2000, Rel Train Loss: 50.12%, Rel Val Loss: 44.64%\n",
            "Moving Avg Val Loss: 0.482913\n",
            "Epoch 920/2000, Train Loss: 0.000687, Val Loss: 0.046256\n",
            "Epoch 920/2000, Rel Train Loss: 39.66%, Rel Val Loss: 43.13%\n",
            "Moving Avg Val Loss: 0.487925\n",
            "Epoch 921/2000, Train Loss: 0.000506, Val Loss: 0.044652\n",
            "Epoch 921/2000, Rel Train Loss: 42.11%, Rel Val Loss: 52.68%\n",
            "Moving Avg Val Loss: 0.485052\n",
            "Epoch 922/2000, Train Loss: 0.000534, Val Loss: 0.045159\n",
            "Epoch 922/2000, Rel Train Loss: 39.72%, Rel Val Loss: 42.84%\n",
            "Moving Avg Val Loss: 0.459432\n",
            "Epoch 923/2000, Train Loss: 0.001015, Val Loss: 0.045379\n",
            "Epoch 923/2000, Rel Train Loss: 46.10%, Rel Val Loss: 46.43%\n",
            "Moving Avg Val Loss: 0.519950\n",
            "Epoch 924/2000, Train Loss: 0.001435, Val Loss: 0.046473\n",
            "Epoch 924/2000, Rel Train Loss: 73.70%, Rel Val Loss: 74.89%\n",
            "Moving Avg Val Loss: 0.523782\n",
            "Epoch 925/2000, Train Loss: 0.000844, Val Loss: 0.047115\n",
            "Epoch 925/2000, Rel Train Loss: 52.52%, Rel Val Loss: 45.05%\n",
            "Moving Avg Val Loss: 0.508468\n",
            "Epoch 926/2000, Train Loss: 0.000621, Val Loss: 0.044615\n",
            "Epoch 926/2000, Rel Train Loss: 37.29%, Rel Val Loss: 45.02%\n",
            "Moving Avg Val Loss: 0.514981\n",
            "Epoch 927/2000, Train Loss: 0.000682, Val Loss: 0.045448\n",
            "Epoch 927/2000, Rel Train Loss: 46.47%, Rel Val Loss: 46.10%\n",
            "Moving Avg Val Loss: 0.511308\n",
            "Epoch 928/2000, Train Loss: 0.000461, Val Loss: 0.044795\n",
            "Epoch 928/2000, Rel Train Loss: 38.52%, Rel Val Loss: 44.59%\n",
            "Moving Avg Val Loss: 0.453985\n",
            "Epoch 929/2000, Train Loss: 0.000423, Val Loss: 0.044784\n",
            "Epoch 929/2000, Rel Train Loss: 36.88%, Rel Val Loss: 46.23%\n",
            "Moving Avg Val Loss: 0.450534\n",
            "Epoch 930/2000, Train Loss: 0.000497, Val Loss: 0.045782\n",
            "Epoch 930/2000, Rel Train Loss: 37.41%, Rel Val Loss: 43.32%\n",
            "Moving Avg Val Loss: 0.461758\n",
            "Epoch 931/2000, Train Loss: 0.000734, Val Loss: 0.051024\n",
            "Epoch 931/2000, Rel Train Loss: 49.32%, Rel Val Loss: 50.63%\n",
            "Moving Avg Val Loss: 0.457111\n",
            "Epoch 932/2000, Train Loss: 0.001563, Val Loss: 0.043773\n",
            "Epoch 932/2000, Rel Train Loss: 49.60%, Rel Val Loss: 43.77%\n",
            "Moving Avg Val Loss: 0.492098\n",
            "Epoch 933/2000, Train Loss: 0.001592, Val Loss: 0.048676\n",
            "Epoch 933/2000, Rel Train Loss: 51.67%, Rel Val Loss: 62.09%\n",
            "Moving Avg Val Loss: 0.607889\n",
            "Epoch 934/2000, Train Loss: 0.002689, Val Loss: 0.050429\n",
            "Epoch 934/2000, Rel Train Loss: 65.62%, Rel Val Loss: 104.13%\n",
            "Moving Avg Val Loss: 0.621018\n",
            "Epoch 935/2000, Train Loss: 0.002176, Val Loss: 0.046929\n",
            "Epoch 935/2000, Rel Train Loss: 68.10%, Rel Val Loss: 49.89%\n",
            "Moving Avg Val Loss: 0.610730\n",
            "Epoch 936/2000, Train Loss: 0.000769, Val Loss: 0.044795\n",
            "Epoch 936/2000, Rel Train Loss: 43.57%, Rel Val Loss: 45.49%\n",
            "Moving Avg Val Loss: 0.630126\n",
            "Epoch 937/2000, Train Loss: 0.000757, Val Loss: 0.045442\n",
            "Epoch 937/2000, Rel Train Loss: 42.74%, Rel Val Loss: 53.47%\n",
            "Moving Avg Val Loss: 0.648490\n",
            "Epoch 938/2000, Train Loss: 0.001911, Val Loss: 0.046689\n",
            "Epoch 938/2000, Rel Train Loss: 63.22%, Rel Val Loss: 71.27%\n",
            "Moving Avg Val Loss: 0.530811\n",
            "Epoch 939/2000, Train Loss: 0.001480, Val Loss: 0.043929\n",
            "Epoch 939/2000, Rel Train Loss: 63.42%, Rel Val Loss: 45.29%\n",
            "Moving Avg Val Loss: 0.539414\n",
            "Epoch 940/2000, Train Loss: 0.000622, Val Loss: 0.043494\n",
            "Epoch 940/2000, Rel Train Loss: 39.86%, Rel Val Loss: 54.19%\n",
            "Moving Avg Val Loss: 0.542101\n",
            "Epoch 941/2000, Train Loss: 0.000677, Val Loss: 0.048552\n",
            "Epoch 941/2000, Rel Train Loss: 43.24%, Rel Val Loss: 46.83%\n",
            "Moving Avg Val Loss: 0.545028\n",
            "Epoch 942/2000, Train Loss: 0.001545, Val Loss: 0.048647\n",
            "Epoch 942/2000, Rel Train Loss: 55.06%, Rel Val Loss: 54.93%\n",
            "Moving Avg Val Loss: 0.498069\n",
            "Epoch 943/2000, Train Loss: 0.002555, Val Loss: 0.047462\n",
            "Epoch 943/2000, Rel Train Loss: 80.01%, Rel Val Loss: 47.79%\n",
            "Moving Avg Val Loss: 0.509901\n",
            "Epoch 944/2000, Train Loss: 0.001179, Val Loss: 0.046820\n",
            "Epoch 944/2000, Rel Train Loss: 73.59%, Rel Val Loss: 51.20%\n",
            "Moving Avg Val Loss: 0.487798\n",
            "Epoch 945/2000, Train Loss: 0.000790, Val Loss: 0.043862\n",
            "Epoch 945/2000, Rel Train Loss: 44.02%, Rel Val Loss: 43.14%\n",
            "Moving Avg Val Loss: 0.482934\n",
            "Epoch 946/2000, Train Loss: 0.001090, Val Loss: 0.045007\n",
            "Epoch 946/2000, Rel Train Loss: 51.19%, Rel Val Loss: 44.40%\n",
            "Moving Avg Val Loss: 0.471895\n",
            "Epoch 947/2000, Train Loss: 0.001405, Val Loss: 0.052039\n",
            "Epoch 947/2000, Rel Train Loss: 52.93%, Rel Val Loss: 49.41%\n",
            "Moving Avg Val Loss: 0.530533\n",
            "Epoch 948/2000, Train Loss: 0.001937, Val Loss: 0.042270\n",
            "Epoch 948/2000, Rel Train Loss: 43.72%, Rel Val Loss: 77.11%\n",
            "Moving Avg Val Loss: 0.583374\n",
            "Epoch 949/2000, Train Loss: 0.002450, Val Loss: 0.055521\n",
            "Epoch 949/2000, Rel Train Loss: 76.41%, Rel Val Loss: 77.62%\n",
            "Moving Avg Val Loss: 0.616684\n",
            "Epoch 950/2000, Train Loss: 0.002498, Val Loss: 0.040506\n",
            "Epoch 950/2000, Rel Train Loss: 61.50%, Rel Val Loss: 59.79%\n",
            "Moving Avg Val Loss: 0.686875\n",
            "Epoch 951/2000, Train Loss: 0.001545, Val Loss: 0.045965\n",
            "Epoch 951/2000, Rel Train Loss: 60.25%, Rel Val Loss: 79.50%\n",
            "Moving Avg Val Loss: 0.717040\n",
            "Epoch 952/2000, Train Loss: 0.001379, Val Loss: 0.046514\n",
            "Epoch 952/2000, Rel Train Loss: 60.67%, Rel Val Loss: 64.50%\n",
            "Moving Avg Val Loss: 0.783280\n",
            "Epoch 953/2000, Train Loss: 0.001806, Val Loss: 0.042648\n",
            "Epoch 953/2000, Rel Train Loss: 62.41%, Rel Val Loss: 110.23%\n",
            "Moving Avg Val Loss: 0.736118\n",
            "Epoch 954/2000, Train Loss: 0.002097, Val Loss: 0.050252\n",
            "Epoch 954/2000, Rel Train Loss: 67.52%, Rel Val Loss: 54.04%\n",
            "Moving Avg Val Loss: 0.713758\n",
            "Epoch 955/2000, Train Loss: 0.001137, Val Loss: 0.041257\n",
            "Epoch 955/2000, Rel Train Loss: 47.09%, Rel Val Loss: 48.61%\n",
            "Moving Avg Val Loss: 0.783539\n",
            "Epoch 956/2000, Train Loss: 0.003423, Val Loss: 0.047362\n",
            "Epoch 956/2000, Rel Train Loss: 67.47%, Rel Val Loss: 114.39%\n",
            "Moving Avg Val Loss: 0.751985\n",
            "Epoch 957/2000, Train Loss: 0.001251, Val Loss: 0.043170\n",
            "Epoch 957/2000, Rel Train Loss: 67.82%, Rel Val Loss: 48.72%\n",
            "Moving Avg Val Loss: 0.624846\n",
            "Epoch 958/2000, Train Loss: 0.000821, Val Loss: 0.042041\n",
            "Epoch 958/2000, Rel Train Loss: 44.76%, Rel Val Loss: 46.66%\n",
            "Moving Avg Val Loss: 0.616865\n",
            "Epoch 959/2000, Train Loss: 0.001056, Val Loss: 0.043427\n",
            "Epoch 959/2000, Rel Train Loss: 51.84%, Rel Val Loss: 50.05%\n",
            "Moving Avg Val Loss: 0.608411\n",
            "Epoch 960/2000, Train Loss: 0.000746, Val Loss: 0.044214\n",
            "Epoch 960/2000, Rel Train Loss: 43.25%, Rel Val Loss: 44.39%\n",
            "Moving Avg Val Loss: 0.468794\n",
            "Epoch 961/2000, Train Loss: 0.001383, Val Loss: 0.044540\n",
            "Epoch 961/2000, Rel Train Loss: 50.49%, Rel Val Loss: 44.58%\n",
            "Moving Avg Val Loss: 0.657919\n",
            "Epoch 962/2000, Train Loss: 0.002050, Val Loss: 0.046205\n",
            "Epoch 962/2000, Rel Train Loss: 79.01%, Rel Val Loss: 143.28%\n",
            "Moving Avg Val Loss: 0.705350\n",
            "Epoch 963/2000, Train Loss: 0.002041, Val Loss: 0.045780\n",
            "Epoch 963/2000, Rel Train Loss: 94.93%, Rel Val Loss: 70.37%\n",
            "Moving Avg Val Loss: 0.738898\n",
            "Epoch 964/2000, Train Loss: 0.001309, Val Loss: 0.043977\n",
            "Epoch 964/2000, Rel Train Loss: 88.92%, Rel Val Loss: 66.83%\n",
            "Moving Avg Val Loss: 0.845650\n",
            "Epoch 965/2000, Train Loss: 0.002108, Val Loss: 0.046105\n",
            "Epoch 965/2000, Rel Train Loss: 78.02%, Rel Val Loss: 97.76%\n",
            "Moving Avg Val Loss: 0.855962\n",
            "Epoch 966/2000, Train Loss: 0.001302, Val Loss: 0.045161\n",
            "Epoch 966/2000, Rel Train Loss: 68.31%, Rel Val Loss: 49.74%\n",
            "Moving Avg Val Loss: 0.659205\n",
            "Epoch 967/2000, Train Loss: 0.001044, Val Loss: 0.044252\n",
            "Epoch 967/2000, Rel Train Loss: 43.03%, Rel Val Loss: 44.90%\n",
            "Moving Avg Val Loss: 0.672859\n",
            "Epoch 968/2000, Train Loss: 0.001712, Val Loss: 0.043187\n",
            "Epoch 968/2000, Rel Train Loss: 53.25%, Rel Val Loss: 77.20%\n",
            "Moving Avg Val Loss: 0.710203\n",
            "Epoch 969/2000, Train Loss: 0.003005, Val Loss: 0.047750\n",
            "Epoch 969/2000, Rel Train Loss: 82.52%, Rel Val Loss: 85.50%\n",
            "Moving Avg Val Loss: 0.616939\n",
            "Epoch 970/2000, Train Loss: 0.001779, Val Loss: 0.043823\n",
            "Epoch 970/2000, Rel Train Loss: 88.96%, Rel Val Loss: 51.13%\n",
            "Moving Avg Val Loss: 0.623391\n",
            "Epoch 971/2000, Train Loss: 0.001195, Val Loss: 0.053099\n",
            "Epoch 971/2000, Rel Train Loss: 58.01%, Rel Val Loss: 52.96%\n",
            "Moving Avg Val Loss: 0.716121\n",
            "Epoch 972/2000, Train Loss: 0.002304, Val Loss: 0.049021\n",
            "Epoch 972/2000, Rel Train Loss: 54.06%, Rel Val Loss: 91.27%\n",
            "Moving Avg Val Loss: 0.721995\n",
            "Epoch 973/2000, Train Loss: 0.002203, Val Loss: 0.062398\n",
            "Epoch 973/2000, Rel Train Loss: 68.87%, Rel Val Loss: 80.14%\n",
            "Moving Avg Val Loss: 0.724484\n",
            "Epoch 974/2000, Train Loss: 0.006819, Val Loss: 0.046241\n",
            "Epoch 974/2000, Rel Train Loss: 88.93%, Rel Val Loss: 86.74%\n",
            "Moving Avg Val Loss: 0.729761\n",
            "Epoch 975/2000, Train Loss: 0.002768, Val Loss: 0.042607\n",
            "Epoch 975/2000, Rel Train Loss: 91.75%, Rel Val Loss: 53.77%\n",
            "Moving Avg Val Loss: 0.732791\n",
            "Epoch 976/2000, Train Loss: 0.003156, Val Loss: 0.052837\n",
            "Epoch 976/2000, Rel Train Loss: 73.51%, Rel Val Loss: 54.48%\n",
            "Moving Avg Val Loss: 0.814571\n",
            "Epoch 977/2000, Train Loss: 0.002990, Val Loss: 0.053428\n",
            "Epoch 977/2000, Rel Train Loss: 89.21%, Rel Val Loss: 132.16%\n",
            "Moving Avg Val Loss: 0.807692\n",
            "Epoch 978/2000, Train Loss: 0.003550, Val Loss: 0.047274\n",
            "Epoch 978/2000, Rel Train Loss: 92.42%, Rel Val Loss: 76.70%\n",
            "Moving Avg Val Loss: 0.729362\n",
            "Epoch 979/2000, Train Loss: 0.001866, Val Loss: 0.044268\n",
            "Epoch 979/2000, Rel Train Loss: 72.50%, Rel Val Loss: 47.58%\n",
            "Moving Avg Val Loss: 0.778212\n",
            "Epoch 980/2000, Train Loss: 0.001021, Val Loss: 0.044599\n",
            "Epoch 980/2000, Rel Train Loss: 44.35%, Rel Val Loss: 78.19%\n",
            "Moving Avg Val Loss: 0.755161\n",
            "Epoch 981/2000, Train Loss: 0.001616, Val Loss: 0.046456\n",
            "Epoch 981/2000, Rel Train Loss: 60.18%, Rel Val Loss: 42.95%\n",
            "Moving Avg Val Loss: 0.584368\n",
            "Epoch 982/2000, Train Loss: 0.000743, Val Loss: 0.044560\n",
            "Epoch 982/2000, Rel Train Loss: 43.47%, Rel Val Loss: 46.76%\n",
            "Moving Avg Val Loss: 0.533362\n",
            "Epoch 983/2000, Train Loss: 0.000728, Val Loss: 0.044499\n",
            "Epoch 983/2000, Rel Train Loss: 44.10%, Rel Val Loss: 51.20%\n",
            "Moving Avg Val Loss: 0.528348\n",
            "Epoch 984/2000, Train Loss: 0.000534, Val Loss: 0.043021\n",
            "Epoch 984/2000, Rel Train Loss: 44.31%, Rel Val Loss: 45.07%\n",
            "Moving Avg Val Loss: 0.457553\n",
            "Epoch 985/2000, Train Loss: 0.000721, Val Loss: 0.044888\n",
            "Epoch 985/2000, Rel Train Loss: 38.60%, Rel Val Loss: 42.80%\n",
            "Moving Avg Val Loss: 0.558783\n",
            "Epoch 986/2000, Train Loss: 0.002175, Val Loss: 0.047652\n",
            "Epoch 986/2000, Rel Train Loss: 61.75%, Rel Val Loss: 93.57%\n",
            "Moving Avg Val Loss: 0.553344\n",
            "Epoch 987/2000, Train Loss: 0.000853, Val Loss: 0.041059\n",
            "Epoch 987/2000, Rel Train Loss: 55.94%, Rel Val Loss: 44.04%\n",
            "Moving Avg Val Loss: 0.583332\n",
            "Epoch 988/2000, Train Loss: 0.001218, Val Loss: 0.044979\n",
            "Epoch 988/2000, Rel Train Loss: 55.76%, Rel Val Loss: 66.19%\n",
            "Moving Avg Val Loss: 0.697298\n",
            "Epoch 989/2000, Train Loss: 0.002199, Val Loss: 0.045504\n",
            "Epoch 989/2000, Rel Train Loss: 65.39%, Rel Val Loss: 102.05%\n",
            "Moving Avg Val Loss: 0.732215\n",
            "Epoch 990/2000, Train Loss: 0.002414, Val Loss: 0.044952\n",
            "Epoch 990/2000, Rel Train Loss: 81.08%, Rel Val Loss: 60.25%\n",
            "Moving Avg Val Loss: 0.638041\n",
            "Epoch 991/2000, Train Loss: 0.001688, Val Loss: 0.040332\n",
            "Epoch 991/2000, Rel Train Loss: 110.55%, Rel Val Loss: 46.48%\n",
            "Moving Avg Val Loss: 0.651678\n",
            "Epoch 992/2000, Train Loss: 0.002564, Val Loss: 0.053782\n",
            "Epoch 992/2000, Rel Train Loss: 56.64%, Rel Val Loss: 50.86%\n",
            "Moving Avg Val Loss: 0.727702\n",
            "Epoch 993/2000, Train Loss: 0.003470, Val Loss: 0.049643\n",
            "Epoch 993/2000, Rel Train Loss: 66.73%, Rel Val Loss: 104.20%\n",
            "Moving Avg Val Loss: 0.622027\n",
            "Epoch 994/2000, Train Loss: 0.002093, Val Loss: 0.049226\n",
            "Epoch 994/2000, Rel Train Loss: 78.28%, Rel Val Loss: 49.22%\n",
            "Moving Avg Val Loss: 0.596328\n",
            "Epoch 995/2000, Train Loss: 0.002806, Val Loss: 0.053786\n",
            "Epoch 995/2000, Rel Train Loss: 70.06%, Rel Val Loss: 47.40%\n",
            "Moving Avg Val Loss: 0.770422\n",
            "Epoch 996/2000, Train Loss: 0.003134, Val Loss: 0.059304\n",
            "Epoch 996/2000, Rel Train Loss: 106.13%, Rel Val Loss: 133.53%\n",
            "Moving Avg Val Loss: 0.826738\n",
            "Epoch 997/2000, Train Loss: 0.004390, Val Loss: 0.045813\n",
            "Epoch 997/2000, Rel Train Loss: 98.82%, Rel Val Loss: 79.02%\n",
            "Moving Avg Val Loss: 0.711000\n",
            "Epoch 998/2000, Train Loss: 0.002470, Val Loss: 0.049353\n",
            "Epoch 998/2000, Rel Train Loss: 89.51%, Rel Val Loss: 46.33%\n",
            "Moving Avg Val Loss: 0.769604\n",
            "Epoch 999/2000, Train Loss: 0.001234, Val Loss: 0.041713\n",
            "Epoch 999/2000, Rel Train Loss: 59.57%, Rel Val Loss: 78.52%\n",
            "Moving Avg Val Loss: 0.845149\n",
            "Epoch 1000/2000, Train Loss: 0.002438, Val Loss: 0.057962\n",
            "Epoch 1000/2000, Rel Train Loss: 66.41%, Rel Val Loss: 85.18%\n",
            "Moving Avg Val Loss: 0.767137\n",
            "Epoch 1001/2000, Train Loss: 0.003041, Val Loss: 0.044979\n",
            "Epoch 1001/2000, Rel Train Loss: 74.55%, Rel Val Loss: 94.52%\n",
            "Moving Avg Val Loss: 0.704765\n",
            "Epoch 1002/2000, Train Loss: 0.001377, Val Loss: 0.050905\n",
            "Epoch 1002/2000, Rel Train Loss: 59.81%, Rel Val Loss: 47.83%\n",
            "Moving Avg Val Loss: 0.705786\n",
            "Epoch 1003/2000, Train Loss: 0.000899, Val Loss: 0.042591\n",
            "Epoch 1003/2000, Rel Train Loss: 45.54%, Rel Val Loss: 46.84%\n",
            "Moving Avg Val Loss: 0.634508\n",
            "Epoch 1004/2000, Train Loss: 0.000493, Val Loss: 0.043815\n",
            "Epoch 1004/2000, Rel Train Loss: 39.85%, Rel Val Loss: 42.88%\n",
            "Moving Avg Val Loss: 0.545428\n",
            "Epoch 1005/2000, Train Loss: 0.000541, Val Loss: 0.042408\n",
            "Epoch 1005/2000, Rel Train Loss: 39.48%, Rel Val Loss: 40.64%\n",
            "Moving Avg Val Loss: 0.456257\n",
            "Epoch 1006/2000, Train Loss: 0.000885, Val Loss: 0.042279\n",
            "Epoch 1006/2000, Rel Train Loss: 44.87%, Rel Val Loss: 49.93%\n",
            "Moving Avg Val Loss: 0.446871\n",
            "Epoch 1007/2000, Train Loss: 0.000739, Val Loss: 0.043514\n",
            "Epoch 1007/2000, Rel Train Loss: 40.95%, Rel Val Loss: 43.14%\n",
            "Moving Avg Val Loss: 0.449886\n",
            "Epoch 1008/2000, Train Loss: 0.000570, Val Loss: 0.044444\n",
            "Epoch 1008/2000, Rel Train Loss: 37.93%, Rel Val Loss: 48.35%\n",
            "Moving Avg Val Loss: 0.448632\n",
            "Epoch 1009/2000, Train Loss: 0.000468, Val Loss: 0.042211\n",
            "Epoch 1009/2000, Rel Train Loss: 37.35%, Rel Val Loss: 42.25%\n",
            "Moving Avg Val Loss: 0.477052\n",
            "Epoch 1010/2000, Train Loss: 0.000948, Val Loss: 0.042683\n",
            "Epoch 1010/2000, Rel Train Loss: 44.73%, Rel Val Loss: 54.85%\n",
            "Moving Avg Val Loss: 0.484171\n",
            "Epoch 1011/2000, Train Loss: 0.001409, Val Loss: 0.046010\n",
            "Epoch 1011/2000, Rel Train Loss: 53.52%, Rel Val Loss: 53.49%\n",
            "Moving Avg Val Loss: 0.501527\n",
            "Epoch 1012/2000, Train Loss: 0.001862, Val Loss: 0.040475\n",
            "Epoch 1012/2000, Rel Train Loss: 55.70%, Rel Val Loss: 51.82%\n",
            "Moving Avg Val Loss: 0.505648\n",
            "Epoch 1013/2000, Train Loss: 0.002556, Val Loss: 0.044779\n",
            "Epoch 1013/2000, Rel Train Loss: 53.41%, Rel Val Loss: 50.41%\n",
            "Moving Avg Val Loss: 0.596087\n",
            "Epoch 1014/2000, Train Loss: 0.003308, Val Loss: 0.048067\n",
            "Epoch 1014/2000, Rel Train Loss: 56.71%, Rel Val Loss: 87.47%\n",
            "Moving Avg Val Loss: 0.579549\n",
            "Epoch 1015/2000, Train Loss: 0.003008, Val Loss: 0.043753\n",
            "Epoch 1015/2000, Rel Train Loss: 90.74%, Rel Val Loss: 46.58%\n",
            "Moving Avg Val Loss: 0.642833\n",
            "Epoch 1016/2000, Train Loss: 0.001702, Val Loss: 0.048308\n",
            "Epoch 1016/2000, Rel Train Loss: 78.85%, Rel Val Loss: 85.14%\n",
            "Moving Avg Val Loss: 0.631619\n",
            "Epoch 1017/2000, Train Loss: 0.001048, Val Loss: 0.041749\n",
            "Epoch 1017/2000, Rel Train Loss: 52.25%, Rel Val Loss: 46.21%\n",
            "Moving Avg Val Loss: 0.631583\n",
            "Epoch 1018/2000, Train Loss: 0.001277, Val Loss: 0.047109\n",
            "Epoch 1018/2000, Rel Train Loss: 46.72%, Rel Val Loss: 50.39%\n",
            "Moving Avg Val Loss: 0.634627\n",
            "Epoch 1019/2000, Train Loss: 0.002206, Val Loss: 0.040146\n",
            "Epoch 1019/2000, Rel Train Loss: 65.08%, Rel Val Loss: 89.00%\n",
            "Moving Avg Val Loss: 0.629059\n",
            "Epoch 1020/2000, Train Loss: 0.001085, Val Loss: 0.043150\n",
            "Epoch 1020/2000, Rel Train Loss: 79.80%, Rel Val Loss: 43.79%\n",
            "Moving Avg Val Loss: 0.547960\n",
            "Epoch 1021/2000, Train Loss: 0.000736, Val Loss: 0.044113\n",
            "Epoch 1021/2000, Rel Train Loss: 46.18%, Rel Val Loss: 44.59%\n",
            "Moving Avg Val Loss: 0.596273\n",
            "Epoch 1022/2000, Train Loss: 0.001143, Val Loss: 0.041175\n",
            "Epoch 1022/2000, Rel Train Loss: 50.72%, Rel Val Loss: 70.37%\n",
            "Moving Avg Val Loss: 0.588168\n",
            "Epoch 1023/2000, Train Loss: 0.000772, Val Loss: 0.044725\n",
            "Epoch 1023/2000, Rel Train Loss: 46.12%, Rel Val Loss: 46.34%\n",
            "Moving Avg Val Loss: 0.509182\n",
            "Epoch 1024/2000, Train Loss: 0.001278, Val Loss: 0.041373\n",
            "Epoch 1024/2000, Rel Train Loss: 47.94%, Rel Val Loss: 49.50%\n",
            "Moving Avg Val Loss: 0.524547\n",
            "Epoch 1025/2000, Train Loss: 0.002022, Val Loss: 0.049372\n",
            "Epoch 1025/2000, Rel Train Loss: 59.44%, Rel Val Loss: 51.48%\n",
            "Moving Avg Val Loss: 0.582376\n",
            "Epoch 1026/2000, Train Loss: 0.002170, Val Loss: 0.042888\n",
            "Epoch 1026/2000, Rel Train Loss: 58.47%, Rel Val Loss: 73.50%\n",
            "Moving Avg Val Loss: 0.620141\n",
            "Epoch 1027/2000, Train Loss: 0.003553, Val Loss: 0.050396\n",
            "Epoch 1027/2000, Rel Train Loss: 60.36%, Rel Val Loss: 89.25%\n",
            "Moving Avg Val Loss: 0.616369\n",
            "Epoch 1028/2000, Train Loss: 0.001445, Val Loss: 0.048610\n",
            "Epoch 1028/2000, Rel Train Loss: 67.42%, Rel Val Loss: 44.46%\n",
            "Moving Avg Val Loss: 0.672752\n",
            "Epoch 1029/2000, Train Loss: 0.002440, Val Loss: 0.049147\n",
            "Epoch 1029/2000, Rel Train Loss: 88.45%, Rel Val Loss: 77.69%\n",
            "Moving Avg Val Loss: 0.812795\n",
            "Epoch 1030/2000, Train Loss: 0.002949, Val Loss: 0.055573\n",
            "Epoch 1030/2000, Rel Train Loss: 95.21%, Rel Val Loss: 121.50%\n",
            "Moving Avg Val Loss: 0.764050\n",
            "Epoch 1031/2000, Train Loss: 0.002313, Val Loss: 0.048061\n",
            "Epoch 1031/2000, Rel Train Loss: 73.61%, Rel Val Loss: 49.13%\n",
            "Moving Avg Val Loss: 0.764009\n",
            "Epoch 1032/2000, Train Loss: 0.001859, Val Loss: 0.046707\n",
            "Epoch 1032/2000, Rel Train Loss: 53.54%, Rel Val Loss: 89.23%\n",
            "Moving Avg Val Loss: 0.761891\n",
            "Epoch 1033/2000, Train Loss: 0.001157, Val Loss: 0.046480\n",
            "Epoch 1033/2000, Rel Train Loss: 55.95%, Rel Val Loss: 43.40%\n",
            "Moving Avg Val Loss: 0.693360\n",
            "Epoch 1034/2000, Train Loss: 0.000703, Val Loss: 0.042667\n",
            "Epoch 1034/2000, Rel Train Loss: 44.10%, Rel Val Loss: 43.43%\n",
            "Moving Avg Val Loss: 0.535500\n",
            "Epoch 1035/2000, Train Loss: 0.000605, Val Loss: 0.045810\n",
            "Epoch 1035/2000, Rel Train Loss: 36.70%, Rel Val Loss: 42.57%\n",
            "Moving Avg Val Loss: 0.523237\n",
            "Epoch 1036/2000, Train Loss: 0.000722, Val Loss: 0.044204\n",
            "Epoch 1036/2000, Rel Train Loss: 42.99%, Rel Val Loss: 43.00%\n",
            "Moving Avg Val Loss: 0.526254\n",
            "Epoch 1037/2000, Train Loss: 0.001079, Val Loss: 0.044226\n",
            "Epoch 1037/2000, Rel Train Loss: 55.72%, Rel Val Loss: 90.74%\n",
            "Moving Avg Val Loss: 0.578177\n",
            "Epoch 1038/2000, Train Loss: 0.002006, Val Loss: 0.043212\n",
            "Epoch 1038/2000, Rel Train Loss: 69.40%, Rel Val Loss: 69.36%\n",
            "Moving Avg Val Loss: 0.575601\n",
            "Epoch 1039/2000, Train Loss: 0.000810, Val Loss: 0.040776\n",
            "Epoch 1039/2000, Rel Train Loss: 68.08%, Rel Val Loss: 42.14%\n",
            "Moving Avg Val Loss: 0.574524\n",
            "Epoch 1040/2000, Train Loss: 0.000769, Val Loss: 0.043337\n",
            "Epoch 1040/2000, Rel Train Loss: 37.83%, Rel Val Loss: 42.03%\n",
            "Moving Avg Val Loss: 0.593140\n",
            "Epoch 1041/2000, Train Loss: 0.000675, Val Loss: 0.043936\n",
            "Epoch 1041/2000, Rel Train Loss: 42.13%, Rel Val Loss: 52.30%\n",
            "Moving Avg Val Loss: 0.534580\n",
            "Epoch 1042/2000, Train Loss: 0.000877, Val Loss: 0.043305\n",
            "Epoch 1042/2000, Rel Train Loss: 41.71%, Rel Val Loss: 61.46%\n",
            "Moving Avg Val Loss: 0.499744\n",
            "Epoch 1043/2000, Train Loss: 0.000775, Val Loss: 0.044243\n",
            "Epoch 1043/2000, Rel Train Loss: 45.95%, Rel Val Loss: 51.94%\n",
            "Moving Avg Val Loss: 0.565937\n",
            "Epoch 1044/2000, Train Loss: 0.000994, Val Loss: 0.042148\n",
            "Epoch 1044/2000, Rel Train Loss: 52.87%, Rel Val Loss: 75.24%\n",
            "Moving Avg Val Loss: 0.568125\n",
            "Epoch 1045/2000, Train Loss: 0.000538, Val Loss: 0.045711\n",
            "Epoch 1045/2000, Rel Train Loss: 48.72%, Rel Val Loss: 43.12%\n",
            "Moving Avg Val Loss: 0.596278\n",
            "Epoch 1046/2000, Train Loss: 0.000958, Val Loss: 0.045538\n",
            "Epoch 1046/2000, Rel Train Loss: 40.62%, Rel Val Loss: 66.38%\n",
            "Moving Avg Val Loss: 0.627649\n",
            "Epoch 1047/2000, Train Loss: 0.001918, Val Loss: 0.044371\n",
            "Epoch 1047/2000, Rel Train Loss: 67.70%, Rel Val Loss: 77.14%\n",
            "Moving Avg Val Loss: 0.609014\n",
            "Epoch 1048/2000, Train Loss: 0.001341, Val Loss: 0.043055\n",
            "Epoch 1048/2000, Rel Train Loss: 82.20%, Rel Val Loss: 42.62%\n",
            "Moving Avg Val Loss: 0.562096\n",
            "Epoch 1049/2000, Train Loss: 0.001297, Val Loss: 0.042717\n",
            "Epoch 1049/2000, Rel Train Loss: 52.71%, Rel Val Loss: 51.78%\n",
            "Moving Avg Val Loss: 0.580965\n",
            "Epoch 1050/2000, Train Loss: 0.000698, Val Loss: 0.043980\n",
            "Epoch 1050/2000, Rel Train Loss: 47.97%, Rel Val Loss: 52.56%\n",
            "Moving Avg Val Loss: 0.552702\n",
            "Epoch 1051/2000, Train Loss: 0.000764, Val Loss: 0.043365\n",
            "Epoch 1051/2000, Rel Train Loss: 40.83%, Rel Val Loss: 52.25%\n",
            "Moving Avg Val Loss: 0.485178\n",
            "Epoch 1052/2000, Train Loss: 0.000702, Val Loss: 0.043597\n",
            "Epoch 1052/2000, Rel Train Loss: 43.65%, Rel Val Loss: 43.38%\n",
            "Moving Avg Val Loss: 0.479973\n",
            "Epoch 1053/2000, Train Loss: 0.000532, Val Loss: 0.043537\n",
            "Epoch 1053/2000, Rel Train Loss: 36.24%, Rel Val Loss: 40.02%\n",
            "Moving Avg Val Loss: 0.465348\n",
            "Epoch 1054/2000, Train Loss: 0.000569, Val Loss: 0.043434\n",
            "Epoch 1054/2000, Rel Train Loss: 40.28%, Rel Val Loss: 44.47%\n",
            "Moving Avg Val Loss: 0.455292\n",
            "Epoch 1055/2000, Train Loss: 0.000617, Val Loss: 0.042274\n",
            "Epoch 1055/2000, Rel Train Loss: 36.55%, Rel Val Loss: 47.53%\n",
            "Moving Avg Val Loss: 0.455438\n",
            "Epoch 1056/2000, Train Loss: 0.000882, Val Loss: 0.044992\n",
            "Epoch 1056/2000, Rel Train Loss: 45.10%, Rel Val Loss: 52.32%\n",
            "Moving Avg Val Loss: 0.451850\n",
            "Epoch 1057/2000, Train Loss: 0.000448, Val Loss: 0.042118\n",
            "Epoch 1057/2000, Rel Train Loss: 41.68%, Rel Val Loss: 41.59%\n",
            "Moving Avg Val Loss: 0.466121\n",
            "Epoch 1058/2000, Train Loss: 0.000638, Val Loss: 0.045819\n",
            "Epoch 1058/2000, Rel Train Loss: 36.05%, Rel Val Loss: 47.16%\n",
            "Moving Avg Val Loss: 0.539378\n",
            "Epoch 1059/2000, Train Loss: 0.002346, Val Loss: 0.046278\n",
            "Epoch 1059/2000, Rel Train Loss: 58.40%, Rel Val Loss: 81.09%\n",
            "Moving Avg Val Loss: 0.658273\n",
            "Epoch 1060/2000, Train Loss: 0.002713, Val Loss: 0.050064\n",
            "Epoch 1060/2000, Rel Train Loss: 90.60%, Rel Val Loss: 106.98%\n",
            "Moving Avg Val Loss: 0.688536\n",
            "Epoch 1061/2000, Train Loss: 0.001661, Val Loss: 0.052204\n",
            "Epoch 1061/2000, Rel Train Loss: 71.15%, Rel Val Loss: 67.45%\n",
            "Moving Avg Val Loss: 0.790353\n",
            "Epoch 1062/2000, Train Loss: 0.004730, Val Loss: 0.053946\n",
            "Epoch 1062/2000, Rel Train Loss: 63.32%, Rel Val Loss: 92.50%\n",
            "Moving Avg Val Loss: 0.893265\n",
            "Epoch 1063/2000, Train Loss: 0.006748, Val Loss: 0.052113\n",
            "Epoch 1063/2000, Rel Train Loss: 126.04%, Rel Val Loss: 98.61%\n",
            "Moving Avg Val Loss: 0.926951\n",
            "Epoch 1064/2000, Train Loss: 0.004449, Val Loss: 0.042376\n",
            "Epoch 1064/2000, Rel Train Loss: 152.91%, Rel Val Loss: 97.94%\n",
            "Moving Avg Val Loss: 0.988390\n",
            "Epoch 1065/2000, Train Loss: 0.002481, Val Loss: 0.047116\n",
            "Epoch 1065/2000, Rel Train Loss: 95.19%, Rel Val Loss: 137.70%\n",
            "Moving Avg Val Loss: 0.978154\n",
            "Epoch 1066/2000, Train Loss: 0.002234, Val Loss: 0.047854\n",
            "Epoch 1066/2000, Rel Train Loss: 65.36%, Rel Val Loss: 62.34%\n",
            "Moving Avg Val Loss: 0.910249\n",
            "Epoch 1067/2000, Train Loss: 0.001411, Val Loss: 0.039417\n",
            "Epoch 1067/2000, Rel Train Loss: 52.72%, Rel Val Loss: 58.54%\n",
            "Moving Avg Val Loss: 0.848326\n",
            "Epoch 1068/2000, Train Loss: 0.003410, Val Loss: 0.047723\n",
            "Epoch 1068/2000, Rel Train Loss: 61.22%, Rel Val Loss: 67.65%\n",
            "Moving Avg Val Loss: 0.834815\n",
            "Epoch 1069/2000, Train Loss: 0.002728, Val Loss: 0.050946\n",
            "Epoch 1069/2000, Rel Train Loss: 78.21%, Rel Val Loss: 91.18%\n",
            "Moving Avg Val Loss: 0.724748\n",
            "Epoch 1070/2000, Train Loss: 0.002796, Val Loss: 0.047101\n",
            "Epoch 1070/2000, Rel Train Loss: 89.23%, Rel Val Loss: 82.66%\n",
            "Moving Avg Val Loss: 0.685062\n",
            "Epoch 1071/2000, Train Loss: 0.001132, Val Loss: 0.040132\n",
            "Epoch 1071/2000, Rel Train Loss: 59.23%, Rel Val Loss: 42.49%\n",
            "Moving Avg Val Loss: 0.655387\n",
            "Epoch 1072/2000, Train Loss: 0.000659, Val Loss: 0.047095\n",
            "Epoch 1072/2000, Rel Train Loss: 37.55%, Rel Val Loss: 43.71%\n",
            "Moving Avg Val Loss: 0.602149\n",
            "Epoch 1073/2000, Train Loss: 0.000567, Val Loss: 0.040209\n",
            "Epoch 1073/2000, Rel Train Loss: 37.20%, Rel Val Loss: 41.03%\n",
            "Moving Avg Val Loss: 0.518291\n",
            "Epoch 1074/2000, Train Loss: 0.000537, Val Loss: 0.043910\n",
            "Epoch 1074/2000, Rel Train Loss: 37.69%, Rel Val Loss: 49.25%\n",
            "Moving Avg Val Loss: 0.442628\n",
            "Epoch 1075/2000, Train Loss: 0.000434, Val Loss: 0.042937\n",
            "Epoch 1075/2000, Rel Train Loss: 38.01%, Rel Val Loss: 44.83%\n",
            "Moving Avg Val Loss: 0.442896\n",
            "Epoch 1076/2000, Train Loss: 0.001038, Val Loss: 0.043820\n",
            "Epoch 1076/2000, Rel Train Loss: 45.60%, Rel Val Loss: 42.63%\n",
            "Moving Avg Val Loss: 0.433363\n",
            "Epoch 1077/2000, Train Loss: 0.000712, Val Loss: 0.040656\n",
            "Epoch 1077/2000, Rel Train Loss: 44.88%, Rel Val Loss: 38.94%\n",
            "Moving Avg Val Loss: 0.446389\n",
            "Epoch 1078/2000, Train Loss: 0.000524, Val Loss: 0.042269\n",
            "Epoch 1078/2000, Rel Train Loss: 41.51%, Rel Val Loss: 47.54%\n",
            "Moving Avg Val Loss: 0.446973\n",
            "Epoch 1079/2000, Train Loss: 0.000472, Val Loss: 0.042401\n",
            "Epoch 1079/2000, Rel Train Loss: 41.27%, Rel Val Loss: 49.55%\n",
            "Moving Avg Val Loss: 0.436171\n",
            "Epoch 1080/2000, Train Loss: 0.000423, Val Loss: 0.040648\n",
            "Epoch 1080/2000, Rel Train Loss: 35.70%, Rel Val Loss: 39.43%\n",
            "Moving Avg Val Loss: 0.429051\n",
            "Epoch 1081/2000, Train Loss: 0.000453, Val Loss: 0.042365\n",
            "Epoch 1081/2000, Rel Train Loss: 37.47%, Rel Val Loss: 39.07%\n",
            "Moving Avg Val Loss: 0.431802\n",
            "Epoch 1082/2000, Train Loss: 0.000664, Val Loss: 0.041383\n",
            "Epoch 1082/2000, Rel Train Loss: 45.21%, Rel Val Loss: 40.31%\n",
            "Moving Avg Val Loss: 0.418058\n",
            "Epoch 1083/2000, Train Loss: 0.000607, Val Loss: 0.042874\n",
            "Epoch 1083/2000, Rel Train Loss: 43.23%, Rel Val Loss: 40.67%\n",
            "Moving Avg Val Loss: 0.421554\n",
            "Epoch 1084/2000, Train Loss: 0.000730, Val Loss: 0.041383\n",
            "Epoch 1084/2000, Rel Train Loss: 34.94%, Rel Val Loss: 51.29%\n",
            "Moving Avg Val Loss: 0.425260\n",
            "Epoch 1085/2000, Train Loss: 0.000427, Val Loss: 0.042614\n",
            "Epoch 1085/2000, Rel Train Loss: 37.41%, Rel Val Loss: 41.28%\n",
            "Moving Avg Val Loss: 0.426192\n",
            "Epoch 1086/2000, Train Loss: 0.000365, Val Loss: 0.040990\n",
            "Epoch 1086/2000, Rel Train Loss: 35.18%, Rel Val Loss: 39.53%\n",
            "Moving Avg Val Loss: 0.438680\n",
            "Epoch 1087/2000, Train Loss: 0.000984, Val Loss: 0.041838\n",
            "Epoch 1087/2000, Rel Train Loss: 39.40%, Rel Val Loss: 46.56%\n",
            "Moving Avg Val Loss: 0.433702\n",
            "Epoch 1088/2000, Train Loss: 0.000467, Val Loss: 0.041686\n",
            "Epoch 1088/2000, Rel Train Loss: 38.15%, Rel Val Loss: 38.18%\n",
            "Moving Avg Val Loss: 0.419660\n",
            "Epoch 1089/2000, Train Loss: 0.000547, Val Loss: 0.042989\n",
            "Epoch 1089/2000, Rel Train Loss: 39.83%, Rel Val Loss: 44.27%\n",
            "Moving Avg Val Loss: 0.416318\n",
            "Epoch 1090/2000, Train Loss: 0.000544, Val Loss: 0.041227\n",
            "Epoch 1090/2000, Rel Train Loss: 37.95%, Rel Val Loss: 39.61%\n",
            "Moving Avg Val Loss: 0.425797\n",
            "Epoch 1091/2000, Train Loss: 0.000344, Val Loss: 0.042323\n",
            "Epoch 1091/2000, Rel Train Loss: 34.57%, Rel Val Loss: 44.27%\n",
            "Moving Avg Val Loss: 0.412682\n",
            "Epoch 1092/2000, Train Loss: 0.000324, Val Loss: 0.041247\n",
            "Epoch 1092/2000, Rel Train Loss: 32.65%, Rel Val Loss: 40.00%\n",
            "Moving Avg Val Loss: 0.415423\n",
            "Epoch 1093/2000, Train Loss: 0.000318, Val Loss: 0.041800\n",
            "Epoch 1093/2000, Rel Train Loss: 32.70%, Rel Val Loss: 39.55%\n",
            "Moving Avg Val Loss: 0.413562\n",
            "Epoch 1094/2000, Train Loss: 0.000326, Val Loss: 0.041766\n",
            "Epoch 1094/2000, Rel Train Loss: 34.00%, Rel Val Loss: 43.34%\n",
            "Moving Avg Val Loss: 0.412561\n",
            "Epoch 1095/2000, Train Loss: 0.000308, Val Loss: 0.041444\n",
            "Epoch 1095/2000, Rel Train Loss: 33.60%, Rel Val Loss: 39.11%\n",
            "Moving Avg Val Loss: 0.404830\n",
            "Epoch 1096/2000, Train Loss: 0.000308, Val Loss: 0.042321\n",
            "Epoch 1096/2000, Rel Train Loss: 35.73%, Rel Val Loss: 40.41%\n",
            "Moving Avg Val Loss: 0.407272\n",
            "Epoch 1097/2000, Train Loss: 0.000300, Val Loss: 0.041958\n",
            "Epoch 1097/2000, Rel Train Loss: 31.83%, Rel Val Loss: 41.22%\n",
            "Moving Avg Val Loss: 0.408148\n",
            "Epoch 1098/2000, Train Loss: 0.000299, Val Loss: 0.042061\n",
            "Epoch 1098/2000, Rel Train Loss: 33.75%, Rel Val Loss: 39.99%\n",
            "Moving Avg Val Loss: 0.409300\n",
            "Epoch 1099/2000, Train Loss: 0.000344, Val Loss: 0.042887\n",
            "Epoch 1099/2000, Rel Train Loss: 36.61%, Rel Val Loss: 43.92%\n",
            "Moving Avg Val Loss: 0.409204\n",
            "Epoch 1100/2000, Train Loss: 0.000334, Val Loss: 0.042818\n",
            "Epoch 1100/2000, Rel Train Loss: 34.58%, Rel Val Loss: 39.06%\n",
            "Moving Avg Val Loss: 0.430778\n",
            "Epoch 1101/2000, Train Loss: 0.000698, Val Loss: 0.042214\n",
            "Epoch 1101/2000, Rel Train Loss: 38.30%, Rel Val Loss: 51.19%\n",
            "Moving Avg Val Loss: 0.512797\n",
            "Epoch 1102/2000, Train Loss: 0.002098, Val Loss: 0.049807\n",
            "Epoch 1102/2000, Rel Train Loss: 72.65%, Rel Val Loss: 82.23%\n",
            "Moving Avg Val Loss: 0.515210\n",
            "Epoch 1103/2000, Train Loss: 0.001050, Val Loss: 0.044909\n",
            "Epoch 1103/2000, Rel Train Loss: 56.08%, Rel Val Loss: 41.20%\n",
            "Moving Avg Val Loss: 0.538066\n",
            "Epoch 1104/2000, Train Loss: 0.000715, Val Loss: 0.042062\n",
            "Epoch 1104/2000, Rel Train Loss: 38.77%, Rel Val Loss: 55.35%\n",
            "Moving Avg Val Loss: 0.543342\n",
            "Epoch 1105/2000, Train Loss: 0.000986, Val Loss: 0.044612\n",
            "Epoch 1105/2000, Rel Train Loss: 48.42%, Rel Val Loss: 41.70%\n",
            "Moving Avg Val Loss: 0.531159\n",
            "Epoch 1106/2000, Train Loss: 0.000788, Val Loss: 0.041216\n",
            "Epoch 1106/2000, Rel Train Loss: 44.47%, Rel Val Loss: 45.10%\n",
            "Moving Avg Val Loss: 0.458759\n",
            "Epoch 1107/2000, Train Loss: 0.000917, Val Loss: 0.044124\n",
            "Epoch 1107/2000, Rel Train Loss: 41.43%, Rel Val Loss: 46.03%\n",
            "Moving Avg Val Loss: 0.576463\n",
            "Epoch 1108/2000, Train Loss: 0.001249, Val Loss: 0.045361\n",
            "Epoch 1108/2000, Rel Train Loss: 60.92%, Rel Val Loss: 100.05%\n",
            "Moving Avg Val Loss: 0.556988\n",
            "Epoch 1109/2000, Train Loss: 0.001148, Val Loss: 0.049427\n",
            "Epoch 1109/2000, Rel Train Loss: 54.06%, Rel Val Loss: 45.61%\n",
            "Moving Avg Val Loss: 0.630783\n",
            "Epoch 1110/2000, Train Loss: 0.001299, Val Loss: 0.044609\n",
            "Epoch 1110/2000, Rel Train Loss: 54.80%, Rel Val Loss: 78.60%\n",
            "Moving Avg Val Loss: 0.630013\n",
            "Epoch 1111/2000, Train Loss: 0.001518, Val Loss: 0.044174\n",
            "Epoch 1111/2000, Rel Train Loss: 57.58%, Rel Val Loss: 44.72%\n",
            "Moving Avg Val Loss: 0.655099\n",
            "Epoch 1112/2000, Train Loss: 0.000646, Val Loss: 0.042072\n",
            "Epoch 1112/2000, Rel Train Loss: 38.81%, Rel Val Loss: 58.57%\n",
            "Moving Avg Val Loss: 0.634120\n",
            "Epoch 1113/2000, Train Loss: 0.002626, Val Loss: 0.041079\n",
            "Epoch 1113/2000, Rel Train Loss: 65.17%, Rel Val Loss: 89.56%\n",
            "Moving Avg Val Loss: 0.647435\n",
            "Epoch 1114/2000, Train Loss: 0.001064, Val Loss: 0.043519\n",
            "Epoch 1114/2000, Rel Train Loss: 65.44%, Rel Val Loss: 52.27%\n",
            "Moving Avg Val Loss: 0.606458\n",
            "Epoch 1115/2000, Train Loss: 0.000657, Val Loss: 0.040503\n",
            "Epoch 1115/2000, Rel Train Loss: 37.67%, Rel Val Loss: 58.11%\n",
            "Moving Avg Val Loss: 0.646201\n",
            "Epoch 1116/2000, Train Loss: 0.001539, Val Loss: 0.045287\n",
            "Epoch 1116/2000, Rel Train Loss: 66.48%, Rel Val Loss: 64.59%\n",
            "Moving Avg Val Loss: 0.612951\n",
            "Epoch 1117/2000, Train Loss: 0.001207, Val Loss: 0.045941\n",
            "Epoch 1117/2000, Rel Train Loss: 49.62%, Rel Val Loss: 41.95%\n",
            "Moving Avg Val Loss: 0.564711\n",
            "Epoch 1118/2000, Train Loss: 0.001041, Val Loss: 0.038003\n",
            "Epoch 1118/2000, Rel Train Loss: 42.26%, Rel Val Loss: 65.44%\n",
            "Moving Avg Val Loss: 0.601425\n",
            "Epoch 1119/2000, Train Loss: 0.001857, Val Loss: 0.043209\n",
            "Epoch 1119/2000, Rel Train Loss: 57.79%, Rel Val Loss: 70.62%\n",
            "Moving Avg Val Loss: 0.611433\n",
            "Epoch 1120/2000, Train Loss: 0.001446, Val Loss: 0.045747\n",
            "Epoch 1120/2000, Rel Train Loss: 70.04%, Rel Val Loss: 63.11%\n",
            "Moving Avg Val Loss: 0.588174\n",
            "Epoch 1121/2000, Train Loss: 0.001810, Val Loss: 0.037771\n",
            "Epoch 1121/2000, Rel Train Loss: 57.86%, Rel Val Loss: 52.96%\n",
            "Moving Avg Val Loss: 0.597153\n",
            "Epoch 1122/2000, Train Loss: 0.001446, Val Loss: 0.047648\n",
            "Epoch 1122/2000, Rel Train Loss: 46.52%, Rel Val Loss: 46.44%\n",
            "Moving Avg Val Loss: 0.568420\n",
            "Epoch 1123/2000, Train Loss: 0.000675, Val Loss: 0.039831\n",
            "Epoch 1123/2000, Rel Train Loss: 46.03%, Rel Val Loss: 51.07%\n",
            "Moving Avg Val Loss: 0.514657\n",
            "Epoch 1124/2000, Train Loss: 0.000726, Val Loss: 0.038466\n",
            "Epoch 1124/2000, Rel Train Loss: 35.11%, Rel Val Loss: 43.74%\n",
            "Moving Avg Val Loss: 0.506689\n",
            "Epoch 1125/2000, Train Loss: 0.000713, Val Loss: 0.042928\n",
            "Epoch 1125/2000, Rel Train Loss: 38.29%, Rel Val Loss: 59.13%\n",
            "Moving Avg Val Loss: 0.552572\n",
            "Epoch 1126/2000, Train Loss: 0.002086, Val Loss: 0.044622\n",
            "Epoch 1126/2000, Rel Train Loss: 76.76%, Rel Val Loss: 75.90%\n",
            "Moving Avg Val Loss: 0.595974\n",
            "Epoch 1127/2000, Train Loss: 0.001141, Val Loss: 0.039410\n",
            "Epoch 1127/2000, Rel Train Loss: 65.03%, Rel Val Loss: 68.14%\n",
            "Moving Avg Val Loss: 0.599387\n",
            "Epoch 1128/2000, Train Loss: 0.000776, Val Loss: 0.046171\n",
            "Epoch 1128/2000, Rel Train Loss: 54.59%, Rel Val Loss: 52.78%\n",
            "Moving Avg Val Loss: 0.597658\n",
            "Epoch 1129/2000, Train Loss: 0.000900, Val Loss: 0.040159\n",
            "Epoch 1129/2000, Rel Train Loss: 54.22%, Rel Val Loss: 42.88%\n",
            "Moving Avg Val Loss: 0.569689\n",
            "Epoch 1130/2000, Train Loss: 0.000518, Val Loss: 0.042060\n",
            "Epoch 1130/2000, Rel Train Loss: 37.33%, Rel Val Loss: 45.15%\n",
            "Moving Avg Val Loss: 0.497395\n",
            "Epoch 1131/2000, Train Loss: 0.000510, Val Loss: 0.042387\n",
            "Epoch 1131/2000, Rel Train Loss: 36.41%, Rel Val Loss: 39.76%\n",
            "Moving Avg Val Loss: 0.450173\n",
            "Epoch 1132/2000, Train Loss: 0.000403, Val Loss: 0.040390\n",
            "Epoch 1132/2000, Rel Train Loss: 34.25%, Rel Val Loss: 44.53%\n",
            "Moving Avg Val Loss: 0.421422\n",
            "Epoch 1133/2000, Train Loss: 0.000499, Val Loss: 0.040480\n",
            "Epoch 1133/2000, Rel Train Loss: 33.72%, Rel Val Loss: 38.40%\n",
            "Moving Avg Val Loss: 0.417268\n",
            "Epoch 1134/2000, Train Loss: 0.000369, Val Loss: 0.042511\n",
            "Epoch 1134/2000, Rel Train Loss: 33.45%, Rel Val Loss: 40.80%\n",
            "Moving Avg Val Loss: 0.411590\n",
            "Epoch 1135/2000, Train Loss: 0.000337, Val Loss: 0.040217\n",
            "Epoch 1135/2000, Rel Train Loss: 33.40%, Rel Val Loss: 42.31%\n",
            "Moving Avg Val Loss: 0.409985\n",
            "Epoch 1136/2000, Train Loss: 0.000314, Val Loss: 0.041072\n",
            "Epoch 1136/2000, Rel Train Loss: 34.35%, Rel Val Loss: 38.95%\n",
            "Moving Avg Val Loss: 0.396491\n",
            "Epoch 1137/2000, Train Loss: 0.000315, Val Loss: 0.042941\n",
            "Epoch 1137/2000, Rel Train Loss: 32.23%, Rel Val Loss: 37.78%\n",
            "Moving Avg Val Loss: 0.399433\n",
            "Epoch 1138/2000, Train Loss: 0.000327, Val Loss: 0.041178\n",
            "Epoch 1138/2000, Rel Train Loss: 30.74%, Rel Val Loss: 39.87%\n",
            "Moving Avg Val Loss: 0.407961\n",
            "Epoch 1139/2000, Train Loss: 0.000490, Val Loss: 0.040878\n",
            "Epoch 1139/2000, Rel Train Loss: 33.99%, Rel Val Loss: 45.06%\n",
            "Moving Avg Val Loss: 0.516432\n",
            "Epoch 1140/2000, Train Loss: 0.002476, Val Loss: 0.041938\n",
            "Epoch 1140/2000, Rel Train Loss: 54.93%, Rel Val Loss: 96.54%\n",
            "Moving Avg Val Loss: 0.561875\n",
            "Epoch 1141/2000, Train Loss: 0.001574, Val Loss: 0.056783\n",
            "Epoch 1141/2000, Rel Train Loss: 80.03%, Rel Val Loss: 61.67%\n",
            "Moving Avg Val Loss: 0.720607\n",
            "Epoch 1142/2000, Train Loss: 0.003424, Val Loss: 0.047004\n",
            "Epoch 1142/2000, Rel Train Loss: 67.56%, Rel Val Loss: 117.15%\n",
            "Moving Avg Val Loss: 0.784499\n",
            "Epoch 1143/2000, Train Loss: 0.004553, Val Loss: 0.041338\n",
            "Epoch 1143/2000, Rel Train Loss: 85.81%, Rel Val Loss: 71.82%\n",
            "Moving Avg Val Loss: 0.799735\n",
            "Epoch 1144/2000, Train Loss: 0.001586, Val Loss: 0.048293\n",
            "Epoch 1144/2000, Rel Train Loss: 51.62%, Rel Val Loss: 52.68%\n",
            "Moving Avg Val Loss: 0.691732\n",
            "Epoch 1145/2000, Train Loss: 0.002653, Val Loss: 0.043871\n",
            "Epoch 1145/2000, Rel Train Loss: 48.84%, Rel Val Loss: 42.54%\n",
            "Moving Avg Val Loss: 0.672670\n",
            "Epoch 1146/2000, Train Loss: 0.001000, Val Loss: 0.040436\n",
            "Epoch 1146/2000, Rel Train Loss: 54.23%, Rel Val Loss: 52.14%\n",
            "Moving Avg Val Loss: 0.529638\n",
            "Epoch 1147/2000, Train Loss: 0.001090, Val Loss: 0.044122\n",
            "Epoch 1147/2000, Rel Train Loss: 45.46%, Rel Val Loss: 45.63%\n",
            "Moving Avg Val Loss: 0.468204\n",
            "Epoch 1148/2000, Train Loss: 0.000732, Val Loss: 0.039580\n",
            "Epoch 1148/2000, Rel Train Loss: 40.66%, Rel Val Loss: 41.10%\n",
            "Moving Avg Val Loss: 0.444705\n",
            "Epoch 1149/2000, Train Loss: 0.000431, Val Loss: 0.042814\n",
            "Epoch 1149/2000, Rel Train Loss: 41.63%, Rel Val Loss: 40.93%\n",
            "Moving Avg Val Loss: 0.439112\n",
            "Epoch 1150/2000, Train Loss: 0.000395, Val Loss: 0.041081\n",
            "Epoch 1150/2000, Rel Train Loss: 34.62%, Rel Val Loss: 39.74%\n",
            "Moving Avg Val Loss: 0.447918\n",
            "Epoch 1151/2000, Train Loss: 0.000631, Val Loss: 0.042230\n",
            "Epoch 1151/2000, Rel Train Loss: 37.00%, Rel Val Loss: 56.55%\n",
            "Moving Avg Val Loss: 0.434728\n",
            "Epoch 1152/2000, Train Loss: 0.000617, Val Loss: 0.041176\n",
            "Epoch 1152/2000, Rel Train Loss: 38.94%, Rel Val Loss: 39.04%\n",
            "Moving Avg Val Loss: 0.428866\n",
            "Epoch 1153/2000, Train Loss: 0.000363, Val Loss: 0.039755\n",
            "Epoch 1153/2000, Rel Train Loss: 32.32%, Rel Val Loss: 38.17%\n",
            "Moving Avg Val Loss: 0.424037\n",
            "Epoch 1154/2000, Train Loss: 0.000427, Val Loss: 0.042155\n",
            "Epoch 1154/2000, Rel Train Loss: 34.53%, Rel Val Loss: 38.52%\n",
            "Moving Avg Val Loss: 0.456719\n",
            "Epoch 1155/2000, Train Loss: 0.000610, Val Loss: 0.040675\n",
            "Epoch 1155/2000, Rel Train Loss: 41.00%, Rel Val Loss: 56.09%\n",
            "Moving Avg Val Loss: 0.422074\n",
            "Epoch 1156/2000, Train Loss: 0.000375, Val Loss: 0.041386\n",
            "Epoch 1156/2000, Rel Train Loss: 36.29%, Rel Val Loss: 39.22%\n",
            "Moving Avg Val Loss: 0.423930\n",
            "Epoch 1157/2000, Train Loss: 0.000534, Val Loss: 0.041311\n",
            "Epoch 1157/2000, Rel Train Loss: 33.78%, Rel Val Loss: 39.96%\n",
            "Moving Avg Val Loss: 0.430577\n",
            "Epoch 1158/2000, Train Loss: 0.000398, Val Loss: 0.040418\n",
            "Epoch 1158/2000, Rel Train Loss: 38.74%, Rel Val Loss: 41.50%\n",
            "Moving Avg Val Loss: 0.431565\n",
            "Epoch 1159/2000, Train Loss: 0.000628, Val Loss: 0.043835\n",
            "Epoch 1159/2000, Rel Train Loss: 35.12%, Rel Val Loss: 39.01%\n",
            "Moving Avg Val Loss: 0.429956\n",
            "Epoch 1160/2000, Train Loss: 0.000791, Val Loss: 0.040360\n",
            "Epoch 1160/2000, Rel Train Loss: 40.55%, Rel Val Loss: 55.28%\n",
            "Moving Avg Val Loss: 0.434972\n",
            "Epoch 1161/2000, Train Loss: 0.000617, Val Loss: 0.042236\n",
            "Epoch 1161/2000, Rel Train Loss: 39.55%, Rel Val Loss: 41.73%\n",
            "Moving Avg Val Loss: 0.430920\n",
            "Epoch 1162/2000, Train Loss: 0.000438, Val Loss: 0.039411\n",
            "Epoch 1162/2000, Rel Train Loss: 32.46%, Rel Val Loss: 37.94%\n",
            "Moving Avg Val Loss: 0.437911\n",
            "Epoch 1163/2000, Train Loss: 0.000331, Val Loss: 0.041462\n",
            "Epoch 1163/2000, Rel Train Loss: 33.18%, Rel Val Loss: 44.99%\n",
            "Moving Avg Val Loss: 0.434747\n",
            "Epoch 1164/2000, Train Loss: 0.000339, Val Loss: 0.042179\n",
            "Epoch 1164/2000, Rel Train Loss: 34.83%, Rel Val Loss: 37.43%\n",
            "Moving Avg Val Loss: 0.403331\n",
            "Epoch 1165/2000, Train Loss: 0.000311, Val Loss: 0.041682\n",
            "Epoch 1165/2000, Rel Train Loss: 33.51%, Rel Val Loss: 39.57%\n",
            "Moving Avg Val Loss: 0.403475\n",
            "Epoch 1166/2000, Train Loss: 0.000400, Val Loss: 0.040830\n",
            "Epoch 1166/2000, Rel Train Loss: 33.00%, Rel Val Loss: 41.80%\n",
            "Moving Avg Val Loss: 0.409765\n",
            "Epoch 1167/2000, Train Loss: 0.000460, Val Loss: 0.041402\n",
            "Epoch 1167/2000, Rel Train Loss: 36.30%, Rel Val Loss: 41.08%\n",
            "Moving Avg Val Loss: 0.393811\n",
            "Epoch 1168/2000, Train Loss: 0.000344, Val Loss: 0.041080\n",
            "Epoch 1168/2000, Rel Train Loss: 32.39%, Rel Val Loss: 37.01%\n",
            "Moving Avg Val Loss: 0.398661\n",
            "Epoch 1169/2000, Train Loss: 0.000299, Val Loss: 0.041103\n",
            "Epoch 1169/2000, Rel Train Loss: 33.19%, Rel Val Loss: 39.86%\n",
            "Moving Avg Val Loss: 0.399337\n",
            "Epoch 1170/2000, Train Loss: 0.000320, Val Loss: 0.041273\n",
            "Epoch 1170/2000, Rel Train Loss: 32.41%, Rel Val Loss: 39.91%\n",
            "Moving Avg Val Loss: 0.393223\n",
            "Epoch 1171/2000, Train Loss: 0.000338, Val Loss: 0.039367\n",
            "Epoch 1171/2000, Rel Train Loss: 34.58%, Rel Val Loss: 38.75%\n",
            "Moving Avg Val Loss: 0.390704\n",
            "Epoch 1172/2000, Train Loss: 0.000335, Val Loss: 0.042988\n",
            "Epoch 1172/2000, Rel Train Loss: 31.72%, Rel Val Loss: 39.82%\n",
            "Moving Avg Val Loss: 0.394768\n",
            "Epoch 1173/2000, Train Loss: 0.000522, Val Loss: 0.040241\n",
            "Epoch 1173/2000, Rel Train Loss: 36.25%, Rel Val Loss: 39.05%\n",
            "Moving Avg Val Loss: 0.413572\n",
            "Epoch 1174/2000, Train Loss: 0.000665, Val Loss: 0.040137\n",
            "Epoch 1174/2000, Rel Train Loss: 38.86%, Rel Val Loss: 49.26%\n",
            "Moving Avg Val Loss: 0.417949\n",
            "Epoch 1175/2000, Train Loss: 0.000405, Val Loss: 0.041459\n",
            "Epoch 1175/2000, Rel Train Loss: 34.46%, Rel Val Loss: 42.10%\n",
            "Moving Avg Val Loss: 0.420987\n",
            "Epoch 1176/2000, Train Loss: 0.000448, Val Loss: 0.044697\n",
            "Epoch 1176/2000, Rel Train Loss: 33.86%, Rel Val Loss: 40.27%\n",
            "Moving Avg Val Loss: 0.434261\n",
            "Epoch 1177/2000, Train Loss: 0.002476, Val Loss: 0.048777\n",
            "Epoch 1177/2000, Rel Train Loss: 58.06%, Rel Val Loss: 46.46%\n",
            "Moving Avg Val Loss: 0.447007\n",
            "Epoch 1178/2000, Train Loss: 0.003688, Val Loss: 0.046748\n",
            "Epoch 1178/2000, Rel Train Loss: 142.22%, Rel Val Loss: 45.42%\n",
            "Moving Avg Val Loss: 0.504781\n",
            "Epoch 1179/2000, Train Loss: 0.001913, Val Loss: 0.042402\n",
            "Epoch 1179/2000, Rel Train Loss: 97.27%, Rel Val Loss: 78.14%\n",
            "Moving Avg Val Loss: 0.505314\n",
            "Epoch 1180/2000, Train Loss: 0.001121, Val Loss: 0.040058\n",
            "Epoch 1180/2000, Rel Train Loss: 44.51%, Rel Val Loss: 42.37%\n",
            "Moving Avg Val Loss: 0.520901\n",
            "Epoch 1181/2000, Train Loss: 0.001116, Val Loss: 0.043145\n",
            "Epoch 1181/2000, Rel Train Loss: 54.08%, Rel Val Loss: 48.06%\n",
            "Moving Avg Val Loss: 0.530900\n",
            "Epoch 1182/2000, Train Loss: 0.000677, Val Loss: 0.041058\n",
            "Epoch 1182/2000, Rel Train Loss: 53.70%, Rel Val Loss: 51.46%\n",
            "Moving Avg Val Loss: 0.514388\n",
            "Epoch 1183/2000, Train Loss: 0.000437, Val Loss: 0.039746\n",
            "Epoch 1183/2000, Rel Train Loss: 38.83%, Rel Val Loss: 37.16%\n",
            "Moving Avg Val Loss: 0.439281\n",
            "Epoch 1184/2000, Train Loss: 0.000364, Val Loss: 0.041577\n",
            "Epoch 1184/2000, Rel Train Loss: 32.96%, Rel Val Loss: 40.59%\n",
            "Moving Avg Val Loss: 0.437389\n",
            "Epoch 1185/2000, Train Loss: 0.000327, Val Loss: 0.040815\n",
            "Epoch 1185/2000, Rel Train Loss: 30.59%, Rel Val Loss: 41.42%\n",
            "Moving Avg Val Loss: 0.414595\n",
            "Epoch 1186/2000, Train Loss: 0.000300, Val Loss: 0.039802\n",
            "Epoch 1186/2000, Rel Train Loss: 31.72%, Rel Val Loss: 36.66%\n",
            "Moving Avg Val Loss: 0.389416\n",
            "Epoch 1187/2000, Train Loss: 0.000299, Val Loss: 0.040954\n",
            "Epoch 1187/2000, Rel Train Loss: 32.06%, Rel Val Loss: 38.87%\n",
            "Moving Avg Val Loss: 0.400502\n",
            "Epoch 1188/2000, Train Loss: 0.000377, Val Loss: 0.039888\n",
            "Epoch 1188/2000, Rel Train Loss: 31.72%, Rel Val Loss: 42.71%\n",
            "Moving Avg Val Loss: 0.410434\n",
            "Epoch 1189/2000, Train Loss: 0.000601, Val Loss: 0.042086\n",
            "Epoch 1189/2000, Rel Train Loss: 39.72%, Rel Val Loss: 45.56%\n",
            "Moving Avg Val Loss: 0.427455\n",
            "Epoch 1190/2000, Train Loss: 0.001547, Val Loss: 0.040418\n",
            "Epoch 1190/2000, Rel Train Loss: 43.55%, Rel Val Loss: 49.93%\n",
            "Moving Avg Val Loss: 0.454731\n",
            "Epoch 1191/2000, Train Loss: 0.000629, Val Loss: 0.044098\n",
            "Epoch 1191/2000, Rel Train Loss: 52.69%, Rel Val Loss: 50.30%\n",
            "Moving Avg Val Loss: 0.457999\n",
            "Epoch 1192/2000, Train Loss: 0.001259, Val Loss: 0.046303\n",
            "Epoch 1192/2000, Rel Train Loss: 46.64%, Rel Val Loss: 40.51%\n",
            "Moving Avg Val Loss: 0.669184\n",
            "Epoch 1193/2000, Train Loss: 0.005241, Val Loss: 0.053831\n",
            "Epoch 1193/2000, Rel Train Loss: 106.06%, Rel Val Loss: 148.30%\n",
            "Moving Avg Val Loss: 0.861666\n",
            "Epoch 1194/2000, Train Loss: 0.012803, Val Loss: 0.048101\n",
            "Epoch 1194/2000, Rel Train Loss: 170.09%, Rel Val Loss: 141.80%\n",
            "Moving Avg Val Loss: 0.959933\n",
            "Epoch 1195/2000, Train Loss: 0.004375, Val Loss: 0.051465\n",
            "Epoch 1195/2000, Rel Train Loss: 140.48%, Rel Val Loss: 99.06%\n",
            "Moving Avg Val Loss: 0.953974\n",
            "Epoch 1196/2000, Train Loss: 0.002773, Val Loss: 0.042268\n",
            "Epoch 1196/2000, Rel Train Loss: 96.73%, Rel Val Loss: 47.32%\n",
            "Moving Avg Val Loss: 1.125263\n",
            "Epoch 1197/2000, Train Loss: 0.004041, Val Loss: 0.054523\n",
            "Epoch 1197/2000, Rel Train Loss: 87.44%, Rel Val Loss: 126.15%\n",
            "Moving Avg Val Loss: 0.958780\n",
            "Epoch 1198/2000, Train Loss: 0.002823, Val Loss: 0.036283\n",
            "Epoch 1198/2000, Rel Train Loss: 52.09%, Rel Val Loss: 65.06%\n",
            "Moving Avg Val Loss: 0.765482\n",
            "Epoch 1199/2000, Train Loss: 0.001914, Val Loss: 0.039497\n",
            "Epoch 1199/2000, Rel Train Loss: 58.65%, Rel Val Loss: 45.15%\n",
            "Moving Avg Val Loss: 0.653830\n",
            "Epoch 1200/2000, Train Loss: 0.001270, Val Loss: 0.046597\n",
            "Epoch 1200/2000, Rel Train Loss: 46.27%, Rel Val Loss: 43.24%\n",
            "Moving Avg Val Loss: 0.692331\n",
            "Epoch 1201/2000, Train Loss: 0.001858, Val Loss: 0.035342\n",
            "Epoch 1201/2000, Rel Train Loss: 49.56%, Rel Val Loss: 66.57%\n",
            "Moving Avg Val Loss: 0.570767\n",
            "Epoch 1202/2000, Train Loss: 0.002947, Val Loss: 0.045764\n",
            "Epoch 1202/2000, Rel Train Loss: 66.26%, Rel Val Loss: 65.37%\n",
            "Moving Avg Val Loss: 0.552498\n",
            "Epoch 1203/2000, Train Loss: 0.002574, Val Loss: 0.036276\n",
            "Epoch 1203/2000, Rel Train Loss: 47.80%, Rel Val Loss: 55.92%\n",
            "Moving Avg Val Loss: 0.597432\n",
            "Epoch 1204/2000, Train Loss: 0.001582, Val Loss: 0.044452\n",
            "Epoch 1204/2000, Rel Train Loss: 51.02%, Rel Val Loss: 67.61%\n",
            "Moving Avg Val Loss: 0.583948\n",
            "Epoch 1205/2000, Train Loss: 0.002117, Val Loss: 0.042003\n",
            "Epoch 1205/2000, Rel Train Loss: 54.61%, Rel Val Loss: 36.50%\n",
            "Moving Avg Val Loss: 0.544294\n",
            "Epoch 1206/2000, Train Loss: 0.000908, Val Loss: 0.036401\n",
            "Epoch 1206/2000, Rel Train Loss: 37.47%, Rel Val Loss: 46.74%\n",
            "Moving Avg Val Loss: 0.501854\n",
            "Epoch 1207/2000, Train Loss: 0.000775, Val Loss: 0.040592\n",
            "Epoch 1207/2000, Rel Train Loss: 44.18%, Rel Val Loss: 44.15%\n",
            "Moving Avg Val Loss: 0.478529\n",
            "Epoch 1208/2000, Train Loss: 0.000716, Val Loss: 0.035140\n",
            "Epoch 1208/2000, Rel Train Loss: 41.40%, Rel Val Loss: 44.26%\n",
            "Moving Avg Val Loss: 0.423101\n",
            "Epoch 1209/2000, Train Loss: 0.000955, Val Loss: 0.038598\n",
            "Epoch 1209/2000, Rel Train Loss: 45.44%, Rel Val Loss: 39.90%\n",
            "Moving Avg Val Loss: 0.432248\n",
            "Epoch 1210/2000, Train Loss: 0.000583, Val Loss: 0.037687\n",
            "Epoch 1210/2000, Rel Train Loss: 50.10%, Rel Val Loss: 41.07%\n",
            "Moving Avg Val Loss: 0.418683\n",
            "Epoch 1211/2000, Train Loss: 0.000528, Val Loss: 0.034926\n",
            "Epoch 1211/2000, Rel Train Loss: 34.78%, Rel Val Loss: 39.96%\n",
            "Moving Avg Val Loss: 0.412328\n",
            "Epoch 1212/2000, Train Loss: 0.000388, Val Loss: 0.037222\n",
            "Epoch 1212/2000, Rel Train Loss: 34.07%, Rel Val Loss: 40.97%\n",
            "Moving Avg Val Loss: 0.398460\n",
            "Epoch 1213/2000, Train Loss: 0.000382, Val Loss: 0.036280\n",
            "Epoch 1213/2000, Rel Train Loss: 33.44%, Rel Val Loss: 37.33%\n",
            "Moving Avg Val Loss: 0.396711\n",
            "Epoch 1214/2000, Train Loss: 0.000716, Val Loss: 0.039669\n",
            "Epoch 1214/2000, Rel Train Loss: 36.87%, Rel Val Loss: 39.03%\n",
            "Moving Avg Val Loss: 0.388512\n",
            "Epoch 1215/2000, Train Loss: 0.000642, Val Loss: 0.035921\n",
            "Epoch 1215/2000, Rel Train Loss: 42.59%, Rel Val Loss: 36.97%\n",
            "Moving Avg Val Loss: 0.395304\n",
            "Epoch 1216/2000, Train Loss: 0.000396, Val Loss: 0.037890\n",
            "Epoch 1216/2000, Rel Train Loss: 37.72%, Rel Val Loss: 43.36%\n",
            "Moving Avg Val Loss: 0.405126\n",
            "Epoch 1217/2000, Train Loss: 0.000659, Val Loss: 0.043681\n",
            "Epoch 1217/2000, Rel Train Loss: 35.33%, Rel Val Loss: 45.88%\n",
            "Moving Avg Val Loss: 0.595562\n",
            "Epoch 1218/2000, Train Loss: 0.004332, Val Loss: 0.047287\n",
            "Epoch 1218/2000, Rel Train Loss: 77.90%, Rel Val Loss: 132.54%\n",
            "Moving Avg Val Loss: 0.635929\n",
            "Epoch 1219/2000, Train Loss: 0.002115, Val Loss: 0.050803\n",
            "Epoch 1219/2000, Rel Train Loss: 86.97%, Rel Val Loss: 59.21%\n",
            "Moving Avg Val Loss: 0.717823\n",
            "Epoch 1220/2000, Train Loss: 0.002878, Val Loss: 0.044445\n",
            "Epoch 1220/2000, Rel Train Loss: 53.44%, Rel Val Loss: 77.92%\n",
            "Moving Avg Val Loss: 0.811159\n",
            "Epoch 1221/2000, Train Loss: 0.003022, Val Loss: 0.043024\n",
            "Epoch 1221/2000, Rel Train Loss: 72.13%, Rel Val Loss: 90.03%\n",
            "Moving Avg Val Loss: 0.821607\n",
            "Epoch 1222/2000, Train Loss: 0.001108, Val Loss: 0.038176\n",
            "Epoch 1222/2000, Rel Train Loss: 64.20%, Rel Val Loss: 51.11%\n",
            "Moving Avg Val Loss: 0.631370\n",
            "Epoch 1223/2000, Train Loss: 0.000705, Val Loss: 0.036955\n",
            "Epoch 1223/2000, Rel Train Loss: 42.04%, Rel Val Loss: 37.43%\n",
            "Moving Avg Val Loss: 0.590401\n",
            "Epoch 1224/2000, Train Loss: 0.000732, Val Loss: 0.040725\n",
            "Epoch 1224/2000, Rel Train Loss: 44.90%, Rel Val Loss: 38.72%\n",
            "Moving Avg Val Loss: 0.509403\n",
            "Epoch 1225/2000, Train Loss: 0.000728, Val Loss: 0.040065\n",
            "Epoch 1225/2000, Rel Train Loss: 34.84%, Rel Val Loss: 37.42%\n",
            "Moving Avg Val Loss: 0.410132\n",
            "Epoch 1226/2000, Train Loss: 0.000724, Val Loss: 0.038942\n",
            "Epoch 1226/2000, Rel Train Loss: 37.57%, Rel Val Loss: 40.39%\n",
            "Moving Avg Val Loss: 0.450052\n",
            "Epoch 1227/2000, Train Loss: 0.000836, Val Loss: 0.040591\n",
            "Epoch 1227/2000, Rel Train Loss: 51.60%, Rel Val Loss: 71.06%\n",
            "Moving Avg Val Loss: 0.450800\n",
            "Epoch 1228/2000, Train Loss: 0.000643, Val Loss: 0.039186\n",
            "Epoch 1228/2000, Rel Train Loss: 41.67%, Rel Val Loss: 37.80%\n",
            "Moving Avg Val Loss: 0.468594\n",
            "Epoch 1229/2000, Train Loss: 0.001152, Val Loss: 0.040421\n",
            "Epoch 1229/2000, Rel Train Loss: 38.41%, Rel Val Loss: 47.62%\n",
            "Moving Avg Val Loss: 0.497693\n",
            "Epoch 1230/2000, Train Loss: 0.000893, Val Loss: 0.041319\n",
            "Epoch 1230/2000, Rel Train Loss: 48.11%, Rel Val Loss: 51.97%\n",
            "Moving Avg Val Loss: 0.488914\n",
            "Epoch 1231/2000, Train Loss: 0.000431, Val Loss: 0.039063\n",
            "Epoch 1231/2000, Rel Train Loss: 37.99%, Rel Val Loss: 36.00%\n",
            "Moving Avg Val Loss: 0.418914\n",
            "Epoch 1232/2000, Train Loss: 0.000386, Val Loss: 0.037470\n",
            "Epoch 1232/2000, Rel Train Loss: 31.75%, Rel Val Loss: 36.06%\n",
            "Moving Avg Val Loss: 0.472860\n",
            "Epoch 1233/2000, Train Loss: 0.000699, Val Loss: 0.039439\n",
            "Epoch 1233/2000, Rel Train Loss: 41.32%, Rel Val Loss: 64.77%\n",
            "Moving Avg Val Loss: 0.474023\n",
            "Epoch 1234/2000, Train Loss: 0.000827, Val Loss: 0.058161\n",
            "Epoch 1234/2000, Rel Train Loss: 41.80%, Rel Val Loss: 48.20%\n",
            "Moving Avg Val Loss: 0.724913\n",
            "Epoch 1235/2000, Train Loss: 0.005614, Val Loss: 0.042716\n",
            "Epoch 1235/2000, Rel Train Loss: 85.72%, Rel Val Loss: 177.41%\n",
            "Moving Avg Val Loss: 0.775253\n",
            "Epoch 1236/2000, Train Loss: 0.002047, Val Loss: 0.049883\n",
            "Epoch 1236/2000, Rel Train Loss: 98.09%, Rel Val Loss: 61.17%\n",
            "Moving Avg Val Loss: 0.841405\n",
            "Epoch 1237/2000, Train Loss: 0.002717, Val Loss: 0.044370\n",
            "Epoch 1237/2000, Rel Train Loss: 48.17%, Rel Val Loss: 69.14%\n",
            "Moving Avg Val Loss: 0.980181\n",
            "Epoch 1238/2000, Train Loss: 0.004089, Val Loss: 0.045761\n",
            "Epoch 1238/2000, Rel Train Loss: 80.75%, Rel Val Loss: 134.16%\n",
            "Moving Avg Val Loss: 0.968893\n",
            "Epoch 1239/2000, Train Loss: 0.004274, Val Loss: 0.041599\n",
            "Epoch 1239/2000, Rel Train Loss: 93.33%, Rel Val Loss: 42.56%\n",
            "Moving Avg Val Loss: 0.707974\n",
            "Epoch 1240/2000, Train Loss: 0.001062, Val Loss: 0.038488\n",
            "Epoch 1240/2000, Rel Train Loss: 53.95%, Rel Val Loss: 46.95%\n",
            "Moving Avg Val Loss: 0.680514\n",
            "Epoch 1241/2000, Train Loss: 0.000993, Val Loss: 0.042686\n",
            "Epoch 1241/2000, Rel Train Loss: 37.94%, Rel Val Loss: 47.44%\n",
            "Moving Avg Val Loss: 0.614880\n",
            "Epoch 1242/2000, Train Loss: 0.000935, Val Loss: 0.040783\n",
            "Epoch 1242/2000, Rel Train Loss: 42.25%, Rel Val Loss: 36.32%\n",
            "Moving Avg Val Loss: 0.424485\n",
            "Epoch 1243/2000, Train Loss: 0.000639, Val Loss: 0.038958\n",
            "Epoch 1243/2000, Rel Train Loss: 36.76%, Rel Val Loss: 38.96%\n",
            "Moving Avg Val Loss: 0.448604\n",
            "Epoch 1244/2000, Train Loss: 0.000615, Val Loss: 0.040220\n",
            "Epoch 1244/2000, Rel Train Loss: 34.96%, Rel Val Loss: 54.62%\n",
            "Moving Avg Val Loss: 0.429881\n",
            "Epoch 1245/2000, Train Loss: 0.000593, Val Loss: 0.038546\n",
            "Epoch 1245/2000, Rel Train Loss: 39.85%, Rel Val Loss: 37.59%\n",
            "Moving Avg Val Loss: 0.408920\n",
            "Epoch 1246/2000, Train Loss: 0.000492, Val Loss: 0.038205\n",
            "Epoch 1246/2000, Rel Train Loss: 33.52%, Rel Val Loss: 36.96%\n",
            "Moving Avg Val Loss: 0.411363\n",
            "Epoch 1247/2000, Train Loss: 0.000418, Val Loss: 0.038498\n",
            "Epoch 1247/2000, Rel Train Loss: 33.24%, Rel Val Loss: 37.55%\n",
            "Moving Avg Val Loss: 0.431357\n",
            "Epoch 1248/2000, Train Loss: 0.000503, Val Loss: 0.039048\n",
            "Epoch 1248/2000, Rel Train Loss: 36.99%, Rel Val Loss: 48.96%\n",
            "Moving Avg Val Loss: 0.429086\n",
            "Epoch 1249/2000, Train Loss: 0.001502, Val Loss: 0.037495\n",
            "Epoch 1249/2000, Rel Train Loss: 42.54%, Rel Val Loss: 53.48%\n",
            "Moving Avg Val Loss: 0.483418\n",
            "Epoch 1250/2000, Train Loss: 0.001225, Val Loss: 0.050736\n",
            "Epoch 1250/2000, Rel Train Loss: 42.41%, Rel Val Loss: 64.76%\n",
            "Moving Avg Val Loss: 0.501604\n",
            "Epoch 1251/2000, Train Loss: 0.001435, Val Loss: 0.039431\n",
            "Epoch 1251/2000, Rel Train Loss: 48.15%, Rel Val Loss: 46.05%\n",
            "Moving Avg Val Loss: 0.523344\n",
            "Epoch 1252/2000, Train Loss: 0.001057, Val Loss: 0.047972\n",
            "Epoch 1252/2000, Rel Train Loss: 47.98%, Rel Val Loss: 48.42%\n",
            "Moving Avg Val Loss: 0.517009\n",
            "Epoch 1253/2000, Train Loss: 0.000564, Val Loss: 0.041448\n",
            "Epoch 1253/2000, Rel Train Loss: 38.81%, Rel Val Loss: 45.79%\n",
            "Moving Avg Val Loss: 0.534492\n",
            "Epoch 1254/2000, Train Loss: 0.000636, Val Loss: 0.042191\n",
            "Epoch 1254/2000, Rel Train Loss: 44.63%, Rel Val Loss: 62.22%\n",
            "Moving Avg Val Loss: 0.486954\n",
            "Epoch 1255/2000, Train Loss: 0.002029, Val Loss: 0.047731\n",
            "Epoch 1255/2000, Rel Train Loss: 53.27%, Rel Val Loss: 40.99%\n",
            "Moving Avg Val Loss: 0.617217\n",
            "Epoch 1256/2000, Train Loss: 0.001799, Val Loss: 0.040603\n",
            "Epoch 1256/2000, Rel Train Loss: 62.72%, Rel Val Loss: 111.19%\n",
            "Moving Avg Val Loss: 0.656486\n",
            "Epoch 1257/2000, Train Loss: 0.001871, Val Loss: 0.051342\n",
            "Epoch 1257/2000, Rel Train Loss: 72.36%, Rel Val Loss: 68.05%\n",
            "Moving Avg Val Loss: 0.740515\n",
            "Epoch 1258/2000, Train Loss: 0.001810, Val Loss: 0.038616\n",
            "Epoch 1258/2000, Rel Train Loss: 59.54%, Rel Val Loss: 87.81%\n",
            "Moving Avg Val Loss: 0.806731\n",
            "Epoch 1259/2000, Train Loss: 0.001667, Val Loss: 0.042753\n",
            "Epoch 1259/2000, Rel Train Loss: 65.19%, Rel Val Loss: 95.33%\n",
            "Moving Avg Val Loss: 0.801499\n",
            "Epoch 1260/2000, Train Loss: 0.000966, Val Loss: 0.044430\n",
            "Epoch 1260/2000, Rel Train Loss: 55.88%, Rel Val Loss: 38.37%\n",
            "Moving Avg Val Loss: 0.669950\n",
            "Epoch 1261/2000, Train Loss: 0.000591, Val Loss: 0.037996\n",
            "Epoch 1261/2000, Rel Train Loss: 41.98%, Rel Val Loss: 45.41%\n",
            "Moving Avg Val Loss: 0.642368\n",
            "Epoch 1262/2000, Train Loss: 0.000484, Val Loss: 0.043013\n",
            "Epoch 1262/2000, Rel Train Loss: 39.14%, Rel Val Loss: 54.26%\n",
            "Moving Avg Val Loss: 0.548992\n",
            "Epoch 1263/2000, Train Loss: 0.000358, Val Loss: 0.037625\n",
            "Epoch 1263/2000, Rel Train Loss: 36.19%, Rel Val Loss: 41.12%\n",
            "Moving Avg Val Loss: 0.435581\n",
            "Epoch 1264/2000, Train Loss: 0.000423, Val Loss: 0.038821\n",
            "Epoch 1264/2000, Rel Train Loss: 33.63%, Rel Val Loss: 38.63%\n",
            "Moving Avg Val Loss: 0.438771\n",
            "Epoch 1265/2000, Train Loss: 0.000680, Val Loss: 0.043392\n",
            "Epoch 1265/2000, Rel Train Loss: 35.01%, Rel Val Loss: 39.97%\n",
            "Moving Avg Val Loss: 0.489471\n",
            "Epoch 1266/2000, Train Loss: 0.001136, Val Loss: 0.038587\n",
            "Epoch 1266/2000, Rel Train Loss: 39.04%, Rel Val Loss: 70.76%\n",
            "Moving Avg Val Loss: 0.500029\n",
            "Epoch 1267/2000, Train Loss: 0.002303, Val Loss: 0.047636\n",
            "Epoch 1267/2000, Rel Train Loss: 66.39%, Rel Val Loss: 59.54%\n",
            "Moving Avg Val Loss: 0.738356\n",
            "Epoch 1268/2000, Train Loss: 0.005476, Val Loss: 0.053330\n",
            "Epoch 1268/2000, Rel Train Loss: 109.45%, Rel Val Loss: 160.28%\n",
            "Moving Avg Val Loss: 0.756717\n",
            "Epoch 1269/2000, Train Loss: 0.002536, Val Loss: 0.038286\n",
            "Epoch 1269/2000, Rel Train Loss: 92.36%, Rel Val Loss: 47.81%\n",
            "Moving Avg Val Loss: 0.777583\n",
            "Epoch 1270/2000, Train Loss: 0.000979, Val Loss: 0.038417\n",
            "Epoch 1270/2000, Rel Train Loss: 51.84%, Rel Val Loss: 50.40%\n",
            "Moving Avg Val Loss: 0.715677\n",
            "Epoch 1271/2000, Train Loss: 0.000512, Val Loss: 0.037519\n",
            "Epoch 1271/2000, Rel Train Loss: 34.86%, Rel Val Loss: 39.81%\n",
            "Moving Avg Val Loss: 0.699961\n",
            "Epoch 1272/2000, Train Loss: 0.000594, Val Loss: 0.034461\n",
            "Epoch 1272/2000, Rel Train Loss: 33.98%, Rel Val Loss: 51.68%\n",
            "Moving Avg Val Loss: 0.480992\n",
            "Epoch 1273/2000, Train Loss: 0.000878, Val Loss: 0.041110\n",
            "Epoch 1273/2000, Rel Train Loss: 44.88%, Rel Val Loss: 50.80%\n",
            "Moving Avg Val Loss: 0.472386\n",
            "Epoch 1274/2000, Train Loss: 0.000699, Val Loss: 0.033600\n",
            "Epoch 1274/2000, Rel Train Loss: 62.77%, Rel Val Loss: 43.50%\n",
            "Moving Avg Val Loss: 0.484424\n",
            "Epoch 1275/2000, Train Loss: 0.000585, Val Loss: 0.040659\n",
            "Epoch 1275/2000, Rel Train Loss: 48.66%, Rel Val Loss: 56.42%\n",
            "Moving Avg Val Loss: 0.559889\n",
            "Epoch 1276/2000, Train Loss: 0.001929, Val Loss: 0.038916\n",
            "Epoch 1276/2000, Rel Train Loss: 53.92%, Rel Val Loss: 77.54%\n",
            "Moving Avg Val Loss: 0.538816\n",
            "Epoch 1277/2000, Train Loss: 0.000786, Val Loss: 0.039811\n",
            "Epoch 1277/2000, Rel Train Loss: 51.68%, Rel Val Loss: 41.14%\n",
            "Moving Avg Val Loss: 0.610097\n",
            "Epoch 1278/2000, Train Loss: 0.001441, Val Loss: 0.047931\n",
            "Epoch 1278/2000, Rel Train Loss: 45.31%, Rel Val Loss: 86.44%\n",
            "Moving Avg Val Loss: 0.641635\n",
            "Epoch 1279/2000, Train Loss: 0.001732, Val Loss: 0.054717\n",
            "Epoch 1279/2000, Rel Train Loss: 56.21%, Rel Val Loss: 59.27%\n",
            "Moving Avg Val Loss: 0.801877\n",
            "Epoch 1280/2000, Train Loss: 0.006261, Val Loss: 0.055309\n",
            "Epoch 1280/2000, Rel Train Loss: 86.02%, Rel Val Loss: 136.54%\n",
            "Moving Avg Val Loss: 0.818641\n",
            "Epoch 1281/2000, Train Loss: 0.004255, Val Loss: 0.039870\n",
            "Epoch 1281/2000, Rel Train Loss: 90.66%, Rel Val Loss: 85.92%\n",
            "Moving Avg Val Loss: 0.848318\n",
            "Epoch 1282/2000, Train Loss: 0.001575, Val Loss: 0.039857\n",
            "Epoch 1282/2000, Rel Train Loss: 73.10%, Rel Val Loss: 55.98%\n",
            "Moving Avg Val Loss: 0.779347\n",
            "Epoch 1283/2000, Train Loss: 0.001732, Val Loss: 0.042284\n",
            "Epoch 1283/2000, Rel Train Loss: 52.52%, Rel Val Loss: 51.95%\n",
            "Moving Avg Val Loss: 0.752264\n",
            "Epoch 1284/2000, Train Loss: 0.001018, Val Loss: 0.040717\n",
            "Epoch 1284/2000, Rel Train Loss: 37.68%, Rel Val Loss: 45.73%\n",
            "Moving Avg Val Loss: 0.686618\n",
            "Epoch 1285/2000, Train Loss: 0.002516, Val Loss: 0.046020\n",
            "Epoch 1285/2000, Rel Train Loss: 57.07%, Rel Val Loss: 103.72%\n",
            "Moving Avg Val Loss: 0.655233\n",
            "Epoch 1286/2000, Train Loss: 0.005881, Val Loss: 0.047329\n",
            "Epoch 1286/2000, Rel Train Loss: 72.39%, Rel Val Loss: 70.23%\n",
            "Moving Avg Val Loss: 0.693335\n",
            "Epoch 1287/2000, Train Loss: 0.001547, Val Loss: 0.051231\n",
            "Epoch 1287/2000, Rel Train Loss: 65.00%, Rel Val Loss: 75.03%\n",
            "Moving Avg Val Loss: 0.704103\n",
            "Epoch 1288/2000, Train Loss: 0.004300, Val Loss: 0.037358\n",
            "Epoch 1288/2000, Rel Train Loss: 79.14%, Rel Val Loss: 57.34%\n",
            "Moving Avg Val Loss: 0.752439\n",
            "Epoch 1289/2000, Train Loss: 0.004128, Val Loss: 0.050626\n",
            "Epoch 1289/2000, Rel Train Loss: 96.33%, Rel Val Loss: 69.90%\n",
            "Moving Avg Val Loss: 0.652219\n",
            "Epoch 1290/2000, Train Loss: 0.003034, Val Loss: 0.035643\n",
            "Epoch 1290/2000, Rel Train Loss: 79.19%, Rel Val Loss: 53.61%\n",
            "Moving Avg Val Loss: 0.604344\n",
            "Epoch 1291/2000, Train Loss: 0.003111, Val Loss: 0.040334\n",
            "Epoch 1291/2000, Rel Train Loss: 75.74%, Rel Val Loss: 46.29%\n",
            "Moving Avg Val Loss: 0.565980\n",
            "Epoch 1292/2000, Train Loss: 0.001010, Val Loss: 0.035764\n",
            "Epoch 1292/2000, Rel Train Loss: 61.54%, Rel Val Loss: 55.85%\n",
            "Moving Avg Val Loss: 0.552102\n",
            "Epoch 1293/2000, Train Loss: 0.000672, Val Loss: 0.032023\n",
            "Epoch 1293/2000, Rel Train Loss: 37.56%, Rel Val Loss: 50.40%\n",
            "Moving Avg Val Loss: 0.491516\n",
            "Epoch 1294/2000, Train Loss: 0.000484, Val Loss: 0.035829\n",
            "Epoch 1294/2000, Rel Train Loss: 33.75%, Rel Val Loss: 39.61%\n",
            "Moving Avg Val Loss: 0.459857\n",
            "Epoch 1295/2000, Train Loss: 0.000402, Val Loss: 0.034266\n",
            "Epoch 1295/2000, Rel Train Loss: 35.45%, Rel Val Loss: 37.78%\n",
            "Moving Avg Val Loss: 0.440365\n",
            "Epoch 1296/2000, Train Loss: 0.000497, Val Loss: 0.032788\n",
            "Epoch 1296/2000, Rel Train Loss: 35.70%, Rel Val Loss: 36.55%\n",
            "Moving Avg Val Loss: 0.403565\n",
            "Epoch 1297/2000, Train Loss: 0.000409, Val Loss: 0.036988\n",
            "Epoch 1297/2000, Rel Train Loss: 34.92%, Rel Val Loss: 37.45%\n",
            "Moving Avg Val Loss: 0.398449\n",
            "Epoch 1298/2000, Train Loss: 0.000646, Val Loss: 0.034115\n",
            "Epoch 1298/2000, Rel Train Loss: 34.18%, Rel Val Loss: 47.84%\n",
            "Moving Avg Val Loss: 0.394331\n",
            "Epoch 1299/2000, Train Loss: 0.000604, Val Loss: 0.036760\n",
            "Epoch 1299/2000, Rel Train Loss: 37.27%, Rel Val Loss: 37.55%\n",
            "Moving Avg Val Loss: 0.391327\n",
            "Epoch 1300/2000, Train Loss: 0.000538, Val Loss: 0.036512\n",
            "Epoch 1300/2000, Rel Train Loss: 37.78%, Rel Val Loss: 36.28%\n",
            "Moving Avg Val Loss: 0.389507\n",
            "Epoch 1301/2000, Train Loss: 0.000454, Val Loss: 0.033712\n",
            "Epoch 1301/2000, Rel Train Loss: 31.30%, Rel Val Loss: 35.64%\n",
            "Moving Avg Val Loss: 0.388906\n",
            "Epoch 1302/2000, Train Loss: 0.000560, Val Loss: 0.035400\n",
            "Epoch 1302/2000, Rel Train Loss: 35.28%, Rel Val Loss: 37.15%\n",
            "Moving Avg Val Loss: 0.478147\n",
            "Epoch 1303/2000, Train Loss: 0.001314, Val Loss: 0.037670\n",
            "Epoch 1303/2000, Rel Train Loss: 50.17%, Rel Val Loss: 92.46%\n",
            "Moving Avg Val Loss: 0.563868\n",
            "Epoch 1304/2000, Train Loss: 0.001416, Val Loss: 0.041033\n",
            "Epoch 1304/2000, Rel Train Loss: 73.13%, Rel Val Loss: 80.41%\n",
            "Moving Avg Val Loss: 0.604516\n",
            "Epoch 1305/2000, Train Loss: 0.001890, Val Loss: 0.044708\n",
            "Epoch 1305/2000, Rel Train Loss: 46.44%, Rel Val Loss: 56.60%\n",
            "Moving Avg Val Loss: 0.664954\n",
            "Epoch 1306/2000, Train Loss: 0.002825, Val Loss: 0.040768\n",
            "Epoch 1306/2000, Rel Train Loss: 60.87%, Rel Val Loss: 65.86%\n",
            "Moving Avg Val Loss: 0.676788\n",
            "Epoch 1307/2000, Train Loss: 0.000962, Val Loss: 0.035805\n",
            "Epoch 1307/2000, Rel Train Loss: 60.37%, Rel Val Loss: 43.07%\n",
            "Moving Avg Val Loss: 0.702891\n",
            "Epoch 1308/2000, Train Loss: 0.002272, Val Loss: 0.046139\n",
            "Epoch 1308/2000, Rel Train Loss: 60.64%, Rel Val Loss: 105.51%\n",
            "Moving Avg Val Loss: 0.629654\n",
            "Epoch 1309/2000, Train Loss: 0.003256, Val Loss: 0.039777\n",
            "Epoch 1309/2000, Rel Train Loss: 68.71%, Rel Val Loss: 43.79%\n",
            "Moving Avg Val Loss: 0.600841\n",
            "Epoch 1310/2000, Train Loss: 0.001332, Val Loss: 0.033599\n",
            "Epoch 1310/2000, Rel Train Loss: 61.17%, Rel Val Loss: 42.19%\n",
            "Moving Avg Val Loss: 0.614723\n",
            "Epoch 1311/2000, Train Loss: 0.001521, Val Loss: 0.041474\n",
            "Epoch 1311/2000, Rel Train Loss: 69.55%, Rel Val Loss: 72.80%\n",
            "Moving Avg Val Loss: 0.613368\n",
            "Epoch 1312/2000, Train Loss: 0.001154, Val Loss: 0.032227\n",
            "Epoch 1312/2000, Rel Train Loss: 39.93%, Rel Val Loss: 42.39%\n",
            "Moving Avg Val Loss: 0.477794\n",
            "Epoch 1313/2000, Train Loss: 0.000486, Val Loss: 0.034182\n",
            "Epoch 1313/2000, Rel Train Loss: 35.59%, Rel Val Loss: 37.73%\n",
            "Moving Avg Val Loss: 0.461687\n",
            "Epoch 1314/2000, Train Loss: 0.000383, Val Loss: 0.035798\n",
            "Epoch 1314/2000, Rel Train Loss: 32.15%, Rel Val Loss: 35.74%\n",
            "Moving Avg Val Loss: 0.452117\n",
            "Epoch 1315/2000, Train Loss: 0.000369, Val Loss: 0.034958\n",
            "Epoch 1315/2000, Rel Train Loss: 33.46%, Rel Val Loss: 37.41%\n",
            "Moving Avg Val Loss: 0.409571\n",
            "Epoch 1316/2000, Train Loss: 0.000519, Val Loss: 0.037872\n",
            "Epoch 1316/2000, Rel Train Loss: 35.94%, Rel Val Loss: 51.52%\n",
            "Moving Avg Val Loss: 0.398831\n",
            "Epoch 1317/2000, Train Loss: 0.000394, Val Loss: 0.036067\n",
            "Epoch 1317/2000, Rel Train Loss: 32.42%, Rel Val Loss: 37.02%\n",
            "Moving Avg Val Loss: 0.422996\n",
            "Epoch 1318/2000, Train Loss: 0.002339, Val Loss: 0.041129\n",
            "Epoch 1318/2000, Rel Train Loss: 69.75%, Rel Val Loss: 49.81%\n",
            "Moving Avg Val Loss: 0.616380\n",
            "Epoch 1319/2000, Train Loss: 0.002622, Val Loss: 0.048157\n",
            "Epoch 1319/2000, Rel Train Loss: 98.04%, Rel Val Loss: 132.43%\n",
            "Moving Avg Val Loss: 0.702074\n",
            "Epoch 1320/2000, Train Loss: 0.003278, Val Loss: 0.037781\n",
            "Epoch 1320/2000, Rel Train Loss: 108.27%, Rel Val Loss: 80.26%\n",
            "Moving Avg Val Loss: 0.705717\n",
            "Epoch 1321/2000, Train Loss: 0.001750, Val Loss: 0.039591\n",
            "Epoch 1321/2000, Rel Train Loss: 75.14%, Rel Val Loss: 53.35%\n",
            "Moving Avg Val Loss: 0.709227\n",
            "Epoch 1322/2000, Train Loss: 0.001177, Val Loss: 0.034297\n",
            "Epoch 1322/2000, Rel Train Loss: 39.97%, Rel Val Loss: 38.77%\n",
            "Moving Avg Val Loss: 0.720635\n",
            "Epoch 1323/2000, Train Loss: 0.000774, Val Loss: 0.040492\n",
            "Epoch 1323/2000, Rel Train Loss: 53.50%, Rel Val Loss: 55.51%\n",
            "Moving Avg Val Loss: 0.530923\n",
            "Epoch 1324/2000, Train Loss: 0.000614, Val Loss: 0.033136\n",
            "Epoch 1324/2000, Rel Train Loss: 36.51%, Rel Val Loss: 37.57%\n",
            "Moving Avg Val Loss: 0.465149\n",
            "Epoch 1325/2000, Train Loss: 0.000820, Val Loss: 0.044416\n",
            "Epoch 1325/2000, Rel Train Loss: 38.08%, Rel Val Loss: 47.37%\n",
            "Moving Avg Val Loss: 0.504987\n",
            "Epoch 1326/2000, Train Loss: 0.001044, Val Loss: 0.038222\n",
            "Epoch 1326/2000, Rel Train Loss: 46.03%, Rel Val Loss: 73.26%\n",
            "Moving Avg Val Loss: 0.577707\n",
            "Epoch 1327/2000, Train Loss: 0.002117, Val Loss: 0.041787\n",
            "Epoch 1327/2000, Rel Train Loss: 53.87%, Rel Val Loss: 75.13%\n",
            "Moving Avg Val Loss: 0.547734\n",
            "Epoch 1328/2000, Train Loss: 0.001637, Val Loss: 0.037805\n",
            "Epoch 1328/2000, Rel Train Loss: 50.06%, Rel Val Loss: 40.53%\n",
            "Moving Avg Val Loss: 0.554662\n",
            "Epoch 1329/2000, Train Loss: 0.000640, Val Loss: 0.037575\n",
            "Epoch 1329/2000, Rel Train Loss: 38.79%, Rel Val Loss: 41.04%\n",
            "Moving Avg Val Loss: 0.547496\n",
            "Epoch 1330/2000, Train Loss: 0.000689, Val Loss: 0.037250\n",
            "Epoch 1330/2000, Rel Train Loss: 35.76%, Rel Val Loss: 43.79%\n",
            "Moving Avg Val Loss: 0.475735\n",
            "Epoch 1331/2000, Train Loss: 0.000394, Val Loss: 0.037857\n",
            "Epoch 1331/2000, Rel Train Loss: 32.68%, Rel Val Loss: 37.38%\n",
            "Moving Avg Val Loss: 0.405647\n",
            "Epoch 1332/2000, Train Loss: 0.000377, Val Loss: 0.037438\n",
            "Epoch 1332/2000, Rel Train Loss: 35.58%, Rel Val Loss: 40.09%\n",
            "Moving Avg Val Loss: 0.418559\n",
            "Epoch 1333/2000, Train Loss: 0.000751, Val Loss: 0.040658\n",
            "Epoch 1333/2000, Rel Train Loss: 37.89%, Rel Val Loss: 46.98%\n",
            "Moving Avg Val Loss: 0.446777\n",
            "Epoch 1334/2000, Train Loss: 0.001001, Val Loss: 0.036461\n",
            "Epoch 1334/2000, Rel Train Loss: 43.06%, Rel Val Loss: 55.15%\n",
            "Moving Avg Val Loss: 0.481226\n",
            "Epoch 1335/2000, Train Loss: 0.001834, Val Loss: 0.045756\n",
            "Epoch 1335/2000, Rel Train Loss: 46.98%, Rel Val Loss: 61.01%\n",
            "Moving Avg Val Loss: 0.483406\n",
            "Epoch 1336/2000, Train Loss: 0.001081, Val Loss: 0.035431\n",
            "Epoch 1336/2000, Rel Train Loss: 37.86%, Rel Val Loss: 38.47%\n",
            "Moving Avg Val Loss: 0.566880\n",
            "Epoch 1337/2000, Train Loss: 0.001972, Val Loss: 0.040267\n",
            "Epoch 1337/2000, Rel Train Loss: 42.09%, Rel Val Loss: 81.83%\n",
            "Moving Avg Val Loss: 0.671179\n",
            "Epoch 1338/2000, Train Loss: 0.002423, Val Loss: 0.048807\n",
            "Epoch 1338/2000, Rel Train Loss: 73.60%, Rel Val Loss: 99.13%\n",
            "Moving Avg Val Loss: 0.681553\n",
            "Epoch 1339/2000, Train Loss: 0.002908, Val Loss: 0.036337\n",
            "Epoch 1339/2000, Rel Train Loss: 72.31%, Rel Val Loss: 60.33%\n",
            "Moving Avg Val Loss: 0.637299\n",
            "Epoch 1340/2000, Train Loss: 0.000829, Val Loss: 0.037660\n",
            "Epoch 1340/2000, Rel Train Loss: 55.81%, Rel Val Loss: 38.88%\n",
            "Moving Avg Val Loss: 0.637663\n",
            "Epoch 1341/2000, Train Loss: 0.000924, Val Loss: 0.040566\n",
            "Epoch 1341/2000, Rel Train Loss: 38.88%, Rel Val Loss: 38.66%\n",
            "Moving Avg Val Loss: 0.628860\n",
            "Epoch 1342/2000, Train Loss: 0.001375, Val Loss: 0.038331\n",
            "Epoch 1342/2000, Rel Train Loss: 51.41%, Rel Val Loss: 77.43%\n",
            "Moving Avg Val Loss: 0.506387\n",
            "Epoch 1343/2000, Train Loss: 0.001805, Val Loss: 0.038356\n",
            "Epoch 1343/2000, Rel Train Loss: 66.48%, Rel Val Loss: 37.90%\n",
            "Moving Avg Val Loss: 0.476223\n",
            "Epoch 1344/2000, Train Loss: 0.001023, Val Loss: 0.036755\n",
            "Epoch 1344/2000, Rel Train Loss: 52.30%, Rel Val Loss: 45.25%\n",
            "Moving Avg Val Loss: 0.528104\n",
            "Epoch 1345/2000, Train Loss: 0.000665, Val Loss: 0.040943\n",
            "Epoch 1345/2000, Rel Train Loss: 44.80%, Rel Val Loss: 64.82%\n",
            "Moving Avg Val Loss: 0.572541\n",
            "Epoch 1346/2000, Train Loss: 0.001355, Val Loss: 0.042510\n",
            "Epoch 1346/2000, Rel Train Loss: 51.34%, Rel Val Loss: 60.87%\n",
            "Moving Avg Val Loss: 0.507510\n",
            "Epoch 1347/2000, Train Loss: 0.000903, Val Loss: 0.037297\n",
            "Epoch 1347/2000, Rel Train Loss: 43.34%, Rel Val Loss: 44.91%\n",
            "Moving Avg Val Loss: 0.605197\n",
            "Epoch 1348/2000, Train Loss: 0.001969, Val Loss: 0.034837\n",
            "Epoch 1348/2000, Rel Train Loss: 42.51%, Rel Val Loss: 86.74%\n",
            "Moving Avg Val Loss: 0.597879\n",
            "Epoch 1349/2000, Train Loss: 0.001319, Val Loss: 0.043365\n",
            "Epoch 1349/2000, Rel Train Loss: 57.71%, Rel Val Loss: 41.59%\n",
            "Moving Avg Val Loss: 0.561718\n",
            "Epoch 1350/2000, Train Loss: 0.000657, Val Loss: 0.035718\n",
            "Epoch 1350/2000, Rel Train Loss: 42.39%, Rel Val Loss: 46.74%\n",
            "Moving Avg Val Loss: 0.514197\n",
            "Epoch 1351/2000, Train Loss: 0.000487, Val Loss: 0.038275\n",
            "Epoch 1351/2000, Rel Train Loss: 42.89%, Rel Val Loss: 37.11%\n",
            "Moving Avg Val Loss: 0.494260\n",
            "Epoch 1352/2000, Train Loss: 0.001124, Val Loss: 0.040040\n",
            "Epoch 1352/2000, Rel Train Loss: 38.00%, Rel Val Loss: 34.94%\n",
            "Moving Avg Val Loss: 0.403189\n",
            "Epoch 1353/2000, Train Loss: 0.001109, Val Loss: 0.032353\n",
            "Epoch 1353/2000, Rel Train Loss: 44.46%, Rel Val Loss: 41.20%\n",
            "Moving Avg Val Loss: 0.410657\n",
            "Epoch 1354/2000, Train Loss: 0.001055, Val Loss: 0.043281\n",
            "Epoch 1354/2000, Rel Train Loss: 38.76%, Rel Val Loss: 45.33%\n",
            "Moving Avg Val Loss: 0.420646\n",
            "Epoch 1355/2000, Train Loss: 0.001870, Val Loss: 0.046632\n",
            "Epoch 1355/2000, Rel Train Loss: 48.53%, Rel Val Loss: 51.74%\n",
            "Moving Avg Val Loss: 0.468402\n",
            "Epoch 1356/2000, Train Loss: 0.004669, Val Loss: 0.040229\n",
            "Epoch 1356/2000, Rel Train Loss: 63.47%, Rel Val Loss: 60.99%\n",
            "Moving Avg Val Loss: 0.544505\n",
            "Epoch 1357/2000, Train Loss: 0.001608, Val Loss: 0.041941\n",
            "Epoch 1357/2000, Rel Train Loss: 71.42%, Rel Val Loss: 72.99%\n",
            "Moving Avg Val Loss: 0.560710\n",
            "Epoch 1358/2000, Train Loss: 0.002667, Val Loss: 0.037604\n",
            "Epoch 1358/2000, Rel Train Loss: 53.27%, Rel Val Loss: 49.31%\n",
            "Moving Avg Val Loss: 0.561906\n",
            "Epoch 1359/2000, Train Loss: 0.001223, Val Loss: 0.034431\n",
            "Epoch 1359/2000, Rel Train Loss: 51.14%, Rel Val Loss: 45.92%\n",
            "Moving Avg Val Loss: 0.577074\n",
            "Epoch 1360/2000, Train Loss: 0.000690, Val Loss: 0.039321\n",
            "Epoch 1360/2000, Rel Train Loss: 48.07%, Rel Val Loss: 59.32%\n",
            "Moving Avg Val Loss: 0.530431\n",
            "Epoch 1361/2000, Train Loss: 0.000596, Val Loss: 0.037227\n",
            "Epoch 1361/2000, Rel Train Loss: 47.97%, Rel Val Loss: 37.67%\n",
            "Moving Avg Val Loss: 0.456371\n",
            "Epoch 1362/2000, Train Loss: 0.000384, Val Loss: 0.036671\n",
            "Epoch 1362/2000, Rel Train Loss: 33.22%, Rel Val Loss: 35.96%\n",
            "Moving Avg Val Loss: 0.438966\n",
            "Epoch 1363/2000, Train Loss: 0.000353, Val Loss: 0.036838\n",
            "Epoch 1363/2000, Rel Train Loss: 33.73%, Rel Val Loss: 40.60%\n",
            "Moving Avg Val Loss: 0.419201\n",
            "Epoch 1364/2000, Train Loss: 0.000375, Val Loss: 0.037440\n",
            "Epoch 1364/2000, Rel Train Loss: 30.84%, Rel Val Loss: 36.04%\n",
            "Moving Avg Val Loss: 0.371702\n",
            "Epoch 1365/2000, Train Loss: 0.000333, Val Loss: 0.036630\n",
            "Epoch 1365/2000, Rel Train Loss: 32.23%, Rel Val Loss: 35.57%\n",
            "Moving Avg Val Loss: 0.393627\n",
            "Epoch 1366/2000, Train Loss: 0.000366, Val Loss: 0.036468\n",
            "Epoch 1366/2000, Rel Train Loss: 34.07%, Rel Val Loss: 48.63%\n",
            "Moving Avg Val Loss: 0.390567\n",
            "Epoch 1367/2000, Train Loss: 0.000324, Val Loss: 0.036479\n",
            "Epoch 1367/2000, Rel Train Loss: 33.46%, Rel Val Loss: 34.43%\n",
            "Moving Avg Val Loss: 0.424825\n",
            "Epoch 1368/2000, Train Loss: 0.000807, Val Loss: 0.035686\n",
            "Epoch 1368/2000, Rel Train Loss: 35.53%, Rel Val Loss: 57.73%\n",
            "Moving Avg Val Loss: 0.435862\n",
            "Epoch 1369/2000, Train Loss: 0.000676, Val Loss: 0.038994\n",
            "Epoch 1369/2000, Rel Train Loss: 42.32%, Rel Val Loss: 41.56%\n",
            "Moving Avg Val Loss: 0.440803\n",
            "Epoch 1370/2000, Train Loss: 0.000439, Val Loss: 0.037897\n",
            "Epoch 1370/2000, Rel Train Loss: 44.39%, Rel Val Loss: 38.04%\n",
            "Moving Avg Val Loss: 0.439824\n",
            "Epoch 1371/2000, Train Loss: 0.000431, Val Loss: 0.036756\n",
            "Epoch 1371/2000, Rel Train Loss: 32.82%, Rel Val Loss: 48.14%\n",
            "Moving Avg Val Loss: 0.468451\n",
            "Epoch 1372/2000, Train Loss: 0.000553, Val Loss: 0.038866\n",
            "Epoch 1372/2000, Rel Train Loss: 40.28%, Rel Val Loss: 48.75%\n",
            "Moving Avg Val Loss: 0.437899\n",
            "Epoch 1373/2000, Train Loss: 0.001516, Val Loss: 0.036591\n",
            "Epoch 1373/2000, Rel Train Loss: 40.28%, Rel Val Loss: 42.46%\n",
            "Moving Avg Val Loss: 0.455354\n",
            "Epoch 1374/2000, Train Loss: 0.001732, Val Loss: 0.042914\n",
            "Epoch 1374/2000, Rel Train Loss: 65.05%, Rel Val Loss: 50.29%\n",
            "Moving Avg Val Loss: 0.548723\n",
            "Epoch 1375/2000, Train Loss: 0.001687, Val Loss: 0.040411\n",
            "Epoch 1375/2000, Rel Train Loss: 76.80%, Rel Val Loss: 84.73%\n",
            "Moving Avg Val Loss: 0.540554\n",
            "Epoch 1376/2000, Train Loss: 0.000921, Val Loss: 0.036810\n",
            "Epoch 1376/2000, Rel Train Loss: 46.88%, Rel Val Loss: 44.06%\n",
            "Moving Avg Val Loss: 0.525146\n",
            "Epoch 1377/2000, Train Loss: 0.000528, Val Loss: 0.038973\n",
            "Epoch 1377/2000, Rel Train Loss: 35.34%, Rel Val Loss: 41.04%\n",
            "Moving Avg Val Loss: 0.554217\n",
            "Epoch 1378/2000, Train Loss: 0.001744, Val Loss: 0.044698\n",
            "Epoch 1378/2000, Rel Train Loss: 46.37%, Rel Val Loss: 56.99%\n",
            "Moving Avg Val Loss: 0.688268\n",
            "Epoch 1379/2000, Train Loss: 0.004844, Val Loss: 0.045285\n",
            "Epoch 1379/2000, Rel Train Loss: 85.57%, Rel Val Loss: 117.31%\n",
            "Moving Avg Val Loss: 0.742967\n",
            "Epoch 1380/2000, Train Loss: 0.002043, Val Loss: 0.038032\n",
            "Epoch 1380/2000, Rel Train Loss: 96.47%, Rel Val Loss: 112.08%\n",
            "Moving Avg Val Loss: 0.867253\n",
            "Epoch 1381/2000, Train Loss: 0.001882, Val Loss: 0.040050\n",
            "Epoch 1381/2000, Rel Train Loss: 87.65%, Rel Val Loss: 106.20%\n",
            "Moving Avg Val Loss: 0.878722\n",
            "Epoch 1382/2000, Train Loss: 0.001516, Val Loss: 0.037724\n",
            "Epoch 1382/2000, Rel Train Loss: 62.12%, Rel Val Loss: 46.78%\n",
            "Moving Avg Val Loss: 0.840137\n",
            "Epoch 1383/2000, Train Loss: 0.000950, Val Loss: 0.038244\n",
            "Epoch 1383/2000, Rel Train Loss: 39.78%, Rel Val Loss: 37.70%\n",
            "Moving Avg Val Loss: 0.700127\n",
            "Epoch 1384/2000, Train Loss: 0.000582, Val Loss: 0.034938\n",
            "Epoch 1384/2000, Rel Train Loss: 38.24%, Rel Val Loss: 47.31%\n",
            "Moving Avg Val Loss: 0.557922\n",
            "Epoch 1385/2000, Train Loss: 0.000578, Val Loss: 0.036915\n",
            "Epoch 1385/2000, Rel Train Loss: 32.01%, Rel Val Loss: 40.98%\n",
            "Moving Avg Val Loss: 0.495731\n",
            "Epoch 1386/2000, Train Loss: 0.001328, Val Loss: 0.034656\n",
            "Epoch 1386/2000, Rel Train Loss: 51.88%, Rel Val Loss: 75.11%\n",
            "Moving Avg Val Loss: 0.509249\n",
            "Epoch 1387/2000, Train Loss: 0.001595, Val Loss: 0.038566\n",
            "Epoch 1387/2000, Rel Train Loss: 66.94%, Rel Val Loss: 53.54%\n",
            "Moving Avg Val Loss: 0.531555\n",
            "Epoch 1388/2000, Train Loss: 0.001130, Val Loss: 0.042390\n",
            "Epoch 1388/2000, Rel Train Loss: 55.15%, Rel Val Loss: 48.85%\n",
            "Moving Avg Val Loss: 0.520621\n",
            "Epoch 1389/2000, Train Loss: 0.000828, Val Loss: 0.036903\n",
            "Epoch 1389/2000, Rel Train Loss: 43.41%, Rel Val Loss: 41.84%\n",
            "Moving Avg Val Loss: 0.519426\n",
            "Epoch 1390/2000, Train Loss: 0.000932, Val Loss: 0.039232\n",
            "Epoch 1390/2000, Rel Train Loss: 41.94%, Rel Val Loss: 40.38%\n",
            "Moving Avg Val Loss: 0.452211\n",
            "Epoch 1391/2000, Train Loss: 0.000791, Val Loss: 0.037113\n",
            "Epoch 1391/2000, Rel Train Loss: 51.01%, Rel Val Loss: 41.50%\n",
            "Moving Avg Val Loss: 0.543423\n",
            "Epoch 1392/2000, Train Loss: 0.001424, Val Loss: 0.038449\n",
            "Epoch 1392/2000, Rel Train Loss: 67.88%, Rel Val Loss: 99.14%\n",
            "Moving Avg Val Loss: 0.530979\n",
            "Epoch 1393/2000, Train Loss: 0.001541, Val Loss: 0.038089\n",
            "Epoch 1393/2000, Rel Train Loss: 66.70%, Rel Val Loss: 42.63%\n",
            "Moving Avg Val Loss: 0.514324\n",
            "Epoch 1394/2000, Train Loss: 0.000669, Val Loss: 0.036495\n",
            "Epoch 1394/2000, Rel Train Loss: 40.67%, Rel Val Loss: 33.51%\n",
            "Moving Avg Val Loss: 0.509019\n",
            "Epoch 1395/2000, Train Loss: 0.000385, Val Loss: 0.036426\n",
            "Epoch 1395/2000, Rel Train Loss: 38.96%, Rel Val Loss: 37.73%\n",
            "Moving Avg Val Loss: 0.497081\n",
            "Epoch 1396/2000, Train Loss: 0.000434, Val Loss: 0.037777\n",
            "Epoch 1396/2000, Rel Train Loss: 29.68%, Rel Val Loss: 35.53%\n",
            "Moving Avg Val Loss: 0.369541\n",
            "Epoch 1397/2000, Train Loss: 0.000288, Val Loss: 0.037197\n",
            "Epoch 1397/2000, Rel Train Loss: 31.32%, Rel Val Loss: 35.37%\n",
            "Moving Avg Val Loss: 0.360480\n",
            "Epoch 1398/2000, Train Loss: 0.000658, Val Loss: 0.035101\n",
            "Epoch 1398/2000, Rel Train Loss: 36.45%, Rel Val Loss: 38.10%\n",
            "Moving Avg Val Loss: 0.366413\n",
            "Epoch 1399/2000, Train Loss: 0.000552, Val Loss: 0.037911\n",
            "Epoch 1399/2000, Rel Train Loss: 31.00%, Rel Val Loss: 36.48%\n",
            "Moving Avg Val Loss: 0.365487\n",
            "Epoch 1400/2000, Train Loss: 0.000993, Val Loss: 0.036003\n",
            "Epoch 1400/2000, Rel Train Loss: 33.71%, Rel Val Loss: 37.26%\n",
            "Moving Avg Val Loss: 0.402771\n",
            "Epoch 1401/2000, Train Loss: 0.001167, Val Loss: 0.036121\n",
            "Epoch 1401/2000, Rel Train Loss: 34.81%, Rel Val Loss: 54.17%\n",
            "Moving Avg Val Loss: 0.401770\n",
            "Epoch 1402/2000, Train Loss: 0.000448, Val Loss: 0.035355\n",
            "Epoch 1402/2000, Rel Train Loss: 39.04%, Rel Val Loss: 34.87%\n",
            "Moving Avg Val Loss: 0.408876\n",
            "Epoch 1403/2000, Train Loss: 0.000366, Val Loss: 0.038220\n",
            "Epoch 1403/2000, Rel Train Loss: 33.96%, Rel Val Loss: 41.65%\n",
            "Moving Avg Val Loss: 0.447504\n",
            "Epoch 1404/2000, Train Loss: 0.001005, Val Loss: 0.037302\n",
            "Epoch 1404/2000, Rel Train Loss: 43.95%, Rel Val Loss: 55.79%\n",
            "Moving Avg Val Loss: 0.465959\n",
            "Epoch 1405/2000, Train Loss: 0.000575, Val Loss: 0.040228\n",
            "Epoch 1405/2000, Rel Train Loss: 36.95%, Rel Val Loss: 46.49%\n",
            "Moving Avg Val Loss: 0.487981\n",
            "Epoch 1406/2000, Train Loss: 0.000917, Val Loss: 0.039713\n",
            "Epoch 1406/2000, Rel Train Loss: 49.78%, Rel Val Loss: 65.18%\n",
            "Moving Avg Val Loss: 0.518798\n",
            "Epoch 1407/2000, Train Loss: 0.002087, Val Loss: 0.036341\n",
            "Epoch 1407/2000, Rel Train Loss: 55.00%, Rel Val Loss: 50.28%\n",
            "Moving Avg Val Loss: 0.511291\n",
            "Epoch 1408/2000, Train Loss: 0.001966, Val Loss: 0.044690\n",
            "Epoch 1408/2000, Rel Train Loss: 84.80%, Rel Val Loss: 37.90%\n",
            "Moving Avg Val Loss: 0.530008\n",
            "Epoch 1409/2000, Train Loss: 0.003306, Val Loss: 0.035508\n",
            "Epoch 1409/2000, Rel Train Loss: 85.11%, Rel Val Loss: 65.15%\n",
            "Moving Avg Val Loss: 0.521596\n",
            "Epoch 1410/2000, Train Loss: 0.001960, Val Loss: 0.044135\n",
            "Epoch 1410/2000, Rel Train Loss: 51.11%, Rel Val Loss: 42.28%\n",
            "Moving Avg Val Loss: 0.551898\n",
            "Epoch 1411/2000, Train Loss: 0.001988, Val Loss: 0.042088\n",
            "Epoch 1411/2000, Rel Train Loss: 57.88%, Rel Val Loss: 80.33%\n",
            "Moving Avg Val Loss: 0.555962\n",
            "Epoch 1412/2000, Train Loss: 0.001585, Val Loss: 0.039200\n",
            "Epoch 1412/2000, Rel Train Loss: 53.84%, Rel Val Loss: 52.31%\n",
            "Moving Avg Val Loss: 0.555025\n",
            "Epoch 1413/2000, Train Loss: 0.001767, Val Loss: 0.034875\n",
            "Epoch 1413/2000, Rel Train Loss: 51.65%, Rel Val Loss: 37.43%\n",
            "Moving Avg Val Loss: 0.506944\n",
            "Epoch 1414/2000, Train Loss: 0.001002, Val Loss: 0.039352\n",
            "Epoch 1414/2000, Rel Train Loss: 40.42%, Rel Val Loss: 41.11%\n",
            "Moving Avg Val Loss: 0.499091\n",
            "Epoch 1415/2000, Train Loss: 0.000595, Val Loss: 0.033654\n",
            "Epoch 1415/2000, Rel Train Loss: 35.64%, Rel Val Loss: 38.36%\n",
            "Moving Avg Val Loss: 0.408801\n",
            "Epoch 1416/2000, Train Loss: 0.000383, Val Loss: 0.037485\n",
            "Epoch 1416/2000, Rel Train Loss: 30.72%, Rel Val Loss: 35.19%\n",
            "Moving Avg Val Loss: 0.390179\n",
            "Epoch 1417/2000, Train Loss: 0.000460, Val Loss: 0.035242\n",
            "Epoch 1417/2000, Rel Train Loss: 31.41%, Rel Val Loss: 43.00%\n",
            "Moving Avg Val Loss: 0.395160\n",
            "Epoch 1418/2000, Train Loss: 0.000412, Val Loss: 0.036560\n",
            "Epoch 1418/2000, Rel Train Loss: 33.89%, Rel Val Loss: 39.92%\n",
            "Moving Avg Val Loss: 0.421950\n",
            "Epoch 1419/2000, Train Loss: 0.000950, Val Loss: 0.036936\n",
            "Epoch 1419/2000, Rel Train Loss: 50.03%, Rel Val Loss: 54.51%\n",
            "Moving Avg Val Loss: 0.430003\n",
            "Epoch 1420/2000, Train Loss: 0.000507, Val Loss: 0.034005\n",
            "Epoch 1420/2000, Rel Train Loss: 48.97%, Rel Val Loss: 42.38%\n",
            "Moving Avg Val Loss: 0.448255\n",
            "Epoch 1421/2000, Train Loss: 0.000743, Val Loss: 0.037070\n",
            "Epoch 1421/2000, Rel Train Loss: 41.95%, Rel Val Loss: 44.31%\n",
            "Moving Avg Val Loss: 0.462958\n",
            "Epoch 1422/2000, Train Loss: 0.000802, Val Loss: 0.034046\n",
            "Epoch 1422/2000, Rel Train Loss: 34.68%, Rel Val Loss: 50.35%\n",
            "Moving Avg Val Loss: 0.477291\n",
            "Epoch 1423/2000, Train Loss: 0.000906, Val Loss: 0.042690\n",
            "Epoch 1423/2000, Rel Train Loss: 51.67%, Rel Val Loss: 47.09%\n",
            "Moving Avg Val Loss: 0.445237\n",
            "Epoch 1424/2000, Train Loss: 0.001268, Val Loss: 0.033854\n",
            "Epoch 1424/2000, Rel Train Loss: 52.57%, Rel Val Loss: 38.48%\n",
            "Moving Avg Val Loss: 0.439809\n",
            "Epoch 1425/2000, Train Loss: 0.000801, Val Loss: 0.034939\n",
            "Epoch 1425/2000, Rel Train Loss: 43.46%, Rel Val Loss: 39.67%\n",
            "Moving Avg Val Loss: 0.419987\n",
            "Epoch 1426/2000, Train Loss: 0.000676, Val Loss: 0.036888\n",
            "Epoch 1426/2000, Rel Train Loss: 39.98%, Rel Val Loss: 34.40%\n",
            "Moving Avg Val Loss: 0.394099\n",
            "Epoch 1427/2000, Train Loss: 0.000490, Val Loss: 0.037993\n",
            "Epoch 1427/2000, Rel Train Loss: 35.02%, Rel Val Loss: 37.41%\n",
            "Moving Avg Val Loss: 0.370094\n",
            "Epoch 1428/2000, Train Loss: 0.000322, Val Loss: 0.037194\n",
            "Epoch 1428/2000, Rel Train Loss: 30.55%, Rel Val Loss: 35.09%\n",
            "Moving Avg Val Loss: 0.369658\n",
            "Epoch 1429/2000, Train Loss: 0.000290, Val Loss: 0.037194\n",
            "Epoch 1429/2000, Rel Train Loss: 31.45%, Rel Val Loss: 38.26%\n",
            "Moving Avg Val Loss: 0.358468\n",
            "Epoch 1430/2000, Train Loss: 0.000434, Val Loss: 0.034368\n",
            "Epoch 1430/2000, Rel Train Loss: 32.90%, Rel Val Loss: 34.08%\n",
            "Moving Avg Val Loss: 0.364666\n",
            "Epoch 1431/2000, Train Loss: 0.000370, Val Loss: 0.036241\n",
            "Epoch 1431/2000, Rel Train Loss: 30.86%, Rel Val Loss: 37.50%\n",
            "Moving Avg Val Loss: 0.357120\n",
            "Epoch 1432/2000, Train Loss: 0.000322, Val Loss: 0.038127\n",
            "Epoch 1432/2000, Rel Train Loss: 34.08%, Rel Val Loss: 33.64%\n",
            "Moving Avg Val Loss: 0.361916\n",
            "Epoch 1433/2000, Train Loss: 0.000354, Val Loss: 0.036963\n",
            "Epoch 1433/2000, Rel Train Loss: 27.97%, Rel Val Loss: 37.48%\n",
            "Moving Avg Val Loss: 0.350115\n",
            "Epoch 1434/2000, Train Loss: 0.000286, Val Loss: 0.036262\n",
            "Epoch 1434/2000, Rel Train Loss: 29.43%, Rel Val Loss: 32.36%\n",
            "Moving Avg Val Loss: 0.354931\n",
            "Epoch 1435/2000, Train Loss: 0.000246, Val Loss: 0.038243\n",
            "Epoch 1435/2000, Rel Train Loss: 28.76%, Rel Val Loss: 36.48%\n",
            "Moving Avg Val Loss: 0.352375\n",
            "Epoch 1436/2000, Train Loss: 0.000361, Val Loss: 0.036886\n",
            "Epoch 1436/2000, Rel Train Loss: 29.97%, Rel Val Loss: 36.22%\n",
            "Moving Avg Val Loss: 0.364748\n",
            "Epoch 1437/2000, Train Loss: 0.000771, Val Loss: 0.045038\n",
            "Epoch 1437/2000, Rel Train Loss: 46.70%, Rel Val Loss: 39.82%\n",
            "Moving Avg Val Loss: 0.364568\n",
            "Epoch 1438/2000, Train Loss: 0.003321, Val Loss: 0.044170\n",
            "Epoch 1438/2000, Rel Train Loss: 72.53%, Rel Val Loss: 37.39%\n",
            "Moving Avg Val Loss: 0.491479\n",
            "Epoch 1439/2000, Train Loss: 0.002208, Val Loss: 0.038735\n",
            "Epoch 1439/2000, Rel Train Loss: 91.35%, Rel Val Loss: 95.82%\n",
            "Moving Avg Val Loss: 0.555311\n",
            "Epoch 1440/2000, Train Loss: 0.003987, Val Loss: 0.047081\n",
            "Epoch 1440/2000, Rel Train Loss: 81.01%, Rel Val Loss: 68.40%\n",
            "Moving Avg Val Loss: 0.647788\n",
            "Epoch 1441/2000, Train Loss: 0.002504, Val Loss: 0.034600\n",
            "Epoch 1441/2000, Rel Train Loss: 54.75%, Rel Val Loss: 82.46%\n",
            "Moving Avg Val Loss: 0.670865\n",
            "Epoch 1442/2000, Train Loss: 0.001744, Val Loss: 0.041114\n",
            "Epoch 1442/2000, Rel Train Loss: 57.56%, Rel Val Loss: 51.36%\n",
            "Moving Avg Val Loss: 0.868849\n",
            "Epoch 1443/2000, Train Loss: 0.006534, Val Loss: 0.036497\n",
            "Epoch 1443/2000, Rel Train Loss: 71.62%, Rel Val Loss: 136.38%\n",
            "Moving Avg Val Loss: 0.885570\n",
            "Epoch 1444/2000, Train Loss: 0.002423, Val Loss: 0.040785\n",
            "Epoch 1444/2000, Rel Train Loss: 116.47%, Rel Val Loss: 104.18%\n",
            "Moving Avg Val Loss: 0.889598\n",
            "Epoch 1445/2000, Train Loss: 0.001383, Val Loss: 0.040241\n",
            "Epoch 1445/2000, Rel Train Loss: 62.44%, Rel Val Loss: 70.41%\n",
            "Moving Avg Val Loss: 0.848419\n",
            "Epoch 1446/2000, Train Loss: 0.003666, Val Loss: 0.040605\n",
            "Epoch 1446/2000, Rel Train Loss: 62.09%, Rel Val Loss: 61.87%\n",
            "Moving Avg Val Loss: 0.829635\n",
            "Epoch 1447/2000, Train Loss: 0.002169, Val Loss: 0.031978\n",
            "Epoch 1447/2000, Rel Train Loss: 58.00%, Rel Val Loss: 41.97%\n",
            "Moving Avg Val Loss: 0.701346\n",
            "Epoch 1448/2000, Train Loss: 0.001773, Val Loss: 0.035900\n",
            "Epoch 1448/2000, Rel Train Loss: 72.73%, Rel Val Loss: 72.24%\n",
            "Moving Avg Val Loss: 0.581316\n",
            "Epoch 1449/2000, Train Loss: 0.001296, Val Loss: 0.033898\n",
            "Epoch 1449/2000, Rel Train Loss: 60.21%, Rel Val Loss: 44.16%\n",
            "Moving Avg Val Loss: 0.537375\n",
            "Epoch 1450/2000, Train Loss: 0.000833, Val Loss: 0.036402\n",
            "Epoch 1450/2000, Rel Train Loss: 37.75%, Rel Val Loss: 48.44%\n",
            "Moving Avg Val Loss: 0.494142\n",
            "Epoch 1451/2000, Train Loss: 0.000659, Val Loss: 0.031119\n",
            "Epoch 1451/2000, Rel Train Loss: 42.67%, Rel Val Loss: 40.26%\n",
            "Moving Avg Val Loss: 0.507833\n",
            "Epoch 1452/2000, Train Loss: 0.000668, Val Loss: 0.039159\n",
            "Epoch 1452/2000, Rel Train Loss: 46.60%, Rel Val Loss: 48.82%\n",
            "Moving Avg Val Loss: 0.434187\n",
            "Epoch 1453/2000, Train Loss: 0.000419, Val Loss: 0.033514\n",
            "Epoch 1453/2000, Rel Train Loss: 32.80%, Rel Val Loss: 35.42%\n",
            "Moving Avg Val Loss: 0.417127\n",
            "Epoch 1454/2000, Train Loss: 0.000342, Val Loss: 0.036016\n",
            "Epoch 1454/2000, Rel Train Loss: 31.73%, Rel Val Loss: 35.63%\n",
            "Moving Avg Val Loss: 0.389265\n",
            "Epoch 1455/2000, Train Loss: 0.000357, Val Loss: 0.034932\n",
            "Epoch 1455/2000, Rel Train Loss: 29.27%, Rel Val Loss: 34.51%\n",
            "Moving Avg Val Loss: 0.395383\n",
            "Epoch 1456/2000, Train Loss: 0.000421, Val Loss: 0.035533\n",
            "Epoch 1456/2000, Rel Train Loss: 35.56%, Rel Val Loss: 43.32%\n",
            "Moving Avg Val Loss: 0.362471\n",
            "Epoch 1457/2000, Train Loss: 0.000374, Val Loss: 0.035409\n",
            "Epoch 1457/2000, Rel Train Loss: 32.48%, Rel Val Loss: 32.36%\n",
            "Moving Avg Val Loss: 0.359100\n",
            "Epoch 1458/2000, Train Loss: 0.000354, Val Loss: 0.035660\n",
            "Epoch 1458/2000, Rel Train Loss: 31.13%, Rel Val Loss: 33.73%\n",
            "Moving Avg Val Loss: 0.357316\n",
            "Epoch 1459/2000, Train Loss: 0.000251, Val Loss: 0.035560\n",
            "Epoch 1459/2000, Rel Train Loss: 28.31%, Rel Val Loss: 34.74%\n",
            "Moving Avg Val Loss: 0.355339\n",
            "Epoch 1460/2000, Train Loss: 0.000237, Val Loss: 0.035405\n",
            "Epoch 1460/2000, Rel Train Loss: 28.34%, Rel Val Loss: 33.52%\n",
            "Moving Avg Val Loss: 0.333859\n",
            "Epoch 1461/2000, Train Loss: 0.000271, Val Loss: 0.034874\n",
            "Epoch 1461/2000, Rel Train Loss: 29.32%, Rel Val Loss: 32.58%\n",
            "Moving Avg Val Loss: 0.334769\n",
            "Epoch 1462/2000, Train Loss: 0.000269, Val Loss: 0.036957\n",
            "Epoch 1462/2000, Rel Train Loss: 30.39%, Rel Val Loss: 32.81%\n",
            "Moving Avg Val Loss: 0.349156\n",
            "Epoch 1463/2000, Train Loss: 0.000331, Val Loss: 0.036556\n",
            "Epoch 1463/2000, Rel Train Loss: 30.46%, Rel Val Loss: 40.92%\n",
            "Moving Avg Val Loss: 0.355823\n",
            "Epoch 1464/2000, Train Loss: 0.000276, Val Loss: 0.035334\n",
            "Epoch 1464/2000, Rel Train Loss: 31.72%, Rel Val Loss: 38.07%\n",
            "Moving Avg Val Loss: 0.356771\n",
            "Epoch 1465/2000, Train Loss: 0.000274, Val Loss: 0.035215\n",
            "Epoch 1465/2000, Rel Train Loss: 30.33%, Rel Val Loss: 34.00%\n",
            "Moving Avg Val Loss: 0.364648\n",
            "Epoch 1466/2000, Train Loss: 0.000334, Val Loss: 0.037266\n",
            "Epoch 1466/2000, Rel Train Loss: 29.13%, Rel Val Loss: 36.51%\n",
            "Moving Avg Val Loss: 0.366420\n",
            "Epoch 1467/2000, Train Loss: 0.000339, Val Loss: 0.033453\n",
            "Epoch 1467/2000, Rel Train Loss: 32.68%, Rel Val Loss: 33.70%\n",
            "Moving Avg Val Loss: 0.352911\n",
            "Epoch 1468/2000, Train Loss: 0.000255, Val Loss: 0.035744\n",
            "Epoch 1468/2000, Rel Train Loss: 28.63%, Rel Val Loss: 34.17%\n",
            "Moving Avg Val Loss: 0.348439\n",
            "Epoch 1469/2000, Train Loss: 0.000271, Val Loss: 0.035864\n",
            "Epoch 1469/2000, Rel Train Loss: 30.01%, Rel Val Loss: 35.84%\n",
            "Moving Avg Val Loss: 0.347846\n",
            "Epoch 1470/2000, Train Loss: 0.000242, Val Loss: 0.034666\n",
            "Epoch 1470/2000, Rel Train Loss: 30.64%, Rel Val Loss: 33.70%\n",
            "Moving Avg Val Loss: 0.345660\n",
            "Epoch 1471/2000, Train Loss: 0.000230, Val Loss: 0.036058\n",
            "Epoch 1471/2000, Rel Train Loss: 29.68%, Rel Val Loss: 35.42%\n",
            "Moving Avg Val Loss: 0.344166\n",
            "Epoch 1472/2000, Train Loss: 0.000211, Val Loss: 0.035230\n",
            "Epoch 1472/2000, Rel Train Loss: 28.15%, Rel Val Loss: 32.95%\n",
            "Moving Avg Val Loss: 0.340871\n",
            "Epoch 1473/2000, Train Loss: 0.000215, Val Loss: 0.035749\n",
            "Epoch 1473/2000, Rel Train Loss: 28.69%, Rel Val Loss: 32.52%\n",
            "Moving Avg Val Loss: 0.339675\n",
            "Epoch 1474/2000, Train Loss: 0.000210, Val Loss: 0.035530\n",
            "Epoch 1474/2000, Rel Train Loss: 28.74%, Rel Val Loss: 35.24%\n",
            "Moving Avg Val Loss: 0.336414\n",
            "Epoch 1475/2000, Train Loss: 0.000215, Val Loss: 0.035418\n",
            "Epoch 1475/2000, Rel Train Loss: 27.84%, Rel Val Loss: 32.07%\n",
            "Moving Avg Val Loss: 0.332787\n",
            "Epoch 1476/2000, Train Loss: 0.000258, Val Loss: 0.035401\n",
            "Epoch 1476/2000, Rel Train Loss: 27.78%, Rel Val Loss: 33.61%\n",
            "Moving Avg Val Loss: 0.332480\n",
            "Epoch 1477/2000, Train Loss: 0.000271, Val Loss: 0.035770\n",
            "Epoch 1477/2000, Rel Train Loss: 28.62%, Rel Val Loss: 32.80%\n",
            "Moving Avg Val Loss: 0.345538\n",
            "Epoch 1478/2000, Train Loss: 0.000230, Val Loss: 0.034147\n",
            "Epoch 1478/2000, Rel Train Loss: 30.24%, Rel Val Loss: 39.05%\n",
            "Moving Avg Val Loss: 0.341710\n",
            "Epoch 1479/2000, Train Loss: 0.000295, Val Loss: 0.036314\n",
            "Epoch 1479/2000, Rel Train Loss: 30.63%, Rel Val Loss: 33.33%\n",
            "Moving Avg Val Loss: 0.358361\n",
            "Epoch 1480/2000, Train Loss: 0.000312, Val Loss: 0.037792\n",
            "Epoch 1480/2000, Rel Train Loss: 33.81%, Rel Val Loss: 40.40%\n",
            "Moving Avg Val Loss: 0.355625\n",
            "Epoch 1481/2000, Train Loss: 0.000266, Val Loss: 0.034523\n",
            "Epoch 1481/2000, Rel Train Loss: 32.90%, Rel Val Loss: 32.24%\n",
            "Moving Avg Val Loss: 0.354295\n",
            "Epoch 1482/2000, Train Loss: 0.000222, Val Loss: 0.035715\n",
            "Epoch 1482/2000, Rel Train Loss: 28.96%, Rel Val Loss: 32.13%\n",
            "Moving Avg Val Loss: 0.351377\n",
            "Epoch 1483/2000, Train Loss: 0.000322, Val Loss: 0.035540\n",
            "Epoch 1483/2000, Rel Train Loss: 28.93%, Rel Val Loss: 37.59%\n",
            "Moving Avg Val Loss: 0.352099\n",
            "Epoch 1484/2000, Train Loss: 0.000418, Val Loss: 0.037218\n",
            "Epoch 1484/2000, Rel Train Loss: 38.05%, Rel Val Loss: 33.69%\n",
            "Moving Avg Val Loss: 0.337945\n",
            "Epoch 1485/2000, Train Loss: 0.000355, Val Loss: 0.036685\n",
            "Epoch 1485/2000, Rel Train Loss: 29.10%, Rel Val Loss: 33.32%\n",
            "Moving Avg Val Loss: 0.352431\n",
            "Epoch 1486/2000, Train Loss: 0.000680, Val Loss: 0.033692\n",
            "Epoch 1486/2000, Rel Train Loss: 32.77%, Rel Val Loss: 39.48%\n",
            "Moving Avg Val Loss: 0.394283\n",
            "Epoch 1487/2000, Train Loss: 0.000941, Val Loss: 0.042389\n",
            "Epoch 1487/2000, Rel Train Loss: 44.58%, Rel Val Loss: 53.06%\n",
            "Moving Avg Val Loss: 0.447378\n",
            "Epoch 1488/2000, Train Loss: 0.002865, Val Loss: 0.054400\n",
            "Epoch 1488/2000, Rel Train Loss: 63.51%, Rel Val Loss: 64.14%\n",
            "Moving Avg Val Loss: 0.578734\n",
            "Epoch 1489/2000, Train Loss: 0.004081, Val Loss: 0.032010\n",
            "Epoch 1489/2000, Rel Train Loss: 87.12%, Rel Val Loss: 99.37%\n",
            "Moving Avg Val Loss: 0.598600\n",
            "Epoch 1490/2000, Train Loss: 0.001188, Val Loss: 0.035693\n",
            "Epoch 1490/2000, Rel Train Loss: 58.08%, Rel Val Loss: 43.25%\n",
            "Moving Avg Val Loss: 0.616077\n",
            "Epoch 1491/2000, Train Loss: 0.001158, Val Loss: 0.034305\n",
            "Epoch 1491/2000, Rel Train Loss: 46.48%, Rel Val Loss: 48.22%\n",
            "Moving Avg Val Loss: 0.636180\n",
            "Epoch 1492/2000, Train Loss: 0.002422, Val Loss: 0.032404\n",
            "Epoch 1492/2000, Rel Train Loss: 71.45%, Rel Val Loss: 63.11%\n",
            "Moving Avg Val Loss: 0.625940\n",
            "Epoch 1493/2000, Train Loss: 0.001541, Val Loss: 0.037221\n",
            "Epoch 1493/2000, Rel Train Loss: 60.72%, Rel Val Loss: 59.02%\n",
            "Moving Avg Val Loss: 0.517721\n",
            "Epoch 1494/2000, Train Loss: 0.001645, Val Loss: 0.037792\n",
            "Epoch 1494/2000, Rel Train Loss: 46.45%, Rel Val Loss: 45.26%\n",
            "Moving Avg Val Loss: 0.569875\n",
            "Epoch 1495/2000, Train Loss: 0.001884, Val Loss: 0.035427\n",
            "Epoch 1495/2000, Rel Train Loss: 43.30%, Rel Val Loss: 69.33%\n",
            "Moving Avg Val Loss: 0.563323\n",
            "Epoch 1496/2000, Train Loss: 0.000837, Val Loss: 0.034766\n",
            "Epoch 1496/2000, Rel Train Loss: 58.73%, Rel Val Loss: 44.95%\n",
            "Moving Avg Val Loss: 0.581544\n",
            "Epoch 1497/2000, Train Loss: 0.002119, Val Loss: 0.043962\n",
            "Epoch 1497/2000, Rel Train Loss: 51.22%, Rel Val Loss: 72.22%\n",
            "Moving Avg Val Loss: 0.699199\n",
            "Epoch 1498/2000, Train Loss: 0.002320, Val Loss: 0.032488\n",
            "Epoch 1498/2000, Rel Train Loss: 60.06%, Rel Val Loss: 117.85%\n",
            "Moving Avg Val Loss: 0.731669\n",
            "Epoch 1499/2000, Train Loss: 0.001821, Val Loss: 0.055283\n",
            "Epoch 1499/2000, Rel Train Loss: 81.38%, Rel Val Loss: 61.49%\n",
            "Moving Avg Val Loss: 0.754961\n",
            "Epoch 1500/2000, Train Loss: 0.003550, Val Loss: 0.033749\n",
            "Epoch 1500/2000, Rel Train Loss: 71.61%, Rel Val Loss: 80.97%\n",
            "Moving Avg Val Loss: 0.779576\n",
            "Epoch 1501/2000, Train Loss: 0.003936, Val Loss: 0.046315\n",
            "Epoch 1501/2000, Rel Train Loss: 75.76%, Rel Val Loss: 57.25%\n",
            "Moving Avg Val Loss: 0.768259\n",
            "Epoch 1502/2000, Train Loss: 0.002769, Val Loss: 0.035920\n",
            "Epoch 1502/2000, Rel Train Loss: 60.38%, Rel Val Loss: 66.56%\n",
            "Moving Avg Val Loss: 0.672362\n",
            "Epoch 1503/2000, Train Loss: 0.001811, Val Loss: 0.048767\n",
            "Epoch 1503/2000, Rel Train Loss: 59.22%, Rel Val Loss: 69.90%\n",
            "Moving Avg Val Loss: 0.654801\n",
            "Epoch 1504/2000, Train Loss: 0.001554, Val Loss: 0.029855\n",
            "Epoch 1504/2000, Rel Train Loss: 50.52%, Rel Val Loss: 52.71%\n",
            "Moving Avg Val Loss: 0.561535\n",
            "Epoch 1505/2000, Train Loss: 0.000806, Val Loss: 0.029534\n",
            "Epoch 1505/2000, Rel Train Loss: 38.71%, Rel Val Loss: 34.34%\n",
            "Moving Avg Val Loss: 0.545788\n",
            "Epoch 1506/2000, Train Loss: 0.000803, Val Loss: 0.034370\n",
            "Epoch 1506/2000, Rel Train Loss: 38.10%, Rel Val Loss: 49.38%\n",
            "Moving Avg Val Loss: 0.513490\n",
            "Epoch 1507/2000, Train Loss: 0.002661, Val Loss: 0.042412\n",
            "Epoch 1507/2000, Rel Train Loss: 50.51%, Rel Val Loss: 50.41%\n",
            "Moving Avg Val Loss: 0.562083\n",
            "Epoch 1508/2000, Train Loss: 0.004222, Val Loss: 0.032549\n",
            "Epoch 1508/2000, Rel Train Loss: 79.09%, Rel Val Loss: 94.20%\n",
            "Moving Avg Val Loss: 0.531359\n",
            "Epoch 1509/2000, Train Loss: 0.001951, Val Loss: 0.030767\n",
            "Epoch 1509/2000, Rel Train Loss: 63.60%, Rel Val Loss: 37.35%\n",
            "Moving Avg Val Loss: 0.542430\n",
            "Epoch 1510/2000, Train Loss: 0.000815, Val Loss: 0.034605\n",
            "Epoch 1510/2000, Rel Train Loss: 48.02%, Rel Val Loss: 39.88%\n",
            "Moving Avg Val Loss: 0.541962\n",
            "Epoch 1511/2000, Train Loss: 0.000608, Val Loss: 0.028234\n",
            "Epoch 1511/2000, Rel Train Loss: 38.44%, Rel Val Loss: 49.15%\n",
            "Moving Avg Val Loss: 0.522793\n",
            "Epoch 1512/2000, Train Loss: 0.000877, Val Loss: 0.033929\n",
            "Epoch 1512/2000, Rel Train Loss: 38.18%, Rel Val Loss: 40.83%\n",
            "Moving Avg Val Loss: 0.508302\n",
            "Epoch 1513/2000, Train Loss: 0.003965, Val Loss: 0.037029\n",
            "Epoch 1513/2000, Rel Train Loss: 69.75%, Rel Val Loss: 86.95%\n",
            "Moving Avg Val Loss: 0.544540\n",
            "Epoch 1514/2000, Train Loss: 0.004445, Val Loss: 0.034223\n",
            "Epoch 1514/2000, Rel Train Loss: 109.70%, Rel Val Loss: 55.47%\n",
            "Moving Avg Val Loss: 0.578559\n",
            "Epoch 1515/2000, Train Loss: 0.002419, Val Loss: 0.034211\n",
            "Epoch 1515/2000, Rel Train Loss: 93.00%, Rel Val Loss: 56.89%\n",
            "Moving Avg Val Loss: 0.562758\n",
            "Epoch 1516/2000, Train Loss: 0.001388, Val Loss: 0.040076\n",
            "Epoch 1516/2000, Rel Train Loss: 42.74%, Rel Val Loss: 41.25%\n",
            "Moving Avg Val Loss: 0.596743\n",
            "Epoch 1517/2000, Train Loss: 0.002404, Val Loss: 0.033975\n",
            "Epoch 1517/2000, Rel Train Loss: 51.26%, Rel Val Loss: 57.82%\n",
            "Moving Avg Val Loss: 0.607086\n",
            "Epoch 1518/2000, Train Loss: 0.001613, Val Loss: 0.032928\n",
            "Epoch 1518/2000, Rel Train Loss: 66.42%, Rel Val Loss: 92.12%\n",
            "Moving Avg Val Loss: 0.588213\n",
            "Epoch 1519/2000, Train Loss: 0.000951, Val Loss: 0.035027\n",
            "Epoch 1519/2000, Rel Train Loss: 66.72%, Rel Val Loss: 46.03%\n",
            "Moving Avg Val Loss: 0.581332\n",
            "Epoch 1520/2000, Train Loss: 0.000540, Val Loss: 0.033342\n",
            "Epoch 1520/2000, Rel Train Loss: 41.83%, Rel Val Loss: 53.45%\n",
            "Moving Avg Val Loss: 0.588405\n",
            "Epoch 1521/2000, Train Loss: 0.000470, Val Loss: 0.035605\n",
            "Epoch 1521/2000, Rel Train Loss: 38.23%, Rel Val Loss: 44.78%\n",
            "Moving Avg Val Loss: 0.540168\n",
            "Epoch 1522/2000, Train Loss: 0.000389, Val Loss: 0.033257\n",
            "Epoch 1522/2000, Rel Train Loss: 38.14%, Rel Val Loss: 33.70%\n",
            "Moving Avg Val Loss: 0.458251\n",
            "Epoch 1523/2000, Train Loss: 0.000469, Val Loss: 0.036080\n",
            "Epoch 1523/2000, Rel Train Loss: 34.80%, Rel Val Loss: 51.16%\n",
            "Moving Avg Val Loss: 0.464102\n",
            "Epoch 1524/2000, Train Loss: 0.001810, Val Loss: 0.032570\n",
            "Epoch 1524/2000, Rel Train Loss: 53.31%, Rel Val Loss: 48.96%\n",
            "Moving Avg Val Loss: 0.553332\n",
            "Epoch 1525/2000, Train Loss: 0.001508, Val Loss: 0.036489\n",
            "Epoch 1525/2000, Rel Train Loss: 50.16%, Rel Val Loss: 98.06%\n",
            "Moving Avg Val Loss: 0.541147\n",
            "Epoch 1526/2000, Train Loss: 0.000751, Val Loss: 0.033374\n",
            "Epoch 1526/2000, Rel Train Loss: 60.68%, Rel Val Loss: 38.69%\n",
            "Moving Avg Val Loss: 0.553787\n",
            "Epoch 1527/2000, Train Loss: 0.000488, Val Loss: 0.033318\n",
            "Epoch 1527/2000, Rel Train Loss: 44.56%, Rel Val Loss: 40.02%\n",
            "Moving Avg Val Loss: 0.537092\n",
            "Epoch 1528/2000, Train Loss: 0.000733, Val Loss: 0.039948\n",
            "Epoch 1528/2000, Rel Train Loss: 34.36%, Rel Val Loss: 42.82%\n",
            "Moving Avg Val Loss: 0.561121\n",
            "Epoch 1529/2000, Train Loss: 0.001199, Val Loss: 0.035109\n",
            "Epoch 1529/2000, Rel Train Loss: 48.20%, Rel Val Loss: 60.97%\n",
            "Moving Avg Val Loss: 0.513785\n",
            "Epoch 1530/2000, Train Loss: 0.000898, Val Loss: 0.036074\n",
            "Epoch 1530/2000, Rel Train Loss: 53.12%, Rel Val Loss: 74.39%\n",
            "Moving Avg Val Loss: 0.507765\n",
            "Epoch 1531/2000, Train Loss: 0.000804, Val Loss: 0.030958\n",
            "Epoch 1531/2000, Rel Train Loss: 45.62%, Rel Val Loss: 35.68%\n",
            "Moving Avg Val Loss: 0.518029\n",
            "Epoch 1532/2000, Train Loss: 0.000726, Val Loss: 0.036497\n",
            "Epoch 1532/2000, Rel Train Loss: 32.70%, Rel Val Loss: 45.16%\n",
            "Moving Avg Val Loss: 0.497438\n",
            "Epoch 1533/2000, Train Loss: 0.000435, Val Loss: 0.032583\n",
            "Epoch 1533/2000, Rel Train Loss: 36.55%, Rel Val Loss: 32.52%\n",
            "Moving Avg Val Loss: 0.441889\n",
            "Epoch 1534/2000, Train Loss: 0.000374, Val Loss: 0.032298\n",
            "Epoch 1534/2000, Rel Train Loss: 27.69%, Rel Val Loss: 33.20%\n",
            "Moving Avg Val Loss: 0.359464\n",
            "Epoch 1535/2000, Train Loss: 0.000361, Val Loss: 0.032500\n",
            "Epoch 1535/2000, Rel Train Loss: 31.16%, Rel Val Loss: 33.18%\n",
            "Moving Avg Val Loss: 0.356387\n",
            "Epoch 1536/2000, Train Loss: 0.000346, Val Loss: 0.033239\n",
            "Epoch 1536/2000, Rel Train Loss: 39.62%, Rel Val Loss: 34.14%\n",
            "Moving Avg Val Loss: 0.376111\n",
            "Epoch 1537/2000, Train Loss: 0.000555, Val Loss: 0.034654\n",
            "Epoch 1537/2000, Rel Train Loss: 40.34%, Rel Val Loss: 55.02%\n",
            "Moving Avg Val Loss: 0.378264\n",
            "Epoch 1538/2000, Train Loss: 0.000547, Val Loss: 0.032501\n",
            "Epoch 1538/2000, Rel Train Loss: 34.35%, Rel Val Loss: 33.60%\n",
            "Moving Avg Val Loss: 0.377414\n",
            "Epoch 1539/2000, Train Loss: 0.000625, Val Loss: 0.035438\n",
            "Epoch 1539/2000, Rel Train Loss: 31.50%, Rel Val Loss: 32.77%\n",
            "Moving Avg Val Loss: 0.387260\n",
            "Epoch 1540/2000, Train Loss: 0.000638, Val Loss: 0.033847\n",
            "Epoch 1540/2000, Rel Train Loss: 39.40%, Rel Val Loss: 38.10%\n",
            "Moving Avg Val Loss: 0.471214\n",
            "Epoch 1541/2000, Train Loss: 0.002330, Val Loss: 0.038692\n",
            "Epoch 1541/2000, Rel Train Loss: 46.13%, Rel Val Loss: 76.12%\n",
            "Moving Avg Val Loss: 0.501861\n",
            "Epoch 1542/2000, Train Loss: 0.001329, Val Loss: 0.037025\n",
            "Epoch 1542/2000, Rel Train Loss: 75.18%, Rel Val Loss: 70.34%\n",
            "Moving Avg Val Loss: 0.576405\n",
            "Epoch 1543/2000, Train Loss: 0.001570, Val Loss: 0.033499\n",
            "Epoch 1543/2000, Rel Train Loss: 77.74%, Rel Val Loss: 70.87%\n",
            "Moving Avg Val Loss: 0.621361\n",
            "Epoch 1544/2000, Train Loss: 0.000775, Val Loss: 0.031695\n",
            "Epoch 1544/2000, Rel Train Loss: 62.28%, Rel Val Loss: 55.25%\n",
            "Moving Avg Val Loss: 0.692697\n",
            "Epoch 1545/2000, Train Loss: 0.001133, Val Loss: 0.038645\n",
            "Epoch 1545/2000, Rel Train Loss: 46.83%, Rel Val Loss: 73.77%\n",
            "Moving Avg Val Loss: 0.607118\n",
            "Epoch 1546/2000, Train Loss: 0.000913, Val Loss: 0.032569\n",
            "Epoch 1546/2000, Rel Train Loss: 48.46%, Rel Val Loss: 33.33%\n",
            "Moving Avg Val Loss: 0.531905\n",
            "Epoch 1547/2000, Train Loss: 0.000766, Val Loss: 0.034862\n",
            "Epoch 1547/2000, Rel Train Loss: 44.86%, Rel Val Loss: 32.73%\n",
            "Moving Avg Val Loss: 0.459151\n",
            "Epoch 1548/2000, Train Loss: 0.000928, Val Loss: 0.036140\n",
            "Epoch 1548/2000, Rel Train Loss: 37.16%, Rel Val Loss: 34.49%\n",
            "Moving Avg Val Loss: 0.452592\n",
            "Epoch 1549/2000, Train Loss: 0.000944, Val Loss: 0.030267\n",
            "Epoch 1549/2000, Rel Train Loss: 43.43%, Rel Val Loss: 51.97%\n",
            "Moving Avg Val Loss: 0.380861\n",
            "Epoch 1550/2000, Train Loss: 0.001536, Val Loss: 0.036710\n",
            "Epoch 1550/2000, Rel Train Loss: 53.37%, Rel Val Loss: 37.91%\n",
            "Moving Avg Val Loss: 0.387326\n",
            "Epoch 1551/2000, Train Loss: 0.000631, Val Loss: 0.030350\n",
            "Epoch 1551/2000, Rel Train Loss: 41.06%, Rel Val Loss: 36.56%\n",
            "Moving Avg Val Loss: 0.439764\n",
            "Epoch 1552/2000, Train Loss: 0.000575, Val Loss: 0.041696\n",
            "Epoch 1552/2000, Rel Train Loss: 44.38%, Rel Val Loss: 58.95%\n",
            "Moving Avg Val Loss: 0.455463\n",
            "Epoch 1553/2000, Train Loss: 0.000420, Val Loss: 0.034253\n",
            "Epoch 1553/2000, Rel Train Loss: 37.08%, Rel Val Loss: 42.34%\n",
            "Moving Avg Val Loss: 0.442244\n",
            "Epoch 1554/2000, Train Loss: 0.000636, Val Loss: 0.036517\n",
            "Epoch 1554/2000, Rel Train Loss: 37.37%, Rel Val Loss: 45.36%\n",
            "Moving Avg Val Loss: 0.486348\n",
            "Epoch 1555/2000, Train Loss: 0.000922, Val Loss: 0.041089\n",
            "Epoch 1555/2000, Rel Train Loss: 55.25%, Rel Val Loss: 59.96%\n",
            "Moving Avg Val Loss: 0.492282\n",
            "Epoch 1556/2000, Train Loss: 0.000809, Val Loss: 0.031882\n",
            "Epoch 1556/2000, Rel Train Loss: 50.85%, Rel Val Loss: 39.53%\n",
            "Moving Avg Val Loss: 0.447109\n",
            "Epoch 1557/2000, Train Loss: 0.000935, Val Loss: 0.039363\n",
            "Epoch 1557/2000, Rel Train Loss: 37.93%, Rel Val Loss: 36.37%\n",
            "Moving Avg Val Loss: 0.428038\n",
            "Epoch 1558/2000, Train Loss: 0.000851, Val Loss: 0.035629\n",
            "Epoch 1558/2000, Rel Train Loss: 40.11%, Rel Val Loss: 32.81%\n",
            "Moving Avg Val Loss: 0.516410\n",
            "Epoch 1559/2000, Train Loss: 0.002102, Val Loss: 0.041755\n",
            "Epoch 1559/2000, Rel Train Loss: 61.53%, Rel Val Loss: 89.55%\n",
            "Moving Avg Val Loss: 0.613350\n",
            "Epoch 1560/2000, Train Loss: 0.001695, Val Loss: 0.030311\n",
            "Epoch 1560/2000, Rel Train Loss: 80.67%, Rel Val Loss: 108.43%\n",
            "Moving Avg Val Loss: 0.624725\n",
            "Epoch 1561/2000, Train Loss: 0.002070, Val Loss: 0.041183\n",
            "Epoch 1561/2000, Rel Train Loss: 82.49%, Rel Val Loss: 45.22%\n",
            "Moving Avg Val Loss: 0.670501\n",
            "Epoch 1562/2000, Train Loss: 0.002042, Val Loss: 0.033330\n",
            "Epoch 1562/2000, Rel Train Loss: 56.60%, Rel Val Loss: 59.25%\n",
            "Moving Avg Val Loss: 0.717261\n",
            "Epoch 1563/2000, Train Loss: 0.001692, Val Loss: 0.043022\n",
            "Epoch 1563/2000, Rel Train Loss: 45.80%, Rel Val Loss: 56.19%\n",
            "Moving Avg Val Loss: 0.640978\n",
            "Epoch 1564/2000, Train Loss: 0.000949, Val Loss: 0.030386\n",
            "Epoch 1564/2000, Rel Train Loss: 37.65%, Rel Val Loss: 51.40%\n",
            "Moving Avg Val Loss: 0.520939\n",
            "Epoch 1565/2000, Train Loss: 0.000836, Val Loss: 0.040332\n",
            "Epoch 1565/2000, Rel Train Loss: 42.75%, Rel Val Loss: 48.41%\n",
            "Moving Avg Val Loss: 0.508017\n",
            "Epoch 1566/2000, Train Loss: 0.000651, Val Loss: 0.032510\n",
            "Epoch 1566/2000, Rel Train Loss: 39.71%, Rel Val Loss: 38.75%\n",
            "Moving Avg Val Loss: 0.522263\n",
            "Epoch 1567/2000, Train Loss: 0.001087, Val Loss: 0.040184\n",
            "Epoch 1567/2000, Rel Train Loss: 45.51%, Rel Val Loss: 66.38%\n",
            "Moving Avg Val Loss: 0.509840\n",
            "Epoch 1568/2000, Train Loss: 0.000702, Val Loss: 0.035588\n",
            "Epoch 1568/2000, Rel Train Loss: 48.06%, Rel Val Loss: 49.97%\n",
            "Moving Avg Val Loss: 0.503612\n",
            "Epoch 1569/2000, Train Loss: 0.001117, Val Loss: 0.035904\n",
            "Epoch 1569/2000, Rel Train Loss: 51.98%, Rel Val Loss: 48.29%\n",
            "Moving Avg Val Loss: 0.473006\n",
            "Epoch 1570/2000, Train Loss: 0.000570, Val Loss: 0.034604\n",
            "Epoch 1570/2000, Rel Train Loss: 39.82%, Rel Val Loss: 33.11%\n",
            "Moving Avg Val Loss: 0.467193\n",
            "Epoch 1571/2000, Train Loss: 0.000461, Val Loss: 0.036279\n",
            "Epoch 1571/2000, Rel Train Loss: 35.11%, Rel Val Loss: 35.85%\n",
            "Moving Avg Val Loss: 0.404932\n",
            "Epoch 1572/2000, Train Loss: 0.000403, Val Loss: 0.032201\n",
            "Epoch 1572/2000, Rel Train Loss: 36.12%, Rel Val Loss: 35.25%\n",
            "Moving Avg Val Loss: 0.369696\n",
            "Epoch 1573/2000, Train Loss: 0.000323, Val Loss: 0.034595\n",
            "Epoch 1573/2000, Rel Train Loss: 37.76%, Rel Val Loss: 32.36%\n",
            "Moving Avg Val Loss: 0.354057\n",
            "Epoch 1574/2000, Train Loss: 0.000314, Val Loss: 0.032626\n",
            "Epoch 1574/2000, Rel Train Loss: 35.24%, Rel Val Loss: 40.47%\n",
            "Moving Avg Val Loss: 0.351494\n",
            "Epoch 1575/2000, Train Loss: 0.000280, Val Loss: 0.033077\n",
            "Epoch 1575/2000, Rel Train Loss: 31.86%, Rel Val Loss: 31.82%\n",
            "Moving Avg Val Loss: 0.364455\n",
            "Epoch 1576/2000, Train Loss: 0.000354, Val Loss: 0.034867\n",
            "Epoch 1576/2000, Rel Train Loss: 31.29%, Rel Val Loss: 42.33%\n",
            "Moving Avg Val Loss: 0.383401\n",
            "Epoch 1577/2000, Train Loss: 0.000509, Val Loss: 0.032479\n",
            "Epoch 1577/2000, Rel Train Loss: 31.30%, Rel Val Loss: 44.72%\n",
            "Moving Avg Val Loss: 0.385962\n",
            "Epoch 1578/2000, Train Loss: 0.000356, Val Loss: 0.035200\n",
            "Epoch 1578/2000, Rel Train Loss: 28.87%, Rel Val Loss: 33.64%\n",
            "Moving Avg Val Loss: 0.369038\n",
            "Epoch 1579/2000, Train Loss: 0.000254, Val Loss: 0.032486\n",
            "Epoch 1579/2000, Rel Train Loss: 29.03%, Rel Val Loss: 32.01%\n",
            "Moving Avg Val Loss: 0.372912\n",
            "Epoch 1580/2000, Train Loss: 0.000244, Val Loss: 0.033151\n",
            "Epoch 1580/2000, Rel Train Loss: 27.71%, Rel Val Loss: 33.76%\n",
            "Moving Avg Val Loss: 0.360324\n",
            "Epoch 1581/2000, Train Loss: 0.000228, Val Loss: 0.034339\n",
            "Epoch 1581/2000, Rel Train Loss: 27.41%, Rel Val Loss: 36.03%\n",
            "Moving Avg Val Loss: 0.331535\n",
            "Epoch 1582/2000, Train Loss: 0.000240, Val Loss: 0.033618\n",
            "Epoch 1582/2000, Rel Train Loss: 30.59%, Rel Val Loss: 30.33%\n",
            "Moving Avg Val Loss: 0.370458\n",
            "Epoch 1583/2000, Train Loss: 0.000626, Val Loss: 0.034149\n",
            "Epoch 1583/2000, Rel Train Loss: 38.54%, Rel Val Loss: 53.10%\n",
            "Moving Avg Val Loss: 0.409504\n",
            "Epoch 1584/2000, Train Loss: 0.000908, Val Loss: 0.034048\n",
            "Epoch 1584/2000, Rel Train Loss: 48.09%, Rel Val Loss: 51.53%\n",
            "Moving Avg Val Loss: 0.477717\n",
            "Epoch 1585/2000, Train Loss: 0.001041, Val Loss: 0.034728\n",
            "Epoch 1585/2000, Rel Train Loss: 47.29%, Rel Val Loss: 67.87%\n",
            "Moving Avg Val Loss: 0.484982\n",
            "Epoch 1586/2000, Train Loss: 0.000822, Val Loss: 0.039102\n",
            "Epoch 1586/2000, Rel Train Loss: 37.11%, Rel Val Loss: 39.67%\n",
            "Moving Avg Val Loss: 0.550633\n",
            "Epoch 1587/2000, Train Loss: 0.001177, Val Loss: 0.029484\n",
            "Epoch 1587/2000, Rel Train Loss: 37.04%, Rel Val Loss: 63.15%\n",
            "Moving Avg Val Loss: 0.533293\n",
            "Epoch 1588/2000, Train Loss: 0.000875, Val Loss: 0.040203\n",
            "Epoch 1588/2000, Rel Train Loss: 44.25%, Rel Val Loss: 44.43%\n",
            "Moving Avg Val Loss: 0.587960\n",
            "Epoch 1589/2000, Train Loss: 0.003611, Val Loss: 0.036912\n",
            "Epoch 1589/2000, Rel Train Loss: 57.71%, Rel Val Loss: 78.87%\n",
            "Moving Avg Val Loss: 0.536304\n",
            "Epoch 1590/2000, Train Loss: 0.003025, Val Loss: 0.046206\n",
            "Epoch 1590/2000, Rel Train Loss: 78.51%, Rel Val Loss: 42.04%\n",
            "Moving Avg Val Loss: 0.618940\n",
            "Epoch 1591/2000, Train Loss: 0.003894, Val Loss: 0.034232\n",
            "Epoch 1591/2000, Rel Train Loss: 81.13%, Rel Val Loss: 80.99%\n",
            "Moving Avg Val Loss: 0.812007\n",
            "Epoch 1592/2000, Train Loss: 0.002756, Val Loss: 0.035897\n",
            "Epoch 1592/2000, Rel Train Loss: 82.24%, Rel Val Loss: 159.69%\n",
            "Moving Avg Val Loss: 0.799498\n",
            "Epoch 1593/2000, Train Loss: 0.001290, Val Loss: 0.031361\n",
            "Epoch 1593/2000, Rel Train Loss: 74.05%, Rel Val Loss: 38.17%\n",
            "Moving Avg Val Loss: 0.711905\n",
            "Epoch 1594/2000, Train Loss: 0.000660, Val Loss: 0.033534\n",
            "Epoch 1594/2000, Rel Train Loss: 33.67%, Rel Val Loss: 35.07%\n",
            "Moving Avg Val Loss: 0.759325\n",
            "Epoch 1595/2000, Train Loss: 0.001183, Val Loss: 0.032216\n",
            "Epoch 1595/2000, Rel Train Loss: 33.19%, Rel Val Loss: 65.75%\n",
            "Moving Avg Val Loss: 0.782663\n",
            "Epoch 1596/2000, Train Loss: 0.003590, Val Loss: 0.033761\n",
            "Epoch 1596/2000, Rel Train Loss: 86.52%, Rel Val Loss: 92.65%\n",
            "Moving Avg Val Loss: 0.655211\n",
            "Epoch 1597/2000, Train Loss: 0.001866, Val Loss: 0.041242\n",
            "Epoch 1597/2000, Rel Train Loss: 106.07%, Rel Val Loss: 95.96%\n",
            "Moving Avg Val Loss: 0.693532\n",
            "Epoch 1598/2000, Train Loss: 0.001491, Val Loss: 0.032504\n",
            "Epoch 1598/2000, Rel Train Loss: 66.59%, Rel Val Loss: 57.33%\n",
            "Moving Avg Val Loss: 0.689706\n",
            "Epoch 1599/2000, Train Loss: 0.000822, Val Loss: 0.035371\n",
            "Epoch 1599/2000, Rel Train Loss: 44.01%, Rel Val Loss: 33.16%\n",
            "Moving Avg Val Loss: 0.619378\n",
            "Epoch 1600/2000, Train Loss: 0.000466, Val Loss: 0.030771\n",
            "Epoch 1600/2000, Rel Train Loss: 30.76%, Rel Val Loss: 30.59%\n",
            "Moving Avg Val Loss: 0.506544\n",
            "Epoch 1601/2000, Train Loss: 0.000310, Val Loss: 0.033900\n",
            "Epoch 1601/2000, Rel Train Loss: 29.45%, Rel Val Loss: 36.24%\n",
            "Moving Avg Val Loss: 0.375175\n",
            "Epoch 1602/2000, Train Loss: 0.000298, Val Loss: 0.032546\n",
            "Epoch 1602/2000, Rel Train Loss: 33.03%, Rel Val Loss: 30.27%\n",
            "Moving Avg Val Loss: 0.340185\n",
            "Epoch 1603/2000, Train Loss: 0.000352, Val Loss: 0.033000\n",
            "Epoch 1603/2000, Rel Train Loss: 33.91%, Rel Val Loss: 39.84%\n",
            "Moving Avg Val Loss: 0.341189\n",
            "Epoch 1604/2000, Train Loss: 0.000342, Val Loss: 0.032771\n",
            "Epoch 1604/2000, Rel Train Loss: 32.64%, Rel Val Loss: 33.66%\n",
            "Moving Avg Val Loss: 0.341507\n",
            "Epoch 1605/2000, Train Loss: 0.000254, Val Loss: 0.031758\n",
            "Epoch 1605/2000, Rel Train Loss: 27.40%, Rel Val Loss: 30.74%\n",
            "Moving Avg Val Loss: 0.331320\n",
            "Epoch 1606/2000, Train Loss: 0.000232, Val Loss: 0.033760\n",
            "Epoch 1606/2000, Rel Train Loss: 26.54%, Rel Val Loss: 31.14%\n",
            "Moving Avg Val Loss: 0.332257\n",
            "Epoch 1607/2000, Train Loss: 0.000293, Val Loss: 0.032978\n",
            "Epoch 1607/2000, Rel Train Loss: 31.22%, Rel Val Loss: 30.74%\n",
            "Moving Avg Val Loss: 0.314635\n",
            "Epoch 1608/2000, Train Loss: 0.000584, Val Loss: 0.036239\n",
            "Epoch 1608/2000, Rel Train Loss: 38.41%, Rel Val Loss: 31.03%\n",
            "Moving Avg Val Loss: 0.341267\n",
            "Epoch 1609/2000, Train Loss: 0.000640, Val Loss: 0.030915\n",
            "Epoch 1609/2000, Rel Train Loss: 51.78%, Rel Val Loss: 46.98%\n",
            "Moving Avg Val Loss: 0.352661\n",
            "Epoch 1610/2000, Train Loss: 0.000391, Val Loss: 0.034639\n",
            "Epoch 1610/2000, Rel Train Loss: 35.54%, Rel Val Loss: 36.44%\n",
            "Moving Avg Val Loss: 0.361489\n",
            "Epoch 1611/2000, Train Loss: 0.000254, Val Loss: 0.033338\n",
            "Epoch 1611/2000, Rel Train Loss: 30.67%, Rel Val Loss: 35.56%\n",
            "Moving Avg Val Loss: 0.364009\n",
            "Epoch 1612/2000, Train Loss: 0.000360, Val Loss: 0.034211\n",
            "Epoch 1612/2000, Rel Train Loss: 32.73%, Rel Val Loss: 32.00%\n",
            "Moving Avg Val Loss: 0.428461\n",
            "Epoch 1613/2000, Train Loss: 0.000601, Val Loss: 0.034374\n",
            "Epoch 1613/2000, Rel Train Loss: 35.90%, Rel Val Loss: 63.25%\n",
            "Moving Avg Val Loss: 0.535698\n",
            "Epoch 1614/2000, Train Loss: 0.003308, Val Loss: 0.045451\n",
            "Epoch 1614/2000, Rel Train Loss: 72.98%, Rel Val Loss: 100.59%\n",
            "Moving Avg Val Loss: 0.668314\n",
            "Epoch 1615/2000, Train Loss: 0.002761, Val Loss: 0.037933\n",
            "Epoch 1615/2000, Rel Train Loss: 81.08%, Rel Val Loss: 102.75%\n",
            "Moving Avg Val Loss: 0.772771\n",
            "Epoch 1616/2000, Train Loss: 0.005790, Val Loss: 0.050940\n",
            "Epoch 1616/2000, Rel Train Loss: 102.59%, Rel Val Loss: 87.79%\n",
            "Moving Avg Val Loss: 0.924108\n",
            "Epoch 1617/2000, Train Loss: 0.004333, Val Loss: 0.037330\n",
            "Epoch 1617/2000, Rel Train Loss: 114.21%, Rel Val Loss: 107.67%\n",
            "Moving Avg Val Loss: 0.883685\n",
            "Epoch 1618/2000, Train Loss: 0.002670, Val Loss: 0.038500\n",
            "Epoch 1618/2000, Rel Train Loss: 60.86%, Rel Val Loss: 43.04%\n",
            "Moving Avg Val Loss: 0.850085\n",
            "Epoch 1619/2000, Train Loss: 0.005220, Val Loss: 0.035906\n",
            "Epoch 1619/2000, Rel Train Loss: 69.69%, Rel Val Loss: 83.79%\n",
            "Moving Avg Val Loss: 0.762066\n",
            "Epoch 1620/2000, Train Loss: 0.002943, Val Loss: 0.038944\n",
            "Epoch 1620/2000, Rel Train Loss: 57.74%, Rel Val Loss: 58.74%\n",
            "Moving Avg Val Loss: 0.791227\n",
            "Epoch 1621/2000, Train Loss: 0.005498, Val Loss: 0.034684\n",
            "Epoch 1621/2000, Rel Train Loss: 63.17%, Rel Val Loss: 102.37%\n",
            "Moving Avg Val Loss: 0.654313\n",
            "Epoch 1622/2000, Train Loss: 0.001705, Val Loss: 0.029887\n",
            "Epoch 1622/2000, Rel Train Loss: 74.54%, Rel Val Loss: 39.21%\n",
            "Moving Avg Val Loss: 0.635907\n",
            "Epoch 1623/2000, Train Loss: 0.001065, Val Loss: 0.034414\n",
            "Epoch 1623/2000, Rel Train Loss: 35.75%, Rel Val Loss: 33.84%\n",
            "Moving Avg Val Loss: 0.535715\n",
            "Epoch 1624/2000, Train Loss: 0.001433, Val Loss: 0.030758\n",
            "Epoch 1624/2000, Rel Train Loss: 48.97%, Rel Val Loss: 33.70%\n",
            "Moving Avg Val Loss: 0.484036\n",
            "Epoch 1625/2000, Train Loss: 0.001105, Val Loss: 0.032464\n",
            "Epoch 1625/2000, Rel Train Loss: 37.14%, Rel Val Loss: 32.90%\n",
            "Moving Avg Val Loss: 0.344208\n",
            "Epoch 1626/2000, Train Loss: 0.000558, Val Loss: 0.030087\n",
            "Epoch 1626/2000, Rel Train Loss: 35.24%, Rel Val Loss: 32.45%\n",
            "Moving Avg Val Loss: 0.342886\n",
            "Epoch 1627/2000, Train Loss: 0.000436, Val Loss: 0.032178\n",
            "Epoch 1627/2000, Rel Train Loss: 33.73%, Rel Val Loss: 38.55%\n",
            "Moving Avg Val Loss: 0.339541\n",
            "Epoch 1628/2000, Train Loss: 0.000389, Val Loss: 0.031551\n",
            "Epoch 1628/2000, Rel Train Loss: 34.02%, Rel Val Loss: 32.17%\n",
            "Moving Avg Val Loss: 0.350193\n",
            "Epoch 1629/2000, Train Loss: 0.000421, Val Loss: 0.030668\n",
            "Epoch 1629/2000, Rel Train Loss: 28.02%, Rel Val Loss: 39.02%\n",
            "Moving Avg Val Loss: 0.350097\n",
            "Epoch 1630/2000, Train Loss: 0.000423, Val Loss: 0.035874\n",
            "Epoch 1630/2000, Rel Train Loss: 30.07%, Rel Val Loss: 32.85%\n",
            "Moving Avg Val Loss: 0.414727\n",
            "Epoch 1631/2000, Train Loss: 0.001820, Val Loss: 0.034510\n",
            "Epoch 1631/2000, Rel Train Loss: 38.34%, Rel Val Loss: 64.77%\n",
            "Moving Avg Val Loss: 0.421377\n",
            "Epoch 1632/2000, Train Loss: 0.002002, Val Loss: 0.030576\n",
            "Epoch 1632/2000, Rel Train Loss: 53.65%, Rel Val Loss: 41.88%\n",
            "Moving Avg Val Loss: 0.440133\n",
            "Epoch 1633/2000, Train Loss: 0.001250, Val Loss: 0.036379\n",
            "Epoch 1633/2000, Rel Train Loss: 46.16%, Rel Val Loss: 41.54%\n",
            "Moving Avg Val Loss: 0.444474\n",
            "Epoch 1634/2000, Train Loss: 0.001110, Val Loss: 0.032901\n",
            "Epoch 1634/2000, Rel Train Loss: 36.77%, Rel Val Loss: 41.19%\n",
            "Moving Avg Val Loss: 0.454524\n",
            "Epoch 1635/2000, Train Loss: 0.003660, Val Loss: 0.038487\n",
            "Epoch 1635/2000, Rel Train Loss: 60.28%, Rel Val Loss: 37.88%\n",
            "Moving Avg Val Loss: 0.476909\n",
            "Epoch 1636/2000, Train Loss: 0.002459, Val Loss: 0.029182\n",
            "Epoch 1636/2000, Rel Train Loss: 82.96%, Rel Val Loss: 75.96%\n",
            "Moving Avg Val Loss: 0.484900\n",
            "Epoch 1637/2000, Train Loss: 0.001254, Val Loss: 0.038808\n",
            "Epoch 1637/2000, Rel Train Loss: 41.69%, Rel Val Loss: 45.87%\n",
            "Moving Avg Val Loss: 0.524071\n",
            "Epoch 1638/2000, Train Loss: 0.003147, Val Loss: 0.032517\n",
            "Epoch 1638/2000, Rel Train Loss: 47.31%, Rel Val Loss: 61.13%\n",
            "Moving Avg Val Loss: 0.595659\n",
            "Epoch 1639/2000, Train Loss: 0.001340, Val Loss: 0.032779\n",
            "Epoch 1639/2000, Rel Train Loss: 75.51%, Rel Val Loss: 76.99%\n",
            "Moving Avg Val Loss: 0.587347\n",
            "Epoch 1640/2000, Train Loss: 0.000680, Val Loss: 0.030505\n",
            "Epoch 1640/2000, Rel Train Loss: 55.52%, Rel Val Loss: 33.72%\n",
            "Moving Avg Val Loss: 0.499941\n",
            "Epoch 1641/2000, Train Loss: 0.000389, Val Loss: 0.033227\n",
            "Epoch 1641/2000, Rel Train Loss: 30.20%, Rel Val Loss: 32.26%\n",
            "Moving Avg Val Loss: 0.472888\n",
            "Epoch 1642/2000, Train Loss: 0.000390, Val Loss: 0.033198\n",
            "Epoch 1642/2000, Rel Train Loss: 31.00%, Rel Val Loss: 32.35%\n",
            "Moving Avg Val Loss: 0.411662\n",
            "Epoch 1643/2000, Train Loss: 0.000341, Val Loss: 0.031819\n",
            "Epoch 1643/2000, Rel Train Loss: 35.64%, Rel Val Loss: 30.52%\n",
            "Moving Avg Val Loss: 0.321189\n",
            "Epoch 1644/2000, Train Loss: 0.000295, Val Loss: 0.032264\n",
            "Epoch 1644/2000, Rel Train Loss: 29.71%, Rel Val Loss: 31.75%\n",
            "Moving Avg Val Loss: 0.318824\n",
            "Epoch 1645/2000, Train Loss: 0.000260, Val Loss: 0.032015\n",
            "Epoch 1645/2000, Rel Train Loss: 27.69%, Rel Val Loss: 32.54%\n",
            "Moving Avg Val Loss: 0.319163\n",
            "Epoch 1646/2000, Train Loss: 0.000285, Val Loss: 0.031380\n",
            "Epoch 1646/2000, Rel Train Loss: 31.25%, Rel Val Loss: 32.43%\n",
            "Moving Avg Val Loss: 0.315671\n",
            "Epoch 1647/2000, Train Loss: 0.000237, Val Loss: 0.032579\n",
            "Epoch 1647/2000, Rel Train Loss: 32.93%, Rel Val Loss: 30.60%\n",
            "Moving Avg Val Loss: 0.314651\n",
            "Epoch 1648/2000, Train Loss: 0.000255, Val Loss: 0.032147\n",
            "Epoch 1648/2000, Rel Train Loss: 30.88%, Rel Val Loss: 30.01%\n",
            "Moving Avg Val Loss: 0.389414\n",
            "Epoch 1649/2000, Train Loss: 0.001229, Val Loss: 0.035133\n",
            "Epoch 1649/2000, Rel Train Loss: 37.05%, Rel Val Loss: 69.13%\n",
            "Moving Avg Val Loss: 0.388631\n",
            "Epoch 1650/2000, Train Loss: 0.000516, Val Loss: 0.032376\n",
            "Epoch 1650/2000, Rel Train Loss: 61.53%, Rel Val Loss: 32.15%\n",
            "Moving Avg Val Loss: 0.394520\n",
            "Epoch 1651/2000, Train Loss: 0.000464, Val Loss: 0.033121\n",
            "Epoch 1651/2000, Rel Train Loss: 30.53%, Rel Val Loss: 35.37%\n",
            "Moving Avg Val Loss: 0.393614\n",
            "Epoch 1652/2000, Train Loss: 0.000336, Val Loss: 0.033425\n",
            "Epoch 1652/2000, Rel Train Loss: 30.97%, Rel Val Loss: 30.15%\n",
            "Moving Avg Val Loss: 0.395491\n",
            "Epoch 1653/2000, Train Loss: 0.000398, Val Loss: 0.030665\n",
            "Epoch 1653/2000, Rel Train Loss: 30.83%, Rel Val Loss: 30.95%\n",
            "Moving Avg Val Loss: 0.328798\n",
            "Epoch 1654/2000, Train Loss: 0.000785, Val Loss: 0.034335\n",
            "Epoch 1654/2000, Rel Train Loss: 35.32%, Rel Val Loss: 35.79%\n",
            "Moving Avg Val Loss: 0.343604\n",
            "Epoch 1655/2000, Train Loss: 0.000551, Val Loss: 0.032373\n",
            "Epoch 1655/2000, Rel Train Loss: 36.22%, Rel Val Loss: 39.55%\n",
            "Moving Avg Val Loss: 0.335130\n",
            "Epoch 1656/2000, Train Loss: 0.000302, Val Loss: 0.032281\n",
            "Epoch 1656/2000, Rel Train Loss: 39.00%, Rel Val Loss: 31.13%\n",
            "Moving Avg Val Loss: 0.335993\n",
            "Epoch 1657/2000, Train Loss: 0.000259, Val Loss: 0.031544\n",
            "Epoch 1657/2000, Rel Train Loss: 29.33%, Rel Val Loss: 30.58%\n",
            "Moving Avg Val Loss: 0.341279\n",
            "Epoch 1658/2000, Train Loss: 0.000257, Val Loss: 0.032090\n",
            "Epoch 1658/2000, Rel Train Loss: 28.19%, Rel Val Loss: 33.59%\n",
            "Moving Avg Val Loss: 0.331425\n",
            "Epoch 1659/2000, Train Loss: 0.000222, Val Loss: 0.032405\n",
            "Epoch 1659/2000, Rel Train Loss: 30.36%, Rel Val Loss: 30.86%\n",
            "Moving Avg Val Loss: 0.317063\n",
            "Epoch 1660/2000, Train Loss: 0.000224, Val Loss: 0.033317\n",
            "Epoch 1660/2000, Rel Train Loss: 27.90%, Rel Val Loss: 32.37%\n",
            "Moving Avg Val Loss: 0.314081\n",
            "Epoch 1661/2000, Train Loss: 0.000240, Val Loss: 0.032074\n",
            "Epoch 1661/2000, Rel Train Loss: 27.51%, Rel Val Loss: 29.64%\n",
            "Moving Avg Val Loss: 0.319674\n",
            "Epoch 1662/2000, Train Loss: 0.000214, Val Loss: 0.033129\n",
            "Epoch 1662/2000, Rel Train Loss: 25.36%, Rel Val Loss: 33.38%\n",
            "Moving Avg Val Loss: 0.313195\n",
            "Epoch 1663/2000, Train Loss: 0.000242, Val Loss: 0.031556\n",
            "Epoch 1663/2000, Rel Train Loss: 29.52%, Rel Val Loss: 30.35%\n",
            "Moving Avg Val Loss: 0.317740\n",
            "Epoch 1664/2000, Train Loss: 0.000238, Val Loss: 0.033360\n",
            "Epoch 1664/2000, Rel Train Loss: 26.92%, Rel Val Loss: 33.13%\n",
            "Moving Avg Val Loss: 0.314363\n",
            "Epoch 1665/2000, Train Loss: 0.000200, Val Loss: 0.032437\n",
            "Epoch 1665/2000, Rel Train Loss: 26.10%, Rel Val Loss: 30.68%\n",
            "Moving Avg Val Loss: 0.316611\n",
            "Epoch 1666/2000, Train Loss: 0.000200, Val Loss: 0.031745\n",
            "Epoch 1666/2000, Rel Train Loss: 25.92%, Rel Val Loss: 30.77%\n",
            "Moving Avg Val Loss: 0.315449\n",
            "Epoch 1667/2000, Train Loss: 0.000220, Val Loss: 0.032614\n",
            "Epoch 1667/2000, Rel Train Loss: 27.95%, Rel Val Loss: 32.80%\n",
            "Moving Avg Val Loss: 0.315306\n",
            "Epoch 1668/2000, Train Loss: 0.000279, Val Loss: 0.033336\n",
            "Epoch 1668/2000, Rel Train Loss: 28.82%, Rel Val Loss: 30.28%\n",
            "Moving Avg Val Loss: 0.315520\n",
            "Epoch 1669/2000, Train Loss: 0.000241, Val Loss: 0.032775\n",
            "Epoch 1669/2000, Rel Train Loss: 29.15%, Rel Val Loss: 33.24%\n",
            "Moving Avg Val Loss: 0.316695\n",
            "Epoch 1670/2000, Train Loss: 0.000205, Val Loss: 0.032994\n",
            "Epoch 1670/2000, Rel Train Loss: 28.93%, Rel Val Loss: 31.27%\n",
            "Moving Avg Val Loss: 0.320735\n",
            "Epoch 1671/2000, Train Loss: 0.000204, Val Loss: 0.032283\n",
            "Epoch 1671/2000, Rel Train Loss: 25.62%, Rel Val Loss: 32.79%\n",
            "Moving Avg Val Loss: 0.324121\n",
            "Epoch 1672/2000, Train Loss: 0.000205, Val Loss: 0.032833\n",
            "Epoch 1672/2000, Rel Train Loss: 30.38%, Rel Val Loss: 34.49%\n",
            "Moving Avg Val Loss: 0.328131\n",
            "Epoch 1673/2000, Train Loss: 0.000266, Val Loss: 0.031676\n",
            "Epoch 1673/2000, Rel Train Loss: 27.43%, Rel Val Loss: 32.28%\n",
            "Moving Avg Val Loss: 0.326158\n",
            "Epoch 1674/2000, Train Loss: 0.000292, Val Loss: 0.033836\n",
            "Epoch 1674/2000, Rel Train Loss: 35.70%, Rel Val Loss: 32.25%\n",
            "Moving Avg Val Loss: 0.331244\n",
            "Epoch 1675/2000, Train Loss: 0.000275, Val Loss: 0.032060\n",
            "Epoch 1675/2000, Rel Train Loss: 28.65%, Rel Val Loss: 33.81%\n",
            "Moving Avg Val Loss: 0.332937\n",
            "Epoch 1676/2000, Train Loss: 0.000230, Val Loss: 0.032510\n",
            "Epoch 1676/2000, Rel Train Loss: 31.27%, Rel Val Loss: 33.63%\n",
            "Moving Avg Val Loss: 0.325631\n",
            "Epoch 1677/2000, Train Loss: 0.000200, Val Loss: 0.033252\n",
            "Epoch 1677/2000, Rel Train Loss: 26.53%, Rel Val Loss: 30.84%\n",
            "Moving Avg Val Loss: 0.322596\n",
            "Epoch 1678/2000, Train Loss: 0.000195, Val Loss: 0.032486\n",
            "Epoch 1678/2000, Rel Train Loss: 27.69%, Rel Val Loss: 30.76%\n",
            "Moving Avg Val Loss: 0.323018\n",
            "Epoch 1679/2000, Train Loss: 0.000185, Val Loss: 0.032464\n",
            "Epoch 1679/2000, Rel Train Loss: 27.69%, Rel Val Loss: 32.46%\n",
            "Moving Avg Val Loss: 0.315443\n",
            "Epoch 1680/2000, Train Loss: 0.000185, Val Loss: 0.032755\n",
            "Epoch 1680/2000, Rel Train Loss: 25.65%, Rel Val Loss: 30.02%\n",
            "Moving Avg Val Loss: 0.306612\n",
            "Epoch 1681/2000, Train Loss: 0.000185, Val Loss: 0.032474\n",
            "Epoch 1681/2000, Rel Train Loss: 28.63%, Rel Val Loss: 29.22%\n",
            "Moving Avg Val Loss: 0.305645\n",
            "Epoch 1682/2000, Train Loss: 0.000192, Val Loss: 0.032185\n",
            "Epoch 1682/2000, Rel Train Loss: 28.57%, Rel Val Loss: 30.35%\n",
            "Moving Avg Val Loss: 0.302200\n",
            "Epoch 1683/2000, Train Loss: 0.000189, Val Loss: 0.032616\n",
            "Epoch 1683/2000, Rel Train Loss: 27.31%, Rel Val Loss: 29.04%\n",
            "Moving Avg Val Loss: 0.294826\n",
            "Epoch 1684/2000, Train Loss: 0.000183, Val Loss: 0.032712\n",
            "Epoch 1684/2000, Rel Train Loss: 25.78%, Rel Val Loss: 28.78%\n",
            "Moving Avg Val Loss: 0.299963\n",
            "Epoch 1685/2000, Train Loss: 0.000184, Val Loss: 0.032283\n",
            "Epoch 1685/2000, Rel Train Loss: 33.61%, Rel Val Loss: 32.59%\n",
            "Moving Avg Val Loss: 0.314550\n",
            "Epoch 1686/2000, Train Loss: 0.000529, Val Loss: 0.037030\n",
            "Epoch 1686/2000, Rel Train Loss: 33.42%, Rel Val Loss: 36.51%\n",
            "Moving Avg Val Loss: 0.318386\n",
            "Epoch 1687/2000, Train Loss: 0.000980, Val Loss: 0.029998\n",
            "Epoch 1687/2000, Rel Train Loss: 52.65%, Rel Val Loss: 32.27%\n",
            "Moving Avg Val Loss: 0.372765\n",
            "Epoch 1688/2000, Train Loss: 0.001022, Val Loss: 0.032892\n",
            "Epoch 1688/2000, Rel Train Loss: 39.75%, Rel Val Loss: 56.23%\n",
            "Moving Avg Val Loss: 0.390287\n",
            "Epoch 1689/2000, Train Loss: 0.000979, Val Loss: 0.041233\n",
            "Epoch 1689/2000, Rel Train Loss: 54.15%, Rel Val Loss: 37.54%\n",
            "Moving Avg Val Loss: 0.398276\n",
            "Epoch 1690/2000, Train Loss: 0.001178, Val Loss: 0.038446\n",
            "Epoch 1690/2000, Rel Train Loss: 41.13%, Rel Val Loss: 36.59%\n",
            "Moving Avg Val Loss: 0.494510\n",
            "Epoch 1691/2000, Train Loss: 0.002997, Val Loss: 0.051176\n",
            "Epoch 1691/2000, Rel Train Loss: 57.19%, Rel Val Loss: 84.63%\n",
            "Moving Avg Val Loss: 1.038747\n",
            "Epoch 1692/2000, Train Loss: 0.007609, Val Loss: 0.040850\n",
            "Epoch 1692/2000, Rel Train Loss: 185.75%, Rel Val Loss: 304.39%\n",
            "Moving Avg Val Loss: 1.091246\n",
            "Epoch 1693/2000, Train Loss: 0.004850, Val Loss: 0.036938\n",
            "Epoch 1693/2000, Rel Train Loss: 190.69%, Rel Val Loss: 82.48%\n",
            "Moving Avg Val Loss: 1.125947\n",
            "Epoch 1694/2000, Train Loss: 0.001624, Val Loss: 0.035327\n",
            "Epoch 1694/2000, Rel Train Loss: 74.91%, Rel Val Loss: 54.89%\n",
            "Moving Avg Val Loss: 1.128706\n",
            "Epoch 1695/2000, Train Loss: 0.001422, Val Loss: 0.028958\n",
            "Epoch 1695/2000, Rel Train Loss: 48.85%, Rel Val Loss: 37.97%\n",
            "Moving Avg Val Loss: 1.064449\n",
            "Epoch 1696/2000, Train Loss: 0.001083, Val Loss: 0.039260\n",
            "Epoch 1696/2000, Rel Train Loss: 37.50%, Rel Val Loss: 52.50%\n",
            "Moving Avg Val Loss: 0.556575\n",
            "Epoch 1697/2000, Train Loss: 0.001154, Val Loss: 0.028717\n",
            "Epoch 1697/2000, Rel Train Loss: 53.24%, Rel Val Loss: 50.45%\n",
            "Moving Avg Val Loss: 0.489603\n",
            "Epoch 1698/2000, Train Loss: 0.000644, Val Loss: 0.036802\n",
            "Epoch 1698/2000, Rel Train Loss: 41.47%, Rel Val Loss: 49.00%\n",
            "Moving Avg Val Loss: 0.445063\n",
            "Epoch 1699/2000, Train Loss: 0.000696, Val Loss: 0.038002\n",
            "Epoch 1699/2000, Rel Train Loss: 31.69%, Rel Val Loss: 32.62%\n",
            "Moving Avg Val Loss: 0.457393\n",
            "Epoch 1700/2000, Train Loss: 0.000658, Val Loss: 0.033189\n",
            "Epoch 1700/2000, Rel Train Loss: 34.29%, Rel Val Loss: 44.13%\n",
            "Moving Avg Val Loss: 0.412922\n",
            "Epoch 1701/2000, Train Loss: 0.000702, Val Loss: 0.035664\n",
            "Epoch 1701/2000, Rel Train Loss: 30.90%, Rel Val Loss: 30.26%\n",
            "Moving Avg Val Loss: 0.388600\n",
            "Epoch 1702/2000, Train Loss: 0.000593, Val Loss: 0.031923\n",
            "Epoch 1702/2000, Rel Train Loss: 29.75%, Rel Val Loss: 38.29%\n",
            "Moving Avg Val Loss: 0.360979\n",
            "Epoch 1703/2000, Train Loss: 0.000533, Val Loss: 0.029286\n",
            "Epoch 1703/2000, Rel Train Loss: 34.46%, Rel Val Loss: 35.18%\n",
            "Moving Avg Val Loss: 0.422870\n",
            "Epoch 1704/2000, Train Loss: 0.000826, Val Loss: 0.034491\n",
            "Epoch 1704/2000, Rel Train Loss: 48.89%, Rel Val Loss: 63.56%\n",
            "Moving Avg Val Loss: 0.450137\n",
            "Epoch 1705/2000, Train Loss: 0.002347, Val Loss: 0.034129\n",
            "Epoch 1705/2000, Rel Train Loss: 47.17%, Rel Val Loss: 57.77%\n",
            "Moving Avg Val Loss: 0.594112\n",
            "Epoch 1706/2000, Train Loss: 0.002513, Val Loss: 0.042534\n",
            "Epoch 1706/2000, Rel Train Loss: 52.01%, Rel Val Loss: 102.25%\n",
            "Moving Avg Val Loss: 0.607133\n",
            "Epoch 1707/2000, Train Loss: 0.002197, Val Loss: 0.027352\n",
            "Epoch 1707/2000, Rel Train Loss: 53.88%, Rel Val Loss: 44.80%\n",
            "Moving Avg Val Loss: 0.621406\n",
            "Epoch 1708/2000, Train Loss: 0.001153, Val Loss: 0.041482\n",
            "Epoch 1708/2000, Rel Train Loss: 47.08%, Rel Val Loss: 42.32%\n",
            "Moving Avg Val Loss: 0.620039\n",
            "Epoch 1709/2000, Train Loss: 0.004386, Val Loss: 0.037825\n",
            "Epoch 1709/2000, Rel Train Loss: 80.48%, Rel Val Loss: 62.88%\n",
            "Moving Avg Val Loss: 0.622442\n",
            "Epoch 1710/2000, Train Loss: 0.003873, Val Loss: 0.026155\n",
            "Epoch 1710/2000, Rel Train Loss: 56.61%, Rel Val Loss: 58.97%\n",
            "Moving Avg Val Loss: 0.535290\n",
            "Epoch 1711/2000, Train Loss: 0.002853, Val Loss: 0.042713\n",
            "Epoch 1711/2000, Rel Train Loss: 53.98%, Rel Val Loss: 58.68%\n",
            "Moving Avg Val Loss: 0.519646\n",
            "Epoch 1712/2000, Train Loss: 0.002082, Val Loss: 0.028223\n",
            "Epoch 1712/2000, Rel Train Loss: 75.06%, Rel Val Loss: 36.98%\n",
            "Moving Avg Val Loss: 0.501827\n",
            "Epoch 1713/2000, Train Loss: 0.001269, Val Loss: 0.031162\n",
            "Epoch 1713/2000, Rel Train Loss: 39.82%, Rel Val Loss: 33.41%\n",
            "Moving Avg Val Loss: 0.471657\n",
            "Epoch 1714/2000, Train Loss: 0.001106, Val Loss: 0.032637\n",
            "Epoch 1714/2000, Rel Train Loss: 39.35%, Rel Val Loss: 47.80%\n",
            "Moving Avg Val Loss: 0.449360\n",
            "Epoch 1715/2000, Train Loss: 0.000803, Val Loss: 0.031242\n",
            "Epoch 1715/2000, Rel Train Loss: 37.83%, Rel Val Loss: 47.82%\n",
            "Moving Avg Val Loss: 0.423777\n",
            "Epoch 1716/2000, Train Loss: 0.000841, Val Loss: 0.031904\n",
            "Epoch 1716/2000, Rel Train Loss: 39.04%, Rel Val Loss: 45.88%\n",
            "Moving Avg Val Loss: 0.444609\n",
            "Epoch 1717/2000, Train Loss: 0.000933, Val Loss: 0.029645\n",
            "Epoch 1717/2000, Rel Train Loss: 35.27%, Rel Val Loss: 47.40%\n",
            "Moving Avg Val Loss: 0.480498\n",
            "Epoch 1718/2000, Train Loss: 0.001181, Val Loss: 0.034009\n",
            "Epoch 1718/2000, Rel Train Loss: 54.98%, Rel Val Loss: 51.36%\n",
            "Moving Avg Val Loss: 0.477592\n",
            "Epoch 1719/2000, Train Loss: 0.000725, Val Loss: 0.027360\n",
            "Epoch 1719/2000, Rel Train Loss: 55.28%, Rel Val Loss: 46.34%\n",
            "Moving Avg Val Loss: 0.482444\n",
            "Epoch 1720/2000, Train Loss: 0.000674, Val Loss: 0.033123\n",
            "Epoch 1720/2000, Rel Train Loss: 50.61%, Rel Val Loss: 50.24%\n",
            "Moving Avg Val Loss: 0.472760\n",
            "Epoch 1721/2000, Train Loss: 0.000873, Val Loss: 0.031950\n",
            "Epoch 1721/2000, Rel Train Loss: 45.03%, Rel Val Loss: 41.04%\n",
            "Moving Avg Val Loss: 0.471068\n",
            "Epoch 1722/2000, Train Loss: 0.000761, Val Loss: 0.028762\n",
            "Epoch 1722/2000, Rel Train Loss: 34.24%, Rel Val Loss: 46.55%\n",
            "Moving Avg Val Loss: 0.433899\n",
            "Epoch 1723/2000, Train Loss: 0.000512, Val Loss: 0.028835\n",
            "Epoch 1723/2000, Rel Train Loss: 36.45%, Rel Val Loss: 32.77%\n",
            "Moving Avg Val Loss: 0.424502\n",
            "Epoch 1724/2000, Train Loss: 0.000436, Val Loss: 0.030970\n",
            "Epoch 1724/2000, Rel Train Loss: 32.29%, Rel Val Loss: 41.64%\n",
            "Moving Avg Val Loss: 0.389816\n",
            "Epoch 1725/2000, Train Loss: 0.000333, Val Loss: 0.030762\n",
            "Epoch 1725/2000, Rel Train Loss: 31.55%, Rel Val Loss: 32.90%\n",
            "Moving Avg Val Loss: 0.449186\n",
            "Epoch 1726/2000, Train Loss: 0.001067, Val Loss: 0.030305\n",
            "Epoch 1726/2000, Rel Train Loss: 44.62%, Rel Val Loss: 70.73%\n",
            "Moving Avg Val Loss: 0.487868\n",
            "Epoch 1727/2000, Train Loss: 0.001210, Val Loss: 0.033940\n",
            "Epoch 1727/2000, Rel Train Loss: 49.71%, Rel Val Loss: 65.89%\n",
            "Moving Avg Val Loss: 0.479869\n",
            "Epoch 1728/2000, Train Loss: 0.000711, Val Loss: 0.028053\n",
            "Epoch 1728/2000, Rel Train Loss: 36.47%, Rel Val Loss: 28.77%\n",
            "Moving Avg Val Loss: 0.474753\n",
            "Epoch 1729/2000, Train Loss: 0.000472, Val Loss: 0.032302\n",
            "Epoch 1729/2000, Rel Train Loss: 30.39%, Rel Val Loss: 39.09%\n",
            "Moving Avg Val Loss: 0.543923\n",
            "Epoch 1730/2000, Train Loss: 0.000871, Val Loss: 0.029158\n",
            "Epoch 1730/2000, Rel Train Loss: 42.65%, Rel Val Loss: 67.49%\n",
            "Moving Avg Val Loss: 0.528216\n",
            "Epoch 1731/2000, Train Loss: 0.000943, Val Loss: 0.033046\n",
            "Epoch 1731/2000, Rel Train Loss: 52.08%, Rel Val Loss: 62.87%\n",
            "Moving Avg Val Loss: 0.461941\n",
            "Epoch 1732/2000, Train Loss: 0.000452, Val Loss: 0.028679\n",
            "Epoch 1732/2000, Rel Train Loss: 42.82%, Rel Val Loss: 32.75%\n",
            "Moving Avg Val Loss: 0.466622\n",
            "Epoch 1733/2000, Train Loss: 0.000360, Val Loss: 0.031585\n",
            "Epoch 1733/2000, Rel Train Loss: 32.82%, Rel Val Loss: 31.11%\n",
            "Moving Avg Val Loss: 0.453446\n",
            "Epoch 1734/2000, Train Loss: 0.000304, Val Loss: 0.029917\n",
            "Epoch 1734/2000, Rel Train Loss: 31.30%, Rel Val Loss: 32.50%\n",
            "Moving Avg Val Loss: 0.401480\n",
            "Epoch 1735/2000, Train Loss: 0.000393, Val Loss: 0.029267\n",
            "Epoch 1735/2000, Rel Train Loss: 33.60%, Rel Val Loss: 41.50%\n",
            "Moving Avg Val Loss: 0.334965\n",
            "Epoch 1736/2000, Train Loss: 0.000240, Val Loss: 0.031133\n",
            "Epoch 1736/2000, Rel Train Loss: 32.42%, Rel Val Loss: 29.62%\n",
            "Moving Avg Val Loss: 0.329564\n",
            "Epoch 1737/2000, Train Loss: 0.000252, Val Loss: 0.029629\n",
            "Epoch 1737/2000, Rel Train Loss: 26.09%, Rel Val Loss: 30.05%\n",
            "Moving Avg Val Loss: 0.333108\n",
            "Epoch 1738/2000, Train Loss: 0.000212, Val Loss: 0.029146\n",
            "Epoch 1738/2000, Rel Train Loss: 25.64%, Rel Val Loss: 32.88%\n",
            "Moving Avg Val Loss: 0.326887\n",
            "Epoch 1739/2000, Train Loss: 0.000196, Val Loss: 0.030527\n",
            "Epoch 1739/2000, Rel Train Loss: 25.56%, Rel Val Loss: 29.39%\n",
            "Moving Avg Val Loss: 0.300383\n",
            "Epoch 1740/2000, Train Loss: 0.000192, Val Loss: 0.029984\n",
            "Epoch 1740/2000, Rel Train Loss: 26.97%, Rel Val Loss: 28.25%\n",
            "Moving Avg Val Loss: 0.302691\n",
            "Epoch 1741/2000, Train Loss: 0.000190, Val Loss: 0.030137\n",
            "Epoch 1741/2000, Rel Train Loss: 26.28%, Rel Val Loss: 30.77%\n",
            "Moving Avg Val Loss: 0.308298\n",
            "Epoch 1742/2000, Train Loss: 0.000190, Val Loss: 0.029876\n",
            "Epoch 1742/2000, Rel Train Loss: 26.57%, Rel Val Loss: 32.86%\n",
            "Moving Avg Val Loss: 0.298397\n",
            "Epoch 1743/2000, Train Loss: 0.000190, Val Loss: 0.030550\n",
            "Epoch 1743/2000, Rel Train Loss: 28.35%, Rel Val Loss: 27.93%\n",
            "Moving Avg Val Loss: 0.312954\n",
            "Epoch 1744/2000, Train Loss: 0.000239, Val Loss: 0.030366\n",
            "Epoch 1744/2000, Rel Train Loss: 24.18%, Rel Val Loss: 36.67%\n",
            "Moving Avg Val Loss: 0.387894\n",
            "Epoch 1745/2000, Train Loss: 0.000963, Val Loss: 0.035417\n",
            "Epoch 1745/2000, Rel Train Loss: 42.14%, Rel Val Loss: 65.72%\n",
            "Moving Avg Val Loss: 0.573640\n",
            "Epoch 1746/2000, Train Loss: 0.003650, Val Loss: 0.034481\n",
            "Epoch 1746/2000, Rel Train Loss: 66.07%, Rel Val Loss: 123.64%\n",
            "Moving Avg Val Loss: 0.672097\n",
            "Epoch 1747/2000, Train Loss: 0.001581, Val Loss: 0.034577\n",
            "Epoch 1747/2000, Rel Train Loss: 63.60%, Rel Val Loss: 82.08%\n",
            "Moving Avg Val Loss: 0.713281\n",
            "Epoch 1748/2000, Train Loss: 0.002500, Val Loss: 0.032534\n",
            "Epoch 1748/2000, Rel Train Loss: 54.34%, Rel Val Loss: 48.53%\n",
            "Moving Avg Val Loss: 0.716500\n",
            "Epoch 1749/2000, Train Loss: 0.001422, Val Loss: 0.031071\n",
            "Epoch 1749/2000, Rel Train Loss: 53.91%, Rel Val Loss: 38.28%\n",
            "Moving Avg Val Loss: 0.776217\n",
            "Epoch 1750/2000, Train Loss: 0.001265, Val Loss: 0.033614\n",
            "Epoch 1750/2000, Rel Train Loss: 71.64%, Rel Val Loss: 95.58%\n",
            "Moving Avg Val Loss: 0.608976\n",
            "Epoch 1751/2000, Train Loss: 0.001126, Val Loss: 0.025128\n",
            "Epoch 1751/2000, Rel Train Loss: 57.76%, Rel Val Loss: 40.02%\n",
            "Moving Avg Val Loss: 0.526752\n",
            "Epoch 1752/2000, Train Loss: 0.001019, Val Loss: 0.037004\n",
            "Epoch 1752/2000, Rel Train Loss: 43.63%, Rel Val Loss: 40.97%\n",
            "Moving Avg Val Loss: 0.490801\n",
            "Epoch 1753/2000, Train Loss: 0.000717, Val Loss: 0.028165\n",
            "Epoch 1753/2000, Rel Train Loss: 34.21%, Rel Val Loss: 30.55%\n",
            "Moving Avg Val Loss: 0.475499\n",
            "Epoch 1754/2000, Train Loss: 0.000328, Val Loss: 0.028878\n",
            "Epoch 1754/2000, Rel Train Loss: 30.88%, Rel Val Loss: 30.62%\n",
            "Moving Avg Val Loss: 0.352743\n",
            "Epoch 1755/2000, Train Loss: 0.000357, Val Loss: 0.028939\n",
            "Epoch 1755/2000, Rel Train Loss: 25.61%, Rel Val Loss: 34.20%\n",
            "Moving Avg Val Loss: 0.327342\n",
            "Epoch 1756/2000, Train Loss: 0.000249, Val Loss: 0.028596\n",
            "Epoch 1756/2000, Rel Train Loss: 28.30%, Rel Val Loss: 27.32%\n",
            "Moving Avg Val Loss: 0.304972\n",
            "Epoch 1757/2000, Train Loss: 0.000322, Val Loss: 0.029782\n",
            "Epoch 1757/2000, Rel Train Loss: 25.11%, Rel Val Loss: 29.79%\n",
            "Moving Avg Val Loss: 0.347518\n",
            "Epoch 1758/2000, Train Loss: 0.000632, Val Loss: 0.029700\n",
            "Epoch 1758/2000, Rel Train Loss: 42.35%, Rel Val Loss: 51.82%\n",
            "Moving Avg Val Loss: 0.346277\n",
            "Epoch 1759/2000, Train Loss: 0.000327, Val Loss: 0.028838\n",
            "Epoch 1759/2000, Rel Train Loss: 35.72%, Rel Val Loss: 30.00%\n",
            "Moving Avg Val Loss: 0.342794\n",
            "Epoch 1760/2000, Train Loss: 0.000337, Val Loss: 0.028579\n",
            "Epoch 1760/2000, Rel Train Loss: 32.94%, Rel Val Loss: 32.46%\n",
            "Moving Avg Val Loss: 0.346499\n",
            "Epoch 1761/2000, Train Loss: 0.000391, Val Loss: 0.030426\n",
            "Epoch 1761/2000, Rel Train Loss: 30.93%, Rel Val Loss: 29.17%\n",
            "Moving Avg Val Loss: 0.363648\n",
            "Epoch 1762/2000, Train Loss: 0.000249, Val Loss: 0.028334\n",
            "Epoch 1762/2000, Rel Train Loss: 45.77%, Rel Val Loss: 38.36%\n",
            "Moving Avg Val Loss: 0.316614\n",
            "Epoch 1763/2000, Train Loss: 0.000228, Val Loss: 0.029911\n",
            "Epoch 1763/2000, Rel Train Loss: 25.89%, Rel Val Loss: 28.31%\n",
            "Moving Avg Val Loss: 0.313751\n",
            "Epoch 1764/2000, Train Loss: 0.000194, Val Loss: 0.028535\n",
            "Epoch 1764/2000, Rel Train Loss: 24.67%, Rel Val Loss: 28.57%\n",
            "Moving Avg Val Loss: 0.308195\n",
            "Epoch 1765/2000, Train Loss: 0.000189, Val Loss: 0.029112\n",
            "Epoch 1765/2000, Rel Train Loss: 25.09%, Rel Val Loss: 29.68%\n",
            "Moving Avg Val Loss: 0.307353\n",
            "Epoch 1766/2000, Train Loss: 0.000191, Val Loss: 0.029477\n",
            "Epoch 1766/2000, Rel Train Loss: 25.71%, Rel Val Loss: 28.75%\n",
            "Moving Avg Val Loss: 0.292773\n",
            "Epoch 1767/2000, Train Loss: 0.000211, Val Loss: 0.027217\n",
            "Epoch 1767/2000, Rel Train Loss: 26.94%, Rel Val Loss: 31.07%\n",
            "Moving Avg Val Loss: 0.307240\n",
            "Epoch 1768/2000, Train Loss: 0.000392, Val Loss: 0.030569\n",
            "Epoch 1768/2000, Rel Train Loss: 23.46%, Rel Val Loss: 35.54%\n",
            "Moving Avg Val Loss: 0.329382\n",
            "Epoch 1769/2000, Train Loss: 0.000507, Val Loss: 0.030526\n",
            "Epoch 1769/2000, Rel Train Loss: 32.35%, Rel Val Loss: 39.64%\n",
            "Moving Avg Val Loss: 0.384333\n",
            "Epoch 1770/2000, Train Loss: 0.000928, Val Loss: 0.033716\n",
            "Epoch 1770/2000, Rel Train Loss: 42.28%, Rel Val Loss: 57.16%\n",
            "Moving Avg Val Loss: 0.418866\n",
            "Epoch 1771/2000, Train Loss: 0.001162, Val Loss: 0.029390\n",
            "Epoch 1771/2000, Rel Train Loss: 48.91%, Rel Val Loss: 46.02%\n",
            "Moving Avg Val Loss: 0.422852\n",
            "Epoch 1772/2000, Train Loss: 0.001108, Val Loss: 0.037860\n",
            "Epoch 1772/2000, Rel Train Loss: 38.51%, Rel Val Loss: 33.06%\n",
            "Moving Avg Val Loss: 0.423725\n",
            "Epoch 1773/2000, Train Loss: 0.000839, Val Loss: 0.031291\n",
            "Epoch 1773/2000, Rel Train Loss: 37.38%, Rel Val Loss: 35.98%\n",
            "Moving Avg Val Loss: 0.440790\n",
            "Epoch 1774/2000, Train Loss: 0.001436, Val Loss: 0.030699\n",
            "Epoch 1774/2000, Rel Train Loss: 44.18%, Rel Val Loss: 48.18%\n",
            "Moving Avg Val Loss: 0.427953\n",
            "Epoch 1775/2000, Train Loss: 0.004949, Val Loss: 0.049827\n",
            "Epoch 1775/2000, Rel Train Loss: 57.95%, Rel Val Loss: 50.74%\n",
            "Moving Avg Val Loss: 0.671055\n",
            "Epoch 1776/2000, Train Loss: 0.010309, Val Loss: 0.035352\n",
            "Epoch 1776/2000, Rel Train Loss: 125.47%, Rel Val Loss: 167.57%\n",
            "Moving Avg Val Loss: 0.878336\n",
            "Epoch 1777/2000, Train Loss: 0.006553, Val Loss: 0.048856\n",
            "Epoch 1777/2000, Rel Train Loss: 170.29%, Rel Val Loss: 136.71%\n",
            "Moving Avg Val Loss: 0.926659\n",
            "Epoch 1778/2000, Train Loss: 0.003024, Val Loss: 0.030904\n",
            "Epoch 1778/2000, Rel Train Loss: 79.61%, Rel Val Loss: 60.14%\n",
            "Moving Avg Val Loss: 0.949960\n",
            "Epoch 1779/2000, Train Loss: 0.005964, Val Loss: 0.030810\n",
            "Epoch 1779/2000, Rel Train Loss: 106.56%, Rel Val Loss: 59.83%\n",
            "Moving Avg Val Loss: 0.992862\n",
            "Epoch 1780/2000, Train Loss: 0.002860, Val Loss: 0.036415\n",
            "Epoch 1780/2000, Rel Train Loss: 105.94%, Rel Val Loss: 72.19%\n",
            "Moving Avg Val Loss: 0.801512\n",
            "Epoch 1781/2000, Train Loss: 0.001331, Val Loss: 0.026787\n",
            "Epoch 1781/2000, Rel Train Loss: 68.61%, Rel Val Loss: 71.90%\n",
            "Moving Avg Val Loss: 0.592295\n",
            "Epoch 1782/2000, Train Loss: 0.000730, Val Loss: 0.030403\n",
            "Epoch 1782/2000, Rel Train Loss: 58.65%, Rel Val Loss: 32.10%\n",
            "Moving Avg Val Loss: 0.533447\n",
            "Epoch 1783/2000, Train Loss: 0.000563, Val Loss: 0.027400\n",
            "Epoch 1783/2000, Rel Train Loss: 35.35%, Rel Val Loss: 30.71%\n",
            "Moving Avg Val Loss: 0.510946\n",
            "Epoch 1784/2000, Train Loss: 0.000935, Val Loss: 0.029657\n",
            "Epoch 1784/2000, Rel Train Loss: 31.91%, Rel Val Loss: 48.58%\n",
            "Moving Avg Val Loss: 0.502126\n",
            "Epoch 1785/2000, Train Loss: 0.002299, Val Loss: 0.035253\n",
            "Epoch 1785/2000, Rel Train Loss: 54.30%, Rel Val Loss: 67.78%\n",
            "Moving Avg Val Loss: 0.475072\n",
            "Epoch 1786/2000, Train Loss: 0.003435, Val Loss: 0.029836\n",
            "Epoch 1786/2000, Rel Train Loss: 69.46%, Rel Val Loss: 58.37%\n",
            "Moving Avg Val Loss: 0.620507\n",
            "Epoch 1787/2000, Train Loss: 0.003688, Val Loss: 0.036994\n",
            "Epoch 1787/2000, Rel Train Loss: 85.79%, Rel Val Loss: 104.81%\n",
            "Moving Avg Val Loss: 0.627554\n",
            "Epoch 1788/2000, Train Loss: 0.003329, Val Loss: 0.026391\n",
            "Epoch 1788/2000, Rel Train Loss: 83.70%, Rel Val Loss: 34.24%\n",
            "Moving Avg Val Loss: 0.648640\n",
            "Epoch 1789/2000, Train Loss: 0.002530, Val Loss: 0.028011\n",
            "Epoch 1789/2000, Rel Train Loss: 39.89%, Rel Val Loss: 59.12%\n",
            "Moving Avg Val Loss: 0.646962\n",
            "Epoch 1790/2000, Train Loss: 0.002134, Val Loss: 0.031321\n",
            "Epoch 1790/2000, Rel Train Loss: 71.02%, Rel Val Loss: 66.94%\n",
            "Moving Avg Val Loss: 0.647959\n",
            "Epoch 1791/2000, Train Loss: 0.001230, Val Loss: 0.027366\n",
            "Epoch 1791/2000, Rel Train Loss: 65.01%, Rel Val Loss: 58.87%\n",
            "Moving Avg Val Loss: 0.508160\n",
            "Epoch 1792/2000, Train Loss: 0.001017, Val Loss: 0.032140\n",
            "Epoch 1792/2000, Rel Train Loss: 39.11%, Rel Val Loss: 34.92%\n",
            "Moving Avg Val Loss: 0.518014\n",
            "Epoch 1793/2000, Train Loss: 0.000698, Val Loss: 0.027642\n",
            "Epoch 1793/2000, Rel Train Loss: 41.20%, Rel Val Loss: 39.16%\n",
            "Moving Avg Val Loss: 0.468693\n",
            "Epoch 1794/2000, Train Loss: 0.000642, Val Loss: 0.031651\n",
            "Epoch 1794/2000, Rel Train Loss: 29.60%, Rel Val Loss: 34.46%\n",
            "Moving Avg Val Loss: 0.417603\n",
            "Epoch 1795/2000, Train Loss: 0.001152, Val Loss: 0.030247\n",
            "Epoch 1795/2000, Rel Train Loss: 55.55%, Rel Val Loss: 41.40%\n",
            "Moving Avg Val Loss: 0.379565\n",
            "Epoch 1796/2000, Train Loss: 0.000515, Val Loss: 0.026879\n",
            "Epoch 1796/2000, Rel Train Loss: 50.99%, Rel Val Loss: 39.85%\n",
            "Moving Avg Val Loss: 0.369281\n",
            "Epoch 1797/2000, Train Loss: 0.000398, Val Loss: 0.028791\n",
            "Epoch 1797/2000, Rel Train Loss: 36.16%, Rel Val Loss: 29.77%\n",
            "Moving Avg Val Loss: 0.349337\n",
            "Epoch 1798/2000, Train Loss: 0.000331, Val Loss: 0.029406\n",
            "Epoch 1798/2000, Rel Train Loss: 28.93%, Rel Val Loss: 29.19%\n",
            "Moving Avg Val Loss: 0.345993\n",
            "Epoch 1799/2000, Train Loss: 0.000318, Val Loss: 0.028188\n",
            "Epoch 1799/2000, Rel Train Loss: 36.35%, Rel Val Loss: 32.79%\n",
            "Moving Avg Val Loss: 0.327303\n",
            "Epoch 1800/2000, Train Loss: 0.000234, Val Loss: 0.028592\n",
            "Epoch 1800/2000, Rel Train Loss: 30.98%, Rel Val Loss: 32.05%\n",
            "Moving Avg Val Loss: 0.310941\n",
            "Epoch 1801/2000, Train Loss: 0.000239, Val Loss: 0.027832\n",
            "Epoch 1801/2000, Rel Train Loss: 26.43%, Rel Val Loss: 31.67%\n",
            "Moving Avg Val Loss: 0.318318\n",
            "Epoch 1802/2000, Train Loss: 0.000211, Val Loss: 0.028080\n",
            "Epoch 1802/2000, Rel Train Loss: 26.92%, Rel Val Loss: 33.46%\n",
            "Moving Avg Val Loss: 0.322442\n",
            "Epoch 1803/2000, Train Loss: 0.000224, Val Loss: 0.028148\n",
            "Epoch 1803/2000, Rel Train Loss: 28.09%, Rel Val Loss: 31.25%\n",
            "Moving Avg Val Loss: 0.312232\n",
            "Epoch 1804/2000, Train Loss: 0.000203, Val Loss: 0.028673\n",
            "Epoch 1804/2000, Rel Train Loss: 25.50%, Rel Val Loss: 27.68%\n",
            "Moving Avg Val Loss: 0.303274\n",
            "Epoch 1805/2000, Train Loss: 0.000191, Val Loss: 0.028276\n",
            "Epoch 1805/2000, Rel Train Loss: 26.78%, Rel Val Loss: 27.57%\n",
            "Moving Avg Val Loss: 0.302400\n",
            "Epoch 1806/2000, Train Loss: 0.000197, Val Loss: 0.028170\n",
            "Epoch 1806/2000, Rel Train Loss: 26.03%, Rel Val Loss: 31.23%\n",
            "Moving Avg Val Loss: 0.293040\n",
            "Epoch 1807/2000, Train Loss: 0.000198, Val Loss: 0.029057\n",
            "Epoch 1807/2000, Rel Train Loss: 25.20%, Rel Val Loss: 28.78%\n",
            "Moving Avg Val Loss: 0.287872\n",
            "Epoch 1808/2000, Train Loss: 0.000190, Val Loss: 0.027929\n",
            "Epoch 1808/2000, Rel Train Loss: 26.45%, Rel Val Loss: 28.67%\n",
            "Moving Avg Val Loss: 0.287996\n",
            "Epoch 1809/2000, Train Loss: 0.000235, Val Loss: 0.028523\n",
            "Epoch 1809/2000, Rel Train Loss: 25.96%, Rel Val Loss: 27.74%\n",
            "Moving Avg Val Loss: 0.288027\n",
            "Epoch 1810/2000, Train Loss: 0.000230, Val Loss: 0.028538\n",
            "Epoch 1810/2000, Rel Train Loss: 28.80%, Rel Val Loss: 27.59%\n",
            "Moving Avg Val Loss: 0.297004\n",
            "Epoch 1811/2000, Train Loss: 0.000286, Val Loss: 0.028362\n",
            "Epoch 1811/2000, Rel Train Loss: 24.82%, Rel Val Loss: 35.72%\n",
            "Moving Avg Val Loss: 0.303879\n",
            "Epoch 1812/2000, Train Loss: 0.000256, Val Loss: 0.029034\n",
            "Epoch 1812/2000, Rel Train Loss: 28.07%, Rel Val Loss: 32.22%\n",
            "Moving Avg Val Loss: 0.301912\n",
            "Epoch 1813/2000, Train Loss: 0.000216, Val Loss: 0.027863\n",
            "Epoch 1813/2000, Rel Train Loss: 27.70%, Rel Val Loss: 27.69%\n",
            "Moving Avg Val Loss: 0.307880\n",
            "Epoch 1814/2000, Train Loss: 0.000202, Val Loss: 0.028772\n",
            "Epoch 1814/2000, Rel Train Loss: 26.63%, Rel Val Loss: 30.73%\n",
            "Moving Avg Val Loss: 0.310429\n",
            "Epoch 1815/2000, Train Loss: 0.000183, Val Loss: 0.027890\n",
            "Epoch 1815/2000, Rel Train Loss: 25.58%, Rel Val Loss: 28.86%\n",
            "Moving Avg Val Loss: 0.297698\n",
            "Epoch 1816/2000, Train Loss: 0.000180, Val Loss: 0.028362\n",
            "Epoch 1816/2000, Rel Train Loss: 26.44%, Rel Val Loss: 29.35%\n",
            "Moving Avg Val Loss: 0.287918\n",
            "Epoch 1817/2000, Train Loss: 0.000180, Val Loss: 0.028335\n",
            "Epoch 1817/2000, Rel Train Loss: 26.03%, Rel Val Loss: 27.33%\n",
            "Moving Avg Val Loss: 0.290422\n",
            "Epoch 1818/2000, Train Loss: 0.000176, Val Loss: 0.028975\n",
            "Epoch 1818/2000, Rel Train Loss: 27.35%, Rel Val Loss: 28.94%\n",
            "Moving Avg Val Loss: 0.283328\n",
            "Epoch 1819/2000, Train Loss: 0.000180, Val Loss: 0.028105\n",
            "Epoch 1819/2000, Rel Train Loss: 25.67%, Rel Val Loss: 27.18%\n",
            "Moving Avg Val Loss: 0.280665\n",
            "Epoch 1820/2000, Train Loss: 0.000171, Val Loss: 0.028767\n",
            "Epoch 1820/2000, Rel Train Loss: 24.47%, Rel Val Loss: 27.53%\n",
            "Moving Avg Val Loss: 0.281613\n",
            "Epoch 1821/2000, Train Loss: 0.000169, Val Loss: 0.028668\n",
            "Epoch 1821/2000, Rel Train Loss: 27.83%, Rel Val Loss: 29.83%\n",
            "Moving Avg Val Loss: 0.291392\n",
            "Epoch 1822/2000, Train Loss: 0.000176, Val Loss: 0.028805\n",
            "Epoch 1822/2000, Rel Train Loss: 24.12%, Rel Val Loss: 32.22%\n",
            "Moving Avg Val Loss: 0.299998\n",
            "Epoch 1823/2000, Train Loss: 0.000222, Val Loss: 0.028651\n",
            "Epoch 1823/2000, Rel Train Loss: 24.89%, Rel Val Loss: 33.24%\n",
            "Moving Avg Val Loss: 0.307340\n",
            "Epoch 1824/2000, Train Loss: 0.000200, Val Loss: 0.028662\n",
            "Epoch 1824/2000, Rel Train Loss: 26.76%, Rel Val Loss: 30.85%\n",
            "Moving Avg Val Loss: 0.307565\n",
            "Epoch 1825/2000, Train Loss: 0.000204, Val Loss: 0.027627\n",
            "Epoch 1825/2000, Rel Train Loss: 26.13%, Rel Val Loss: 27.64%\n",
            "Moving Avg Val Loss: 0.306847\n",
            "Epoch 1826/2000, Train Loss: 0.000195, Val Loss: 0.029490\n",
            "Epoch 1826/2000, Rel Train Loss: 25.71%, Rel Val Loss: 29.47%\n",
            "Moving Avg Val Loss: 0.304562\n",
            "Epoch 1827/2000, Train Loss: 0.000195, Val Loss: 0.028364\n",
            "Epoch 1827/2000, Rel Train Loss: 26.17%, Rel Val Loss: 31.08%\n",
            "Moving Avg Val Loss: 0.296293\n",
            "Epoch 1828/2000, Train Loss: 0.000175, Val Loss: 0.028994\n",
            "Epoch 1828/2000, Rel Train Loss: 25.90%, Rel Val Loss: 29.11%\n",
            "Moving Avg Val Loss: 0.290138\n",
            "Epoch 1829/2000, Train Loss: 0.000169, Val Loss: 0.028886\n",
            "Epoch 1829/2000, Rel Train Loss: 25.51%, Rel Val Loss: 27.77%\n",
            "Moving Avg Val Loss: 0.290973\n",
            "Epoch 1830/2000, Train Loss: 0.000169, Val Loss: 0.028721\n",
            "Epoch 1830/2000, Rel Train Loss: 23.96%, Rel Val Loss: 28.06%\n",
            "Moving Avg Val Loss: 0.289572\n",
            "Epoch 1831/2000, Train Loss: 0.000166, Val Loss: 0.028820\n",
            "Epoch 1831/2000, Rel Train Loss: 25.92%, Rel Val Loss: 28.77%\n",
            "Moving Avg Val Loss: 0.287972\n",
            "Epoch 1832/2000, Train Loss: 0.000192, Val Loss: 0.028953\n",
            "Epoch 1832/2000, Rel Train Loss: 23.75%, Rel Val Loss: 30.28%\n",
            "Moving Avg Val Loss: 0.287425\n",
            "Epoch 1833/2000, Train Loss: 0.000256, Val Loss: 0.028412\n",
            "Epoch 1833/2000, Rel Train Loss: 27.56%, Rel Val Loss: 28.83%\n",
            "Moving Avg Val Loss: 0.301006\n",
            "Epoch 1834/2000, Train Loss: 0.000258, Val Loss: 0.030228\n",
            "Epoch 1834/2000, Rel Train Loss: 27.71%, Rel Val Loss: 34.56%\n",
            "Moving Avg Val Loss: 0.305388\n",
            "Epoch 1835/2000, Train Loss: 0.000205, Val Loss: 0.029130\n",
            "Epoch 1835/2000, Rel Train Loss: 36.43%, Rel Val Loss: 30.25%\n",
            "Moving Avg Val Loss: 0.307376\n",
            "Epoch 1836/2000, Train Loss: 0.000206, Val Loss: 0.028590\n",
            "Epoch 1836/2000, Rel Train Loss: 26.38%, Rel Val Loss: 29.76%\n",
            "Moving Avg Val Loss: 0.313202\n",
            "Epoch 1837/2000, Train Loss: 0.000343, Val Loss: 0.028962\n",
            "Epoch 1837/2000, Rel Train Loss: 39.53%, Rel Val Loss: 33.19%\n",
            "Moving Avg Val Loss: 0.311503\n",
            "Epoch 1838/2000, Train Loss: 0.000407, Val Loss: 0.027710\n",
            "Epoch 1838/2000, Rel Train Loss: 35.99%, Rel Val Loss: 27.98%\n",
            "Moving Avg Val Loss: 0.339674\n",
            "Epoch 1839/2000, Train Loss: 0.000409, Val Loss: 0.030593\n",
            "Epoch 1839/2000, Rel Train Loss: 28.81%, Rel Val Loss: 48.65%\n",
            "Moving Avg Val Loss: 0.345864\n",
            "Epoch 1840/2000, Train Loss: 0.000333, Val Loss: 0.031991\n",
            "Epoch 1840/2000, Rel Train Loss: 36.83%, Rel Val Loss: 33.35%\n",
            "Moving Avg Val Loss: 0.345186\n",
            "Epoch 1841/2000, Train Loss: 0.000344, Val Loss: 0.027727\n",
            "Epoch 1841/2000, Rel Train Loss: 28.56%, Rel Val Loss: 29.42%\n",
            "Moving Avg Val Loss: 0.348215\n",
            "Epoch 1842/2000, Train Loss: 0.000248, Val Loss: 0.029476\n",
            "Epoch 1842/2000, Rel Train Loss: 26.09%, Rel Val Loss: 34.70%\n",
            "Moving Avg Val Loss: 0.352717\n",
            "Epoch 1843/2000, Train Loss: 0.000441, Val Loss: 0.030284\n",
            "Epoch 1843/2000, Rel Train Loss: 30.28%, Rel Val Loss: 30.23%\n",
            "Moving Avg Val Loss: 0.333476\n",
            "Epoch 1844/2000, Train Loss: 0.000625, Val Loss: 0.027516\n",
            "Epoch 1844/2000, Rel Train Loss: 40.72%, Rel Val Loss: 39.03%\n",
            "Moving Avg Val Loss: 0.328721\n",
            "Epoch 1845/2000, Train Loss: 0.000431, Val Loss: 0.029415\n",
            "Epoch 1845/2000, Rel Train Loss: 25.37%, Rel Val Loss: 30.97%\n",
            "Moving Avg Val Loss: 0.360430\n",
            "Epoch 1846/2000, Train Loss: 0.000405, Val Loss: 0.030410\n",
            "Epoch 1846/2000, Rel Train Loss: 30.89%, Rel Val Loss: 45.28%\n",
            "Moving Avg Val Loss: 0.350369\n",
            "Epoch 1847/2000, Train Loss: 0.000408, Val Loss: 0.029904\n",
            "Epoch 1847/2000, Rel Train Loss: 28.76%, Rel Val Loss: 29.67%\n",
            "Moving Avg Val Loss: 0.351720\n",
            "Epoch 1848/2000, Train Loss: 0.000644, Val Loss: 0.027898\n",
            "Epoch 1848/2000, Rel Train Loss: 41.87%, Rel Val Loss: 30.91%\n",
            "Moving Avg Val Loss: 0.335834\n",
            "Epoch 1849/2000, Train Loss: 0.000460, Val Loss: 0.034502\n",
            "Epoch 1849/2000, Rel Train Loss: 33.43%, Rel Val Loss: 31.09%\n",
            "Moving Avg Val Loss: 0.340685\n",
            "Epoch 1850/2000, Train Loss: 0.000382, Val Loss: 0.028732\n",
            "Epoch 1850/2000, Rel Train Loss: 33.47%, Rel Val Loss: 33.39%\n",
            "Moving Avg Val Loss: 0.372534\n",
            "Epoch 1851/2000, Train Loss: 0.000648, Val Loss: 0.028267\n",
            "Epoch 1851/2000, Rel Train Loss: 38.51%, Rel Val Loss: 61.20%\n",
            "Moving Avg Val Loss: 0.377321\n",
            "Epoch 1852/2000, Train Loss: 0.000634, Val Loss: 0.032038\n",
            "Epoch 1852/2000, Rel Train Loss: 42.23%, Rel Val Loss: 32.07%\n",
            "Moving Avg Val Loss: 0.380788\n",
            "Epoch 1853/2000, Train Loss: 0.000673, Val Loss: 0.027122\n",
            "Epoch 1853/2000, Rel Train Loss: 33.96%, Rel Val Loss: 32.64%\n",
            "Moving Avg Val Loss: 0.442711\n",
            "Epoch 1854/2000, Train Loss: 0.000565, Val Loss: 0.030921\n",
            "Epoch 1854/2000, Rel Train Loss: 35.05%, Rel Val Loss: 62.05%\n",
            "Moving Avg Val Loss: 0.526347\n",
            "Epoch 1855/2000, Train Loss: 0.001954, Val Loss: 0.040647\n",
            "Epoch 1855/2000, Rel Train Loss: 56.84%, Rel Val Loss: 75.21%\n",
            "Moving Avg Val Loss: 0.635731\n",
            "Epoch 1856/2000, Train Loss: 0.002500, Val Loss: 0.025613\n",
            "Epoch 1856/2000, Rel Train Loss: 81.95%, Rel Val Loss: 115.89%\n",
            "Moving Avg Val Loss: 0.644344\n",
            "Epoch 1857/2000, Train Loss: 0.001088, Val Loss: 0.031956\n",
            "Epoch 1857/2000, Rel Train Loss: 70.07%, Rel Val Loss: 36.37%\n",
            "Moving Avg Val Loss: 0.811866\n",
            "Epoch 1858/2000, Train Loss: 0.002028, Val Loss: 0.031334\n",
            "Epoch 1858/2000, Rel Train Loss: 74.07%, Rel Val Loss: 116.40%\n",
            "Moving Avg Val Loss: 0.848302\n",
            "Epoch 1859/2000, Train Loss: 0.001509, Val Loss: 0.031167\n",
            "Epoch 1859/2000, Rel Train Loss: 81.56%, Rel Val Loss: 80.27%\n",
            "Moving Avg Val Loss: 0.763361\n",
            "Epoch 1860/2000, Train Loss: 0.000953, Val Loss: 0.033035\n",
            "Epoch 1860/2000, Rel Train Loss: 44.56%, Rel Val Loss: 32.74%\n",
            "Moving Avg Val Loss: 0.658250\n",
            "Epoch 1861/2000, Train Loss: 0.001510, Val Loss: 0.026166\n",
            "Epoch 1861/2000, Rel Train Loss: 48.44%, Rel Val Loss: 63.34%\n",
            "Moving Avg Val Loss: 0.691443\n",
            "Epoch 1862/2000, Train Loss: 0.001078, Val Loss: 0.032657\n",
            "Epoch 1862/2000, Rel Train Loss: 56.70%, Rel Val Loss: 52.97%\n",
            "Moving Avg Val Loss: 0.745729\n",
            "Epoch 1863/2000, Train Loss: 0.002828, Val Loss: 0.031149\n",
            "Epoch 1863/2000, Rel Train Loss: 87.69%, Rel Val Loss: 143.55%\n",
            "Moving Avg Val Loss: 0.672222\n",
            "Epoch 1864/2000, Train Loss: 0.004555, Val Loss: 0.035945\n",
            "Epoch 1864/2000, Rel Train Loss: 122.00%, Rel Val Loss: 43.51%\n",
            "Moving Avg Val Loss: 0.730678\n",
            "Epoch 1865/2000, Train Loss: 0.001991, Val Loss: 0.025936\n",
            "Epoch 1865/2000, Rel Train Loss: 83.94%, Rel Val Loss: 61.97%\n",
            "Moving Avg Val Loss: 0.698868\n",
            "Epoch 1866/2000, Train Loss: 0.001911, Val Loss: 0.036547\n",
            "Epoch 1866/2000, Rel Train Loss: 48.43%, Rel Val Loss: 47.43%\n",
            "Moving Avg Val Loss: 0.662528\n",
            "Epoch 1867/2000, Train Loss: 0.001942, Val Loss: 0.029053\n",
            "Epoch 1867/2000, Rel Train Loss: 71.79%, Rel Val Loss: 34.80%\n",
            "Moving Avg Val Loss: 0.463584\n",
            "Epoch 1868/2000, Train Loss: 0.001057, Val Loss: 0.033197\n",
            "Epoch 1868/2000, Rel Train Loss: 51.83%, Rel Val Loss: 44.08%\n",
            "Moving Avg Val Loss: 0.441960\n",
            "Epoch 1869/2000, Train Loss: 0.001502, Val Loss: 0.036682\n",
            "Epoch 1869/2000, Rel Train Loss: 47.13%, Rel Val Loss: 32.70%\n",
            "Moving Avg Val Loss: 0.473659\n",
            "Epoch 1870/2000, Train Loss: 0.003024, Val Loss: 0.026260\n",
            "Epoch 1870/2000, Rel Train Loss: 69.04%, Rel Val Loss: 77.82%\n",
            "Moving Avg Val Loss: 0.507479\n",
            "Epoch 1871/2000, Train Loss: 0.001846, Val Loss: 0.052792\n",
            "Epoch 1871/2000, Rel Train Loss: 49.59%, Rel Val Loss: 64.34%\n",
            "Moving Avg Val Loss: 0.594660\n",
            "Epoch 1872/2000, Train Loss: 0.004046, Val Loss: 0.025489\n",
            "Epoch 1872/2000, Rel Train Loss: 79.63%, Rel Val Loss: 78.39%\n",
            "Moving Avg Val Loss: 0.819853\n",
            "Epoch 1873/2000, Train Loss: 0.003786, Val Loss: 0.043864\n",
            "Epoch 1873/2000, Rel Train Loss: 91.40%, Rel Val Loss: 156.67%\n",
            "Moving Avg Val Loss: 0.876115\n",
            "Epoch 1874/2000, Train Loss: 0.005455, Val Loss: 0.030119\n",
            "Epoch 1874/2000, Rel Train Loss: 82.27%, Rel Val Loss: 60.83%\n",
            "Moving Avg Val Loss: 0.788436\n",
            "Epoch 1875/2000, Train Loss: 0.002294, Val Loss: 0.030746\n",
            "Epoch 1875/2000, Rel Train Loss: 74.81%, Rel Val Loss: 33.98%\n",
            "Moving Avg Val Loss: 0.734756\n",
            "Epoch 1876/2000, Train Loss: 0.002020, Val Loss: 0.029938\n",
            "Epoch 1876/2000, Rel Train Loss: 39.61%, Rel Val Loss: 37.50%\n",
            "Moving Avg Val Loss: 0.637090\n",
            "Epoch 1877/2000, Train Loss: 0.000525, Val Loss: 0.027151\n",
            "Epoch 1877/2000, Rel Train Loss: 33.10%, Rel Val Loss: 29.56%\n",
            "Moving Avg Val Loss: 0.381470\n",
            "Epoch 1878/2000, Train Loss: 0.000820, Val Loss: 0.030484\n",
            "Epoch 1878/2000, Rel Train Loss: 30.75%, Rel Val Loss: 28.86%\n",
            "Moving Avg Val Loss: 0.381383\n",
            "Epoch 1879/2000, Train Loss: 0.001203, Val Loss: 0.026166\n",
            "Epoch 1879/2000, Rel Train Loss: 39.20%, Rel Val Loss: 60.79%\n",
            "Moving Avg Val Loss: 0.389799\n",
            "Epoch 1880/2000, Train Loss: 0.001245, Val Loss: 0.028084\n",
            "Epoch 1880/2000, Rel Train Loss: 65.15%, Rel Val Loss: 38.19%\n",
            "Moving Avg Val Loss: 0.381491\n",
            "Epoch 1881/2000, Train Loss: 0.000870, Val Loss: 0.031533\n",
            "Epoch 1881/2000, Rel Train Loss: 43.62%, Rel Val Loss: 33.35%\n",
            "Moving Avg Val Loss: 0.408596\n",
            "Epoch 1882/2000, Train Loss: 0.001820, Val Loss: 0.023277\n",
            "Epoch 1882/2000, Rel Train Loss: 36.62%, Rel Val Loss: 43.11%\n",
            "Moving Avg Val Loss: 0.417644\n",
            "Epoch 1883/2000, Train Loss: 0.001718, Val Loss: 0.028017\n",
            "Epoch 1883/2000, Rel Train Loss: 42.02%, Rel Val Loss: 33.39%\n",
            "Moving Avg Val Loss: 0.424809\n",
            "Epoch 1884/2000, Train Loss: 0.003316, Val Loss: 0.032554\n",
            "Epoch 1884/2000, Rel Train Loss: 36.10%, Rel Val Loss: 64.37%\n",
            "Moving Avg Val Loss: 0.468564\n",
            "Epoch 1885/2000, Train Loss: 0.002681, Val Loss: 0.022637\n",
            "Epoch 1885/2000, Rel Train Loss: 73.11%, Rel Val Loss: 60.07%\n",
            "Moving Avg Val Loss: 0.514326\n",
            "Epoch 1886/2000, Train Loss: 0.002936, Val Loss: 0.038803\n",
            "Epoch 1886/2000, Rel Train Loss: 58.59%, Rel Val Loss: 56.23%\n",
            "Moving Avg Val Loss: 0.558865\n",
            "Epoch 1887/2000, Train Loss: 0.002236, Val Loss: 0.025016\n",
            "Epoch 1887/2000, Rel Train Loss: 60.55%, Rel Val Loss: 65.38%\n",
            "Moving Avg Val Loss: 0.585411\n",
            "Epoch 1888/2000, Train Loss: 0.001603, Val Loss: 0.035252\n",
            "Epoch 1888/2000, Rel Train Loss: 72.02%, Rel Val Loss: 46.66%\n",
            "Moving Avg Val Loss: 0.552271\n",
            "Epoch 1889/2000, Train Loss: 0.001380, Val Loss: 0.027255\n",
            "Epoch 1889/2000, Rel Train Loss: 44.67%, Rel Val Loss: 47.80%\n",
            "Moving Avg Val Loss: 0.515971\n",
            "Epoch 1890/2000, Train Loss: 0.000841, Val Loss: 0.031326\n",
            "Epoch 1890/2000, Rel Train Loss: 47.25%, Rel Val Loss: 41.91%\n",
            "Moving Avg Val Loss: 0.475424\n",
            "Epoch 1891/2000, Train Loss: 0.000984, Val Loss: 0.029603\n",
            "Epoch 1891/2000, Rel Train Loss: 44.35%, Rel Val Loss: 35.96%\n",
            "Moving Avg Val Loss: 0.410460\n",
            "Epoch 1892/2000, Train Loss: 0.000496, Val Loss: 0.027894\n",
            "Epoch 1892/2000, Rel Train Loss: 36.41%, Rel Val Loss: 32.90%\n",
            "Moving Avg Val Loss: 0.386432\n",
            "Epoch 1893/2000, Train Loss: 0.000643, Val Loss: 0.028317\n",
            "Epoch 1893/2000, Rel Train Loss: 32.71%, Rel Val Loss: 34.65%\n",
            "Moving Avg Val Loss: 0.372626\n",
            "Epoch 1894/2000, Train Loss: 0.001083, Val Loss: 0.028135\n",
            "Epoch 1894/2000, Rel Train Loss: 52.42%, Rel Val Loss: 40.90%\n",
            "Moving Avg Val Loss: 0.373580\n",
            "Epoch 1895/2000, Train Loss: 0.000826, Val Loss: 0.026713\n",
            "Epoch 1895/2000, Rel Train Loss: 44.74%, Rel Val Loss: 42.39%\n",
            "Moving Avg Val Loss: 0.359915\n",
            "Epoch 1896/2000, Train Loss: 0.000521, Val Loss: 0.028733\n",
            "Epoch 1896/2000, Rel Train Loss: 28.80%, Rel Val Loss: 29.13%\n",
            "Moving Avg Val Loss: 0.380413\n",
            "Epoch 1897/2000, Train Loss: 0.000478, Val Loss: 0.026083\n",
            "Epoch 1897/2000, Rel Train Loss: 36.48%, Rel Val Loss: 43.15%\n",
            "Moving Avg Val Loss: 0.380321\n",
            "Epoch 1898/2000, Train Loss: 0.000532, Val Loss: 0.028370\n",
            "Epoch 1898/2000, Rel Train Loss: 39.53%, Rel Val Loss: 34.60%\n",
            "Moving Avg Val Loss: 0.353984\n",
            "Epoch 1899/2000, Train Loss: 0.000358, Val Loss: 0.026558\n",
            "Epoch 1899/2000, Rel Train Loss: 35.20%, Rel Val Loss: 27.73%\n",
            "Moving Avg Val Loss: 0.325243\n",
            "Epoch 1900/2000, Train Loss: 0.000259, Val Loss: 0.026955\n",
            "Epoch 1900/2000, Rel Train Loss: 29.08%, Rel Val Loss: 28.02%\n",
            "Moving Avg Val Loss: 0.338864\n",
            "Epoch 1901/2000, Train Loss: 0.000273, Val Loss: 0.026698\n",
            "Epoch 1901/2000, Rel Train Loss: 28.32%, Rel Val Loss: 35.94%\n",
            "Moving Avg Val Loss: 0.304725\n",
            "Epoch 1902/2000, Train Loss: 0.000373, Val Loss: 0.026708\n",
            "Epoch 1902/2000, Rel Train Loss: 30.25%, Rel Val Loss: 26.08%\n",
            "Moving Avg Val Loss: 0.291481\n",
            "Epoch 1903/2000, Train Loss: 0.000293, Val Loss: 0.026973\n",
            "Epoch 1903/2000, Rel Train Loss: 26.54%, Rel Val Loss: 27.98%\n",
            "Moving Avg Val Loss: 0.291799\n",
            "Epoch 1904/2000, Train Loss: 0.000260, Val Loss: 0.026539\n",
            "Epoch 1904/2000, Rel Train Loss: 25.17%, Rel Val Loss: 27.89%\n",
            "Moving Avg Val Loss: 0.293693\n",
            "Epoch 1905/2000, Train Loss: 0.000216, Val Loss: 0.026157\n",
            "Epoch 1905/2000, Rel Train Loss: 25.37%, Rel Val Loss: 28.97%\n",
            "Moving Avg Val Loss: 0.282339\n",
            "Epoch 1906/2000, Train Loss: 0.000338, Val Loss: 0.028165\n",
            "Epoch 1906/2000, Rel Train Loss: 26.18%, Rel Val Loss: 30.26%\n",
            "Moving Avg Val Loss: 0.284523\n",
            "Epoch 1907/2000, Train Loss: 0.000300, Val Loss: 0.025881\n",
            "Epoch 1907/2000, Rel Train Loss: 35.29%, Rel Val Loss: 27.17%\n",
            "Moving Avg Val Loss: 0.282664\n",
            "Epoch 1908/2000, Train Loss: 0.000332, Val Loss: 0.028846\n",
            "Epoch 1908/2000, Rel Train Loss: 26.86%, Rel Val Loss: 27.05%\n",
            "Moving Avg Val Loss: 0.288525\n",
            "Epoch 1909/2000, Train Loss: 0.000358, Val Loss: 0.024933\n",
            "Epoch 1909/2000, Rel Train Loss: 31.24%, Rel Val Loss: 30.82%\n",
            "Moving Avg Val Loss: 0.373113\n",
            "Epoch 1910/2000, Train Loss: 0.002350, Val Loss: 0.034776\n",
            "Epoch 1910/2000, Rel Train Loss: 34.36%, Rel Val Loss: 71.26%\n",
            "Moving Avg Val Loss: 0.390914\n",
            "Epoch 1911/2000, Train Loss: 0.001290, Val Loss: 0.024673\n",
            "Epoch 1911/2000, Rel Train Loss: 52.76%, Rel Val Loss: 39.16%\n",
            "Moving Avg Val Loss: 0.452746\n",
            "Epoch 1912/2000, Train Loss: 0.001127, Val Loss: 0.035645\n",
            "Epoch 1912/2000, Rel Train Loss: 38.07%, Rel Val Loss: 58.08%\n",
            "Moving Avg Val Loss: 0.472912\n",
            "Epoch 1913/2000, Train Loss: 0.005236, Val Loss: 0.032854\n",
            "Epoch 1913/2000, Rel Train Loss: 92.92%, Rel Val Loss: 37.13%\n",
            "Moving Avg Val Loss: 0.798109\n",
            "Epoch 1914/2000, Train Loss: 0.005472, Val Loss: 0.031774\n",
            "Epoch 1914/2000, Rel Train Loss: 78.10%, Rel Val Loss: 193.42%\n",
            "Moving Avg Val Loss: 0.855435\n",
            "Epoch 1915/2000, Train Loss: 0.004183, Val Loss: 0.040294\n",
            "Epoch 1915/2000, Rel Train Loss: 159.09%, Rel Val Loss: 99.93%\n",
            "Moving Avg Val Loss: 0.975966\n",
            "Epoch 1916/2000, Train Loss: 0.005595, Val Loss: 0.032606\n",
            "Epoch 1916/2000, Rel Train Loss: 127.36%, Rel Val Loss: 99.43%\n",
            "Moving Avg Val Loss: 1.117063\n",
            "Epoch 1917/2000, Train Loss: 0.008214, Val Loss: 0.043928\n",
            "Epoch 1917/2000, Rel Train Loss: 96.34%, Rel Val Loss: 128.63%\n",
            "Moving Avg Val Loss: 1.382715\n",
            "Epoch 1918/2000, Train Loss: 0.007867, Val Loss: 0.035041\n",
            "Epoch 1918/2000, Rel Train Loss: 112.24%, Rel Val Loss: 169.96%\n",
            "Moving Avg Val Loss: 1.108709\n",
            "Epoch 1919/2000, Train Loss: 0.002757, Val Loss: 0.038751\n",
            "Epoch 1919/2000, Rel Train Loss: 91.88%, Rel Val Loss: 56.41%\n",
            "Moving Avg Val Loss: 1.009720\n",
            "Epoch 1920/2000, Train Loss: 0.001250, Val Loss: 0.023385\n",
            "Epoch 1920/2000, Rel Train Loss: 52.65%, Rel Val Loss: 50.43%\n",
            "Moving Avg Val Loss: 0.921564\n",
            "Epoch 1921/2000, Train Loss: 0.001263, Val Loss: 0.032089\n",
            "Epoch 1921/2000, Rel Train Loss: 46.89%, Rel Val Loss: 55.35%\n",
            "Moving Avg Val Loss: 0.745138\n",
            "Epoch 1922/2000, Train Loss: 0.001350, Val Loss: 0.021221\n",
            "Epoch 1922/2000, Rel Train Loss: 48.20%, Rel Val Loss: 40.42%\n",
            "Moving Avg Val Loss: 0.478452\n",
            "Epoch 1923/2000, Train Loss: 0.001111, Val Loss: 0.033221\n",
            "Epoch 1923/2000, Rel Train Loss: 42.41%, Rel Val Loss: 36.61%\n",
            "Moving Avg Val Loss: 0.443339\n",
            "Epoch 1924/2000, Train Loss: 0.000790, Val Loss: 0.024758\n",
            "Epoch 1924/2000, Rel Train Loss: 38.36%, Rel Val Loss: 38.86%\n",
            "Moving Avg Val Loss: 0.399468\n",
            "Epoch 1925/2000, Train Loss: 0.000707, Val Loss: 0.027002\n",
            "Epoch 1925/2000, Rel Train Loss: 32.93%, Rel Val Loss: 28.50%\n",
            "Moving Avg Val Loss: 0.345848\n",
            "Epoch 1926/2000, Train Loss: 0.000543, Val Loss: 0.026548\n",
            "Epoch 1926/2000, Rel Train Loss: 32.07%, Rel Val Loss: 28.54%\n",
            "Moving Avg Val Loss: 0.320459\n",
            "Epoch 1927/2000, Train Loss: 0.000327, Val Loss: 0.026366\n",
            "Epoch 1927/2000, Rel Train Loss: 30.91%, Rel Val Loss: 27.73%\n",
            "Moving Avg Val Loss: 0.310413\n",
            "Epoch 1928/2000, Train Loss: 0.000250, Val Loss: 0.026010\n",
            "Epoch 1928/2000, Rel Train Loss: 30.84%, Rel Val Loss: 31.59%\n",
            "Moving Avg Val Loss: 0.288182\n",
            "Epoch 1929/2000, Train Loss: 0.000249, Val Loss: 0.026523\n",
            "Epoch 1929/2000, Rel Train Loss: 26.35%, Rel Val Loss: 27.74%\n",
            "Moving Avg Val Loss: 0.282425\n",
            "Epoch 1930/2000, Train Loss: 0.000253, Val Loss: 0.026151\n",
            "Epoch 1930/2000, Rel Train Loss: 25.70%, Rel Val Loss: 25.62%\n",
            "Moving Avg Val Loss: 0.278805\n",
            "Epoch 1931/2000, Train Loss: 0.000238, Val Loss: 0.025938\n",
            "Epoch 1931/2000, Rel Train Loss: 26.40%, Rel Val Loss: 26.73%\n",
            "Moving Avg Val Loss: 0.278138\n",
            "Epoch 1932/2000, Train Loss: 0.000239, Val Loss: 0.026315\n",
            "Epoch 1932/2000, Rel Train Loss: 28.85%, Rel Val Loss: 27.39%\n",
            "Moving Avg Val Loss: 0.281846\n",
            "Epoch 1933/2000, Train Loss: 0.000255, Val Loss: 0.026112\n",
            "Epoch 1933/2000, Rel Train Loss: 26.13%, Rel Val Loss: 33.45%\n",
            "Moving Avg Val Loss: 0.291087\n",
            "Epoch 1934/2000, Train Loss: 0.000426, Val Loss: 0.026406\n",
            "Epoch 1934/2000, Rel Train Loss: 30.64%, Rel Val Loss: 32.36%\n",
            "Moving Avg Val Loss: 0.299991\n",
            "Epoch 1935/2000, Train Loss: 0.000543, Val Loss: 0.029783\n",
            "Epoch 1935/2000, Rel Train Loss: 33.49%, Rel Val Loss: 30.07%\n",
            "Moving Avg Val Loss: 0.308180\n",
            "Epoch 1936/2000, Train Loss: 0.000888, Val Loss: 0.024707\n",
            "Epoch 1936/2000, Rel Train Loss: 39.27%, Rel Val Loss: 30.82%\n",
            "Moving Avg Val Loss: 0.312929\n",
            "Epoch 1937/2000, Train Loss: 0.000415, Val Loss: 0.028136\n",
            "Epoch 1937/2000, Rel Train Loss: 34.24%, Rel Val Loss: 29.77%\n",
            "Moving Avg Val Loss: 0.303865\n",
            "Epoch 1938/2000, Train Loss: 0.000306, Val Loss: 0.026195\n",
            "Epoch 1938/2000, Rel Train Loss: 27.57%, Rel Val Loss: 28.91%\n",
            "Moving Avg Val Loss: 0.294014\n",
            "Epoch 1939/2000, Train Loss: 0.000266, Val Loss: 0.026182\n",
            "Epoch 1939/2000, Rel Train Loss: 29.90%, Rel Val Loss: 27.44%\n",
            "Moving Avg Val Loss: 0.288098\n",
            "Epoch 1940/2000, Train Loss: 0.000220, Val Loss: 0.027449\n",
            "Epoch 1940/2000, Rel Train Loss: 25.12%, Rel Val Loss: 27.11%\n",
            "Moving Avg Val Loss: 0.285317\n",
            "Epoch 1941/2000, Train Loss: 0.000206, Val Loss: 0.026312\n",
            "Epoch 1941/2000, Rel Train Loss: 26.55%, Rel Val Loss: 29.43%\n",
            "Moving Avg Val Loss: 0.279242\n",
            "Epoch 1942/2000, Train Loss: 0.000207, Val Loss: 0.026294\n",
            "Epoch 1942/2000, Rel Train Loss: 27.96%, Rel Val Loss: 26.73%\n",
            "Moving Avg Val Loss: 0.273748\n",
            "Epoch 1943/2000, Train Loss: 0.000183, Val Loss: 0.026435\n",
            "Epoch 1943/2000, Rel Train Loss: 26.14%, Rel Val Loss: 26.17%\n",
            "Moving Avg Val Loss: 0.271624\n",
            "Epoch 1944/2000, Train Loss: 0.000187, Val Loss: 0.026478\n",
            "Epoch 1944/2000, Rel Train Loss: 26.55%, Rel Val Loss: 26.37%\n",
            "Moving Avg Val Loss: 0.271541\n",
            "Epoch 1945/2000, Train Loss: 0.000192, Val Loss: 0.025991\n",
            "Epoch 1945/2000, Rel Train Loss: 26.81%, Rel Val Loss: 27.07%\n",
            "Moving Avg Val Loss: 0.272774\n",
            "Epoch 1946/2000, Train Loss: 0.000291, Val Loss: 0.027437\n",
            "Epoch 1946/2000, Rel Train Loss: 27.09%, Rel Val Loss: 30.05%\n",
            "Moving Avg Val Loss: 0.275543\n",
            "Epoch 1947/2000, Train Loss: 0.000275, Val Loss: 0.024320\n",
            "Epoch 1947/2000, Rel Train Loss: 27.52%, Rel Val Loss: 28.11%\n",
            "Moving Avg Val Loss: 0.280125\n",
            "Epoch 1948/2000, Train Loss: 0.000464, Val Loss: 0.027596\n",
            "Epoch 1948/2000, Rel Train Loss: 28.08%, Rel Val Loss: 28.46%\n",
            "Moving Avg Val Loss: 0.299538\n",
            "Epoch 1949/2000, Train Loss: 0.000562, Val Loss: 0.026789\n",
            "Epoch 1949/2000, Rel Train Loss: 40.13%, Rel Val Loss: 36.08%\n",
            "Moving Avg Val Loss: 0.342434\n",
            "Epoch 1950/2000, Train Loss: 0.000678, Val Loss: 0.027702\n",
            "Epoch 1950/2000, Rel Train Loss: 37.80%, Rel Val Loss: 48.52%\n",
            "Moving Avg Val Loss: 0.355969\n",
            "Epoch 1951/2000, Train Loss: 0.000724, Val Loss: 0.030677\n",
            "Epoch 1951/2000, Rel Train Loss: 36.19%, Rel Val Loss: 36.82%\n",
            "Moving Avg Val Loss: 0.384492\n",
            "Epoch 1952/2000, Train Loss: 0.000667, Val Loss: 0.023569\n",
            "Epoch 1952/2000, Rel Train Loss: 34.04%, Rel Val Loss: 42.37%\n",
            "Moving Avg Val Loss: 0.433268\n",
            "Epoch 1953/2000, Train Loss: 0.000635, Val Loss: 0.026769\n",
            "Epoch 1953/2000, Rel Train Loss: 30.55%, Rel Val Loss: 52.85%\n",
            "Moving Avg Val Loss: 0.420786\n",
            "Epoch 1954/2000, Train Loss: 0.000416, Val Loss: 0.028553\n",
            "Epoch 1954/2000, Rel Train Loss: 35.30%, Rel Val Loss: 29.84%\n",
            "Moving Avg Val Loss: 0.392722\n",
            "Epoch 1955/2000, Train Loss: 0.001225, Val Loss: 0.027419\n",
            "Epoch 1955/2000, Rel Train Loss: 37.12%, Rel Val Loss: 34.49%\n",
            "Moving Avg Val Loss: 0.395104\n",
            "Epoch 1956/2000, Train Loss: 0.001109, Val Loss: 0.025518\n",
            "Epoch 1956/2000, Rel Train Loss: 30.82%, Rel Val Loss: 38.01%\n",
            "Moving Avg Val Loss: 0.530625\n",
            "Epoch 1957/2000, Train Loss: 0.003227, Val Loss: 0.035858\n",
            "Epoch 1957/2000, Rel Train Loss: 53.57%, Rel Val Loss: 110.14%\n",
            "Moving Avg Val Loss: 0.555756\n",
            "Epoch 1958/2000, Train Loss: 0.003507, Val Loss: 0.025599\n",
            "Epoch 1958/2000, Rel Train Loss: 99.30%, Rel Val Loss: 65.41%\n",
            "Moving Avg Val Loss: 0.615700\n",
            "Epoch 1959/2000, Train Loss: 0.002362, Val Loss: 0.032549\n",
            "Epoch 1959/2000, Rel Train Loss: 62.16%, Rel Val Loss: 59.81%\n",
            "Moving Avg Val Loss: 0.607184\n",
            "Epoch 1960/2000, Train Loss: 0.001826, Val Loss: 0.022924\n",
            "Epoch 1960/2000, Rel Train Loss: 49.71%, Rel Val Loss: 30.23%\n",
            "Moving Avg Val Loss: 0.599599\n",
            "Epoch 1961/2000, Train Loss: 0.001429, Val Loss: 0.029938\n",
            "Epoch 1961/2000, Rel Train Loss: 48.76%, Rel Val Loss: 34.21%\n",
            "Moving Avg Val Loss: 0.484213\n",
            "Epoch 1962/2000, Train Loss: 0.000903, Val Loss: 0.029587\n",
            "Epoch 1962/2000, Rel Train Loss: 50.75%, Rel Val Loss: 52.44%\n",
            "Moving Avg Val Loss: 0.419980\n",
            "Epoch 1963/2000, Train Loss: 0.000707, Val Loss: 0.024143\n",
            "Epoch 1963/2000, Rel Train Loss: 40.89%, Rel Val Loss: 33.29%\n",
            "Moving Avg Val Loss: 0.464520\n",
            "Epoch 1964/2000, Train Loss: 0.002428, Val Loss: 0.038543\n",
            "Epoch 1964/2000, Rel Train Loss: 35.17%, Rel Val Loss: 82.08%\n",
            "Moving Avg Val Loss: 0.499799\n",
            "Epoch 1965/2000, Train Loss: 0.002247, Val Loss: 0.029003\n",
            "Epoch 1965/2000, Rel Train Loss: 54.61%, Rel Val Loss: 47.87%\n",
            "Moving Avg Val Loss: 0.503051\n",
            "Epoch 1966/2000, Train Loss: 0.000830, Val Loss: 0.025032\n",
            "Epoch 1966/2000, Rel Train Loss: 43.98%, Rel Val Loss: 35.84%\n",
            "Moving Avg Val Loss: 0.468319\n",
            "Epoch 1967/2000, Train Loss: 0.001162, Val Loss: 0.035459\n",
            "Epoch 1967/2000, Rel Train Loss: 38.91%, Rel Val Loss: 35.08%\n",
            "Moving Avg Val Loss: 0.536319\n",
            "Epoch 1968/2000, Train Loss: 0.002174, Val Loss: 0.024277\n",
            "Epoch 1968/2000, Rel Train Loss: 51.29%, Rel Val Loss: 67.29%\n",
            "Moving Avg Val Loss: 0.452057\n",
            "Epoch 1969/2000, Train Loss: 0.001080, Val Loss: 0.034857\n",
            "Epoch 1969/2000, Rel Train Loss: 54.34%, Rel Val Loss: 39.95%\n",
            "Moving Avg Val Loss: 0.458835\n",
            "Epoch 1970/2000, Train Loss: 0.001682, Val Loss: 0.021744\n",
            "Epoch 1970/2000, Rel Train Loss: 49.38%, Rel Val Loss: 51.26%\n",
            "Moving Avg Val Loss: 0.475618\n",
            "Epoch 1971/2000, Train Loss: 0.001649, Val Loss: 0.040224\n",
            "Epoch 1971/2000, Rel Train Loss: 55.20%, Rel Val Loss: 44.23%\n",
            "Moving Avg Val Loss: 0.611342\n",
            "Epoch 1972/2000, Train Loss: 0.002409, Val Loss: 0.028370\n",
            "Epoch 1972/2000, Rel Train Loss: 72.35%, Rel Val Loss: 102.94%\n",
            "Moving Avg Val Loss: 0.584446\n",
            "Epoch 1973/2000, Train Loss: 0.003465, Val Loss: 0.034026\n",
            "Epoch 1973/2000, Rel Train Loss: 64.63%, Rel Val Loss: 53.85%\n",
            "Moving Avg Val Loss: 0.609735\n",
            "Epoch 1974/2000, Train Loss: 0.002559, Val Loss: 0.031295\n",
            "Epoch 1974/2000, Rel Train Loss: 59.43%, Rel Val Loss: 52.59%\n",
            "Moving Avg Val Loss: 0.606074\n",
            "Epoch 1975/2000, Train Loss: 0.000857, Val Loss: 0.024225\n",
            "Epoch 1975/2000, Rel Train Loss: 47.73%, Rel Val Loss: 49.43%\n",
            "Moving Avg Val Loss: 0.593240\n",
            "Epoch 1976/2000, Train Loss: 0.000974, Val Loss: 0.028643\n",
            "Epoch 1976/2000, Rel Train Loss: 39.60%, Rel Val Loss: 37.81%\n",
            "Moving Avg Val Loss: 0.451190\n",
            "Epoch 1977/2000, Train Loss: 0.000581, Val Loss: 0.027729\n",
            "Epoch 1977/2000, Rel Train Loss: 36.52%, Rel Val Loss: 31.91%\n",
            "Moving Avg Val Loss: 0.412004\n",
            "Epoch 1978/2000, Train Loss: 0.000463, Val Loss: 0.025869\n",
            "Epoch 1978/2000, Rel Train Loss: 37.07%, Rel Val Loss: 34.25%\n",
            "Moving Avg Val Loss: 0.384848\n",
            "Epoch 1979/2000, Train Loss: 0.000648, Val Loss: 0.025352\n",
            "Epoch 1979/2000, Rel Train Loss: 33.45%, Rel Val Loss: 39.02%\n",
            "Moving Avg Val Loss: 0.350329\n",
            "Epoch 1980/2000, Train Loss: 0.000869, Val Loss: 0.027658\n",
            "Epoch 1980/2000, Rel Train Loss: 44.28%, Rel Val Loss: 32.17%\n",
            "Moving Avg Val Loss: 0.333034\n",
            "Epoch 1981/2000, Train Loss: 0.000779, Val Loss: 0.027562\n",
            "Epoch 1981/2000, Rel Train Loss: 34.87%, Rel Val Loss: 29.17%\n",
            "Moving Avg Val Loss: 0.361358\n",
            "Epoch 1982/2000, Train Loss: 0.000460, Val Loss: 0.027473\n",
            "Epoch 1982/2000, Rel Train Loss: 40.72%, Rel Val Loss: 46.08%\n",
            "Moving Avg Val Loss: 0.346277\n",
            "Epoch 1983/2000, Train Loss: 0.000761, Val Loss: 0.026792\n",
            "Epoch 1983/2000, Rel Train Loss: 28.58%, Rel Val Loss: 26.71%\n",
            "Moving Avg Val Loss: 0.360684\n",
            "Epoch 1984/2000, Train Loss: 0.000531, Val Loss: 0.026767\n",
            "Epoch 1984/2000, Rel Train Loss: 29.14%, Rel Val Loss: 46.22%\n",
            "Moving Avg Val Loss: 0.355526\n",
            "Epoch 1985/2000, Train Loss: 0.000701, Val Loss: 0.029480\n",
            "Epoch 1985/2000, Rel Train Loss: 35.97%, Rel Val Loss: 29.59%\n",
            "Moving Avg Val Loss: 0.403109\n",
            "Epoch 1986/2000, Train Loss: 0.000756, Val Loss: 0.029476\n",
            "Epoch 1986/2000, Rel Train Loss: 36.06%, Rel Val Loss: 52.96%\n",
            "Moving Avg Val Loss: 0.387190\n",
            "Epoch 1987/2000, Train Loss: 0.002202, Val Loss: 0.025902\n",
            "Epoch 1987/2000, Rel Train Loss: 71.08%, Rel Val Loss: 38.12%\n",
            "Moving Avg Val Loss: 0.447480\n",
            "Epoch 1988/2000, Train Loss: 0.001405, Val Loss: 0.025755\n",
            "Epoch 1988/2000, Rel Train Loss: 59.50%, Rel Val Loss: 56.86%\n",
            "Moving Avg Val Loss: 0.445323\n",
            "Epoch 1989/2000, Train Loss: 0.001493, Val Loss: 0.029288\n",
            "Epoch 1989/2000, Rel Train Loss: 44.36%, Rel Val Loss: 45.14%\n",
            "Moving Avg Val Loss: 0.444421\n",
            "Epoch 1990/2000, Train Loss: 0.000561, Val Loss: 0.027405\n",
            "Epoch 1990/2000, Rel Train Loss: 30.76%, Rel Val Loss: 29.14%\n",
            "Moving Avg Val Loss: 0.395879\n",
            "Epoch 1991/2000, Train Loss: 0.000817, Val Loss: 0.027298\n",
            "Epoch 1991/2000, Rel Train Loss: 34.04%, Rel Val Loss: 28.69%\n",
            "Moving Avg Val Loss: 0.383309\n",
            "Epoch 1992/2000, Train Loss: 0.001483, Val Loss: 0.028669\n",
            "Epoch 1992/2000, Rel Train Loss: 50.70%, Rel Val Loss: 31.83%\n",
            "Moving Avg Val Loss: 0.380595\n",
            "Epoch 1993/2000, Train Loss: 0.001667, Val Loss: 0.026637\n",
            "Epoch 1993/2000, Rel Train Loss: 53.44%, Rel Val Loss: 55.50%\n",
            "Moving Avg Val Loss: 0.407518\n",
            "Epoch 1994/2000, Train Loss: 0.001151, Val Loss: 0.034011\n",
            "Epoch 1994/2000, Rel Train Loss: 56.40%, Rel Val Loss: 58.60%\n",
            "Moving Avg Val Loss: 0.428025\n",
            "Epoch 1995/2000, Train Loss: 0.001166, Val Loss: 0.022557\n",
            "Epoch 1995/2000, Rel Train Loss: 42.19%, Rel Val Loss: 39.39%\n",
            "Moving Avg Val Loss: 0.467881\n",
            "Epoch 1996/2000, Train Loss: 0.001057, Val Loss: 0.035754\n",
            "Epoch 1996/2000, Rel Train Loss: 56.72%, Rel Val Loss: 48.62%\n",
            "Moving Avg Val Loss: 0.477963\n",
            "Epoch 1997/2000, Train Loss: 0.001461, Val Loss: 0.027205\n",
            "Epoch 1997/2000, Rel Train Loss: 53.42%, Rel Val Loss: 36.87%\n",
            "Moving Avg Val Loss: 0.440345\n",
            "Epoch 1998/2000, Train Loss: 0.000479, Val Loss: 0.027036\n",
            "Epoch 1998/2000, Rel Train Loss: 31.92%, Rel Val Loss: 36.69%\n",
            "Moving Avg Val Loss: 0.378251\n",
            "Epoch 1999/2000, Train Loss: 0.000376, Val Loss: 0.025851\n",
            "Epoch 1999/2000, Rel Train Loss: 27.86%, Rel Val Loss: 27.56%\n",
            "Moving Avg Val Loss: 0.354176\n",
            "Epoch 2000/2000, Train Loss: 0.000252, Val Loss: 0.026828\n",
            "Epoch 2000/2000, Rel Train Loss: 26.74%, Rel Val Loss: 27.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Plot Train & Validation Loss === (Add this after training loop)\n",
        "\n",
        "\n",
        "# Plot the updated lists\n",
        "plt.plot([100* x for x in train_relative_loss_history], label=\"Training Loss\")\n",
        "plt.plot([100 * x for x in valid_relative_loss_history], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Relative Loss (%)\")\n",
        "plt.title(\"Training & Validation Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9eTsSTQraA8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "168d8352-560e-4388-9384-cffbfad06931"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(Y_train.flatten().cpu().numpy(), bins=50, alpha=0.5, label=\"Train\")\n",
        "plt.hist(Y_val.flatten().cpu().numpy(), bins=50, alpha=0.5, label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-a1WynhyZQiM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "1c572cc6-1199-4427-cb80-ff17618e8cbf"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Test Model Performance ===\n",
        "model.eval()  # Set model to evaluation mode\n",
        "total_test_loss = 0\n",
        "total_absolute_error = 0\n",
        "total_relative_error = 0\n",
        "epsilon = 1e-8  # To avoid division by zero\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_inputs, test_targets in test_loader:\n",
        "        test_inputs, test_targets = test_inputs.to(\"cuda\"), test_targets.to(\"cuda\")\n",
        "        test_outputs = model(test_inputs)\n",
        "\n",
        "        # Compute MSE Loss\n",
        "        test_loss = criterion(test_outputs, test_targets)\n",
        "        total_test_loss += test_loss.item()\n",
        "\n",
        "        # Compute MAE (Mean Absolute Error)\n",
        "        mae = torch.abs(test_outputs - test_targets).mean().item()\n",
        "        total_absolute_error += mae\n",
        "\n",
        "        # Compute Relative Error\n",
        "        relative_error = (torch.abs(test_outputs - test_targets) / (torch.abs(test_targets) + epsilon)).mean().item()\n",
        "        total_relative_error += relative_error\n",
        "\n",
        "# Compute average test loss\n",
        "avg_test_loss = total_test_loss / len(test_loader)\n",
        "avg_test_mae = total_absolute_error / len(test_loader)\n",
        "avg_test_relative_error = total_relative_error / len(test_loader)\n",
        "\n",
        "print(f\" Test MSE Loss: {avg_test_loss:.6f}\")\n",
        "print(f\" Test MAE (Mean Absolute Error): {avg_test_mae:.6f}\")\n",
        "print(f\" Test Relative Error: {avg_test_relative_error:.6f}\")\n"
      ],
      "metadata": {
        "id": "WaCxu7HLkR1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63e2322-d39b-48ca-f1ed-b6585b569690"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test MSE Loss: 0.004179\n",
            " Test MAE (Mean Absolute Error): 0.019485\n",
            " Test Relative Error: 0.277595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy.random as random\n",
        "\n",
        "# === Select a random test sample ===\n",
        "# Select a random test sample\n",
        "sample_idx = random.randint(0, len(test_dataset) - 1) # Change this index to visualize different test samples\n",
        "\n",
        "# Get the test input and target\n",
        "test_sample, target_sample = test_dataset[sample_idx]  # Assuming test_dataset is a TensorDataset\n",
        "test_sample = test_sample.unsqueeze(0).to(\"cuda\")  # Add batch dimension\n",
        "\n",
        "# Get model prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model(test_sample).cpu().squeeze(0)  # Remove batch dimension\n",
        "\n",
        "# Move target to CPU for plotting\n",
        "target_sample = target_sample.cpu()\n",
        "\n",
        "# Compute the difference (absolute error)\n",
        "# Compute the relative error\n",
        "epsilon = 1e-8  # Small constant to prevent division by zero\n",
        "difference = torch.abs(prediction - target_sample) #/ (torch.abs(target_sample) + epsilon)\n",
        "\n",
        "\n",
        "# === Plotting ===\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the target\n",
        "im1 = axes[0].imshow(target_sample[-1].numpy(), cmap=\"viridis\")\n",
        "axes[0].set_title(\"Ground Truth (Target)\")\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# Plot the prediction\n",
        "im2 = axes[1].imshow(prediction[-1].numpy(), cmap=\"viridis\")\n",
        "axes[1].set_title(\"Model Prediction\")\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "# Plot the absolute error\n",
        "im3 = axes[2].imshow( difference[-1].numpy(), cmap=\"inferno\")\n",
        "axes[2].set_title(\"Difference (Absolute Error)\")\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yBbugKtDmwC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "85d85a34-4adc-48b2-ba41-21e00259aede"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABNgAAAGbCAYAAAAWQi0ZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAq/FJREFUeJzs3XlcVFX/B/DPHXaFAVEWMRS3xB3DJMzSkgK1jDK3LJdMqycqpSztMcGsR8u10iQr03okyxZ/pkYRaj5P4h6Vpqam4ja4sss29/7+8JnJkRmYc+cOovN597qv5M75nntmGO537pl7zpEURVFAREREREREREREquiudQOIiIiIiIiIiIiuZ+xgIyIiIiIiIiIicgA72IiIiIiIiIiIiBzADjYiIiIiIiIiIiIHsIONiIiIiIiIiIjIAexgIyIiIiIiIiIicgA72IiIiIiIiIiIiBzgfq0bQER0IykrK0NFRYUmdXl6esLb21uTuoiI6MagZZ4BmGuIiKg6XtOoww42IiKNlJWVoWULXxjOGDWpLzQ0FEeOHHGZhERERDXTOs8AzDVERGSprKwMLVuGwmAo0KQ+V8oz7GAjItJIRUUFDGeMOLYrAno/x0bgFxbJaBF9FBUVFS6RjIiIqHZa5hmAuYaIiKqrqKiAwVCAo8ffhl7v41BdhYWXEBH+vMvkGXawERFpzNdPgq+f5FAdMhyLJyKiG5cWeQZgriEiItt8fb3g6+vlUB2yLGvUmusDO9iIiDRmVGQYFcfrICIiskaLPGOqh4iIyBpFqYKiVDlchyvhKqJEREREREREREQO4B1sREQak6FAhmO3FjgaT0RENy4t8oypHiIiImsUxQhFcWxRHUfjrzfsYCMi0pgMGY4OunG8BiIiulFpkWdM9RAREVkjK1WQHRzi6Wj89YZDRImIiIiIiIiIiBzAO9iIiDRmVBQYFceG3TgaT0RENy4t8oypHiIiImu4yIE4drAREWmMc7AREZEzcQ42IiJytstzsDnaweZac7BxiCgR0Q1k0aJFiIiIgLe3N2JiYrB9+3abZffu3YtBgwYhIiICkiRhwYIF1cqkpqZCkiSLLTIy0onPgIiIiIiI6PrDDjYiIo3JUGB0cFNzV8Hnn3+O5ORkpKSkYPfu3ejatSvi4+Nx5swZq+VLS0vRqlUrzJo1C6GhoTbr7dixI06fPm3e/vvf/wq3jYiItKNFnlGba4iIyDUocpUmmyvhEFEiIo1dqyGi8+bNw7hx4zBmzBgAQFpaGtatW4elS5di8uTJ1crfeuutuPXWWwHA6uMm7u7uNXbAERFR3eIQUSIicjql6vLmaB0uhHewERHVY4WFhRZbeXm51XIVFRXYtWsX4uLizPt0Oh3i4uKQnZ3tUBsOHjyIsLAwtGrVCiNGjEBubq5D9REREREREd1o2MFGRKQx0+pujm4AEB4eDn9/f/M2c+ZMq8c8d+4cjEYjQkJCLPaHhITAYDCofi4xMTFYtmwZMjIysHjxYhw5cgR33HEHioqKVNdJRESO0SrPcBVRIiKyxbSKqKObK+EQUSIijcn/2xytAwCOHz8OvV5v3u/l5eVgzWL69etn/neXLl0QExODFi1a4IsvvsDYsWPrtC1ERHSZFnnGVA8REZFVchUgVzpehwthBxsRUT2m1+stOthsadKkCdzc3JCXl2exPy8vT9P50wICAnDzzTfj0KFDmtVJRERERER0veMQUSIijWmxsptRcOJpT09PREdHIysry7xPlmVkZWUhNjZWs+dWXFyMw4cPo2nTpprVSUREYrTKM6K5hoiIXAeHiIrjHWxERDeI5ORkjBo1Ct27d0ePHj2wYMEClJSUmFcVHTlyJJo1a2aex62iogJ//PGH+d8nT55ETk4OfH190aZNGwDAiy++iPvvvx8tWrTAqVOnkJKSAjc3NwwfPvzaPEkiIiIiIqJ6iB1sREQaMyqXN0frEDV06FCcPXsW06ZNg8FgQFRUFDIyMswLH+Tm5kKn+/vG5VOnTqFbt27mn+fMmYM5c+agd+/e2LRpEwDgxIkTGD58OM6fP4+goCD06tULW7duRVBQkEPPj4iI1NMiz5jqISIiskquAmQ3x+twIexgIyLSmJaLHIhKSkpCUlKS1cdMnWYmERERUGpZQW7lypUqW0JERM7CRQ6IiMjp2MEmjHOwEREREREREREROYB3sBERaUyGBCMkh+sgIiKyRos8Y6qHiIjIOiPg8CIFRk1acr3gHWxERBqTFW02IiIia7TKM8w1RERkiyRXabKpsWjRIkRERMDb2xsxMTHYvn17jeVXrVqFyMhIeHt7o3Pnzli/fr35scrKSrz88svo3LkzGjZsiLCwMIwcORKnTp2yqCMiIgKSJFlss2bNEmo3O9iIiIiIiIiIiOia+/zzz5GcnIyUlBTs3r0bXbt2RXx8PM6cOWO1/JYtWzB8+HCMHTsWv/zyCxITE5GYmIg9e/YAAEpLS7F79268+uqr2L17N77++mscOHAAAwcOrFbXa6+9htOnT5u3Z599VqjtHCJKRKQxowZDd7QY+kNERDcmLfKMqR4iIiKr5CpAdvCeLBV3sM2bNw/jxo3DmDFjAABpaWlYt24dli5dismTJ1cr//bbbyMhIQGTJk0CAMyYMQOZmZlYuHAh0tLS4O/vj8zMTIuYhQsXokePHsjNzUXz5s3N+/38/BAaGircZhPewUZEpDHThY+jGxERkTVa5RnmGiIiskmu0mYDUFhYaLGVl5dbPWRFRQV27dqFuLg48z6dToe4uDhkZ2dbjcnOzrYoDwDx8fE2ywNAQUEBJElCQECAxf5Zs2ahcePG6NatG2bPno2qKrEOQt7BRkREREREREREThEeHm7xc0pKClJTU6uVO3fuHIxGI0JCQiz2h4SEYP/+/VbrNhgMVssbDAar5cvKyvDyyy9j+PDh0Ov15v3PPfccbrnlFgQGBmLLli2YMmUKTp8+jXnz5tnzFAGwg42ISHOyIkFWHFxF1MF4IiK6cWmRZ0z1EBERWSMpVZAUxwY9Sv9bhfT48eMWnVleXl4O1atWZWUlhgwZAkVRsHjxYovHkpOTzf/u0qULPD098eSTT2LmzJl2t5cdbEREGuMcbERE5Eycg42IiJxOlgHZ6HgdAPR6vUUHmy1NmjSBm5sb8vLyLPbn5eXZnBstNDTUrvKmzrVjx45hw4YNtbYnJiYGVVVVOHr0KNq1a1dr2wHOwUZERERERERERNeYp6cnoqOjkZWVZd4nyzKysrIQGxtrNSY2NtaiPABkZmZalDd1rh08eBA//vgjGjduXGtbcnJyoNPpEBwcbHf7eQcbEZHGjNDB6OD3Fw5+V0RERDcwLfLM5XqIiIisk+QqSLJjdzpLKlYRTU5OxqhRo9C9e3f06NEDCxYsQElJiXlV0ZEjR6JZs2aYOXMmAOD5559H7969MXfuXAwYMAArV67Ezp07sWTJEgCXO9cefvhh7N69G2vXroXRaDTPzxYYGAhPT09kZ2dj27ZtuOuuu+Dn54fs7GxMnDgRjz76KBo1amR329nBRkSkMUWDuXEUzotDREQ2aJFnTPUQERFZJRsB2cEvc1QMMR06dCjOnj2LadOmwWAwICoqChkZGeaFDHJzc6HT/d2unj17Ij09HVOnTsUrr7yCtm3bYvXq1ejUqRMA4OTJk1izZg0AICoqyuJYGzduRJ8+feDl5YWVK1ciNTUV5eXlaNmyJSZOnGgxL5s9JEVRFOFnTERE1RQWFsLf3x9ZvzdHQz/HklFJkYy+nXNRUFBg13wFRER049MyzwDMNUREVJ0p15z6bSD0fh6O1VVUibAua1wmz3AONqpTkiRZXY63Phk9ejR8fX0dqkOWZXTq1AlvvPGGRq2qXyorKxEeHo733nvvWjelXjJNPu3oRkQ1U5tTjh49CkmSsGzZMs3bpLU+ffqgT58+5p+d0faIiAiMHj1as/rI+bTKM8w1JCo1NRWSZPm+qaqqwksvvYTw8HDodDokJiYCAIqLi/HEE08gNDQUkiRhwoQJdd/geub48ePw9vbGzz//rCp+2bJlkCQJO3fu1LhlNWOeEJeRkQFfX1+cPXv2WjdFPblKm82FsIOtHjpy5AiSkpJw8803o0GDBmjQoAE6dOiAZ555Br/99tu1bp5T9enTB5Ik1bo52klXWlqK1NRUbNq0SZN2X+2zzz7D8ePHkZSUBAB2PSdJkpzWHrW2bNmC1NRU5OfnW+z38PBAcnIy3njjDZSVlV2bxtVjRkWnyUZ0PTB92JckCf/973+rPa4oCsLDwyFJEu67775r0EL1Nm3aZHGO9vDwQKtWrTBy5Ej89ddf17p5Qmydz+n6pFWeYa5xbVeevyVJgre3N8LCwhAfH4933nkHRUVFdtWzdOlSzJ49Gw8//DCWL1+OiRMnAgD+9a9/YdmyZXj66afx6aef4rHHHnPm07kuvPbaa4iJicHtt99u9fEhQ4ZAkiS8/PLLddwy53nvvfec8oVWTdeNkZGRmh9PVEJCAtq0aWOeJ+x6JMlGTTZXwjnY6pm1a9di6NChcHd3x4gRI9C1a1fodDrs378fX3/9NRYvXowjR46gRYsW17qpTvHPf/4TTzzxhPnnHTt24J133sErr7yC9u3bm/d36dLFoeOUlpZi+vTpAGBxZ4BWZs+ejWHDhsHf3x8A8Omnn1o8/sknnyAzM7Pa/iufY32wZcsWTJ8+HaNHj0ZAQIDFY2PGjMHkyZORnp6Oxx9//No0kIjqDW9vb6Snp6NXr14W+3/66SecOHECXl5e16hljnvuuedw6623orKyErt378aSJUuwbt06/P777wgLC6vTtrRo0QKXLl2Ch4fYkI2azucHDhywmMuEiFzLa6+9hpYtW6KyshIGgwGbNm3ChAkTMG/ePKxZs8bic/fUqVMxefJki/gNGzagWbNmmD9/frX9t912G1JSUurkedR3Z8+exfLly7F8+XKrjxcWFuLbb79FREQEPvvsM8yaNava3YLXo/feew9NmjRxyh1wN910k9UOLNM12LX25JNP4sUXX8T06dPh5+d3rZtDdYAdbPXI4cOHMWzYMLRo0QJZWVlo2rSpxeNvvvkm3nvvvVo/BJeUlKBhw4bObKrT3HPPPRY/e3t745133sE999xTY0dYfXrOv/zyC3799VfMnTvXvO/RRx+1KLN161ZkZmZW26+GoigoKyuDj4+Pw3WJCAgIwL333otly5axg+0qMiTIDt4gLIPTY9L1pX///li1ahXeeecduLv//fEiPT0d0dHROHfu3DVsnWPuuOMOPPzwwwAuf7lw880347nnnsPy5csxZcoUqzHOykumu0y0dD13froqLfLM5XqYawjo168funfvbv55ypQp2LBhA+677z4MHDgQ+/btM3/OdHd3tzjHA8CZM2eqddyb9nfo0EGzdsqyjIqKCs3PgXXl3//+N9zd3XH//fdbffyrr76C0WjE0qVLcffdd2Pz5s3o3bt3Hbfy+uLv76/qespWjtbiuqqsrAyenp7Q6XQYNGgQnn32Waxater6vF5SNFjkQHGtO9j4dWU98tZbb6GkpAQff/xxtc414HJCe+655xAeHm7eZ5ov7PDhw+jfvz/8/PwwYsQIAJdPHC+88ALCw8Ph5eWFdu3aYc6cObhyXYua5nK5eiimac6FQ4cOmb8B9/f3x5gxY1BaWmoRW15ejokTJyIoKAh+fn4YOHAgTpw44eArZNmOP/74A4888ggaNWpkvmPi6rlqTEaPHo2IiAjzcw4KCgIATJ8+3eaw05MnTyIxMRG+vr4ICgrCiy++CKOx9hPE6tWr4enpiTvvvFPoeX388ce4++67ERwcDC8vL3To0AGLFy+uVi4iIgL33Xcfvv/+e3Tv3h0+Pj54//33AQDHjh3DwIED0bBhQwQHB2PixIn4/vvvrQ4/3bZtGxISEuDv748GDRqgd+/eFvNBpKamYtKkSQCAli1bml+no0ePmsvcc889+O9//4sLFy4IPdcbHefFIVc0fPhwnD9/HpmZmeZ9FRUV+PLLL/HII49YjbEnTwFiOeXkyZN4/PHHERISAi8vL3Ts2BFLly7V7okCuPvuuwFcntIBqDkvAZcvqqKjo+Hj44PAwEAMGzYMx48fr1bvkiVL0Lp1a/j4+KBHjx74z3/+U62Mrby9f/9+DBkyBEFBQfDx8UG7du3wz3/+09y+ms7n1ubW+euvvzB48GAEBgaiQYMGuO2227Bu3TqLMqYhtF988QXeeOMN3HTTTfD29kbfvn1x6NAh+19QEsY52MjZ7r77brz66qs4duwY/v3vf5v3XzkHm+l8tHHjRuzdu9diyhNJknDkyBGsW7eu2jmnvLwcKSkpaNOmDby8vBAeHo6XXnoJ5eXlFm2QJAlJSUlYsWIFOnbsCC8vL2RkZACw71wveo7atm0b+vfvj0aNGqFhw4bo0qUL3n77bYsy+/fvx8MPP4zAwEB4e3uje/fu5tUJa7N69WrExMTYnOt5xYoVuOeee3DXXXehffv2WLFihc26SktL8eSTT6Jx48bQ6/UYOXIkLl68aFFm586diI+PR5MmTeDj44OWLVtW6+SxNw9fzdpcfMDfw46vzC979+7FTz/9ZH4fXHmtlp+fjwkTJpiP36ZNG7z55puQZbnG44uoKUfXdF0lkgdXrlyJqVOnolmzZmjQoAEKCwsBAMHBwejSpQv+7//+T7PnU5ckWdZgiKh2v8vrAe9gq0fWrl2LNm3aICYmRiiuqqoK8fHx6NWrF+bMmYMGDRpAURQMHDgQGzduxNixYxEVFYXvv/8ekyZNwsmTJ6vdwi1iyJAhaNmyJWbOnIndu3fjww8/RHBwMN58801zmSeeeAL//ve/8cgjj6Bnz57YsGEDBgwYoPqY1gwePBht27bFv/71r1qTwJWCgoKwePFiPP3003jwwQfx0EMPAbAcdmo0GhEfH4+YmBjMmTMHP/74I+bOnYvWrVvj6aefrrH+LVu2oFOnTsLDdxYvXoyOHTti4MCBcHd3x7fffot//OMfkGUZzzzzjEXZAwcOYPjw4XjyyScxbtw4tGvXDiUlJbj77rtx+vRpPP/88wgNDUV6ejo2btxY7VgbNmxAv379EB0djZSUFOh0OnMH33/+8x/06NEDDz30EP7880989tlnmD9/Ppo0aWJ+/Uyio6OhKAq2bNly3c2tRETaioiIQGxsLD777DP069cPAPDdd9+hoKAAw4YNwzvvvGNRXiRP2ZtT8vLycNttt5kvyoKCgvDdd99h7NixKCws1GyC7cOHDwMAGjdubLHfWl5644038Oqrr2LIkCF44okncPbsWbz77ru488478csvv5jv+vjoo4/w5JNPomfPnpgwYQL++usvDBw4EIGBgRZfrFnz22+/4Y477oCHhwfGjx+PiIgIHD58GN9++y3eeOMNu87nV8rLy0PPnj1RWlqK5557Do0bN8by5csxcOBAfPnll3jwwQctys+aNQs6nQ4vvvgiCgoK8NZbb2HEiBHYtm2b8GtLRPXHY489hldeeQU//PADxo0bV+3xoKAgfPrpp3jjjTdQXFxsHqrXvn17fPrpp5g4cSJuuukmvPDCC+bysixj4MCB+O9//4vx48ejffv2+P333zF//nz8+eefWL16tcUxNmzYgC+++AJJSUlo0qQJIiIihM/19pyjMjMzcd9996Fp06bmz9H79u3D2rVr8fzzzwMA9u7di9tvvx3NmjXD5MmT0bBhQ3zxxRdITEzEV199Ve3ceKXKykrs2LHD5nXEqVOnsHHjRvPw0eHDh2P+/PlYuHAhPD09q5VPSkpCQEAAUlNTceDAASxevBjHjh0zd/icOXMG9957L4KCgjB58mQEBATg6NGj+Prrr811OPN60WTBggV49tln4evra/7SJyQkBMDlTsLevXvj5MmTePLJJ9G8eXNs2bIFU6ZMwenTp7FgwYJa6zcajVbvkPfx8al2h5qta0dr11WieXDGjBnw9PTEiy++iPLycovfWXR0dLX3Nd3AFKoXCgoKFABKYmJitccuXryonD171ryVlpaaHxs1apQCQJk8ebJFzOrVqxUAyuuvv26x/+GHH1YkSVIOHTqkKIqiHDlyRAGgfPzxx9WOC0BJSUkx/5ySkqIAUB5//HGLcg8++KDSuHFj8885OTkKAOUf//iHRblHHnmkWp21WbVqlQJA2bhxY7V2DB8+vFr53r17K7179662f9SoUUqLFi3MP589e9ZmW0yv6WuvvWaxv1u3bkp0dHStbb7pppuUQYMG1VjmmWeeUa7+87vy92oSHx+vtGrVymJfixYtFABKRkaGxf65c+cqAJTVq1eb9126dEmJjIy0eA1lWVbatm2rxMfHK7IsWxy/ZcuWyj333GPeN3v2bAWAcuTIEavP49SpUwoA5c0336zx+boK09/xN7+2VX74K9Kh7Ztf2yoAlIKCgmv9tIhq9PHHHysAlB07digLFy5U/Pz8zOezwYMHK3fddZeiKJfPXQMGDDDH2ZunRHLK2LFjlaZNmyrnzp2zKDts2DDF39/f3K6act+VNm7cqABQli5dqpw9e1Y5deqUsm7dOiUiIkKRJEnZsWOHoii289LRo0cVNzc35Y033rDY//vvvyvu7u7m/RUVFUpwcLASFRWllJeXm8stWbJEAWCR16y1/c4771T8/PyUY8eOWRznynN8TefzFi1aKKNGjTL/PGHCBAWA8p///Me8r6ioSGnZsqUSERGhGI1Gi9enffv2Fu1+++23FQDK77//bu1lJQdomWeYa+jK87ct/v7+Srdu3cw/m853V+rdu7fSsWPHarFXn/cVRVE+/fRTRafTWZxfFEVR0tLSFADKzz//bN4HQNHpdMrevXstytp7rrf3HFVVVaW0bNlSadGihXLx4kWLOq88j/bt21fp3LmzUlZWZvF4z549lbZt21Z7/lc6dOiQAkB59913rT4+Z84cxcfHRyksLFQURVH+/PPPy3/r33xjUc70O4uOjlYqKirM+9966y0FgPJ///d/iqIoyjfffFPr79bePKwo1fOEtffBle27Mtd07NjR6vXZjBkzlIYNGyp//vmnxf7Jkycrbm5uSm5urs22K8rl9x0Aq9uTTz5Zra3Wrh1tXVeJ5sFWrVpZvZZTFEX517/+pQBQ8vLyanw+9Ykp1xi29VZK9/Z1aDNs6+1SeYZDROsJ022k1m4Z7tOnD4KCgszbokWLqpW5+tuQ9evXw83NDc8995zF/hdeeAGKouC7775T3dannnrK4uc77rgD58+fNz+H9evXA0C1Y2u9NPfV7dCatedpz6px58+fR6NGjYSPd+VY/4KCApw7dw69e/fGX3/9hYKCAouyLVu2RHx8vMW+jIwMNGvWDAMHDjTv8/b2rvaNY05ODg4ePIhHHnkE58+fx7lz53Du3DmUlJSgb9++2Lx5s923ZZue5/U8t5IzXJ4bx/GN6HozZMgQXLp0CWvXrkVRURHWrl1rc3iovXnK3pyiKAq++uor3H///VAUxXxuO3fuHOLj41FQUIDdu3erel6PP/44goKCEBYWhgEDBqCkpATLly+3mLMIqJ43vv76a8iyjCFDhli0JzQ0FG3btjXfYbxz506cOXMGTz31lMW33qNHj651ouazZ89i8+bNePzxx9G8eXOLx9ROjr1+/Xr06NHDYpirr68vxo8fj6NHj+KPP/6wKD9mzBiLdt9xxx0AcN2ttHo90SrPMNdQbXx9fe1eTdQeq1atQvv27REZGWlxXjQNvb965EXv3r0t5nFTc66v7Rz1yy+/4MiRI5gwYUK1ueRM59ELFy5gw4YNGDJkCIqKiszHPH/+POLj43Hw4EGcPHnS5vM+f/48ANi8RlixYgUGDBhgngi/bdu2iI6OtjlMdPz48RajZZ5++mm4u7ubc6bpeaxduxaVlZVW63Dm9aI9Vq1ahTvuuAONGjWy+D3GxcXBaDRi8+bNtdYRERGBzMzMapu1605b147WrqtE8+CoUaNsztt2PV8vcRVRcRwiWk+YTqbFxcXVHnv//fdRVFSEvLw8q5M4uru746abbrLYd+zYMYSFhVVbrcS0SuWxY8dUt/XqD/Cmk8bFixeh1+tx7Ngx6HQ6tG7d2qJcu3btVB/TmpYtW2pa35W8vb2rDZ1p1KhRtbkNbFEEhqya/Pzzz0hJSUF2dna1Oe0KCgosLrKsPfdjx46hdevW1S6o2rRpY/HzwYMHAVxOBLYUFBTY1Uloep43wgpHROS4oKAgxMXFIT09HaWlpTAajebFAa5mb56yN6ecPXsW+fn5WLJkCZYsWWL1mGfOnFH1vKZNm4Y77rgDbm5uaNKkCdq3b19tkm+g+rn54MGDUBQFbdu2tVqv6eLI9FyvLufh4YFWrVrV2DbTBWKnTp3sezJ2OHbsmNXpKq783Vx5vJo+FxDR9a24uBjBwcGa1Xfw4EHs27fP5hD1q8/TV59X1ZzraztHmYb913QePXToEBRFwauvvopXX33V5nGbNWtmsw7A+jXCvn378Msvv2DkyJEWc8P16dMHixYtQmFhIfR6vUXM1fnC19cXTZs2Nc991rt3bwwaNAjTp0/H/Pnz0adPHyQmJuKRRx4xL2zjzOtFexw8eBC//fab3e8Faxo2bIi4uDi7jmfr2tHWdZVIHqzpupTXS66FHWz1hL+/P5o2bYo9e/ZUe8z0x33l5PJX8vLyqnVlUVts/aHXNJm/m5ub1f1qOpUcYe1bAkmSrLbDnsUJrmTrOdqjcePGwhcVhw8fRt++fREZGYl58+YhPDwcnp6eWL9+PebPn1/tjjJHVrYx1TV79mxERUVZLWNr8tWrmZ6naT4fukyGDkauIkou6pFHHsG4ceNgMBjQr18/qyvLOYPp3Pboo4/a/ALhyrk2RXTu3NmuD/BXn5tlWYYkSfjuu++s5hV7z7X1XX35XOBKtMgzl+vh74hsO3HiBAoKCqp9WesIWZbRuXNnzJs3z+rjV885ae28Coid67U4R5mO++KLL1a728mkptfJNGentWsE0yISEydOxMSJE6s9/tVXX2HMmDF2txW4fE305ZdfYuvWrfj222/x/fff4/HHH8fcuXOxdetWh/OPmmvIq8myjHvuuQcvvfSS1cdvvvlmVW2zxdb1kyPXVfbUcV1fL8lGQHawY5B3sNG1MmDAAHz44YfYvn07evTo4VBdLVq0wI8//oiioiKLbyX2799vfhz4+xuc/Px8i3hHvrFo0aIFZFnG4cOHLe4wOHDggOo67dWoUSOrQ1Kufj7O/AYhMjLSvLKcvb799luUl5djzZo1Ft+yWVugwJYWLVrgjz/+gKIoFs/v6lWSTHeB6PX6Wi8Ya3udTM/T9G0OXWZUdDA6OALfyAtTuk49+OCDePLJJ7F161Z8/vnnNsvZm6fszSmmFUaNRqPd32Y7W+vWraEoClq2bFnjhYLpuR48eNA8TAq4PCn2kSNH0LVrV5uxpjvcrH1BdyWRvNeiRQurOfvq3w1dO1rkmcv1MNeQbZ9++ikA2OxQUqN169b49ddf0bdvX1Wfx51xrjd9Nt6zZ4/NOk3nWg8PD1XHbd68OXx8fKpdIyiKgvT0dNx11134xz/+US1uxowZWLFiRbUOtoMHD+Kuu+4y/1xcXIzTp0+jf//+FuVuu+023HbbbXjjjTeQnp6OESNGYOXKlXjiiSfszsPWXHkNeeUXadauIW39nlu3bo3i4uJ6k7OvpGUePHLkCJo0aWLzTr367PIQT8eum11tiCjnYKtHXnrpJTRo0ACPP/448vLyqj0u8i1L//79YTQasXDhQov98+fPhyRJ5hXe9Ho9mjRpUm2M+3vvvafiGVxmqvvqFePsWQnGUa1bt8b+/ftx9uxZ875ff/0VP//8s0W5Bg0aAKjesaiF2NhY7Nmzp9pS4zUxfbN25e+4oKAAH3/8sd11xMfH4+TJkxZLhZeVleGDDz6wKBcdHY3WrVtjzpw5VockX/namVbfsfU67dq1C5IkITY21u52EtGNzdfXF4sXL0Zqairuv/9+m+XszVP25hQ3NzcMGjQIX331ldXOpivPbXXloYcegpubG6ZPn14thyuKYp6Tp3v37ggKCkJaWhoqKirMZZYtW1ZrngoKCsKdd96JpUuXIjc3t9oxTGo7n1+pf//+2L59O7Kzs837SkpKsGTJEkRERFjMh0REN6YNGzZgxowZaNmyJUaMGKFZvUOGDMHJkyerfT4FgEuXLqGkpKTGeGec62+55Ra0bNkSCxYsqHaONJ1Hg4OD0adPH7z//vs4ffq08HE9PDzQvXt37Ny502L/zz//jKNHj2LMmDF4+OGHq21Dhw7Fxo0bcerUKYu4JUuWWMyttnjxYlRVVZlz5sWLF6vlHdPIFdM1ir152BpTp+SV15Cm+Umv1rBhQ6u5Z8iQIcjOzsb3339f7bH8/HxUVVXZPL6zaZkHd+3axWslF8I72OqRtm3bIj09HcOHD0e7du0wYsQIdO3aFYqi4MiRI0hPT4dOp6s235o1999/P+666y7885//xNGjR9G1a1f88MMP+L//+z9MmDDBYi6bJ554ArNmzcITTzyB7t27Y/Pmzfjzzz9VP4+oqCgMHz4c7733HgoKCtCzZ09kZWVVu5PKGR5//HHMmzcP8fHxGDt2LM6cOYO0tDR07NjRvAgDcPk23g4dOuDzzz/HzTffjMDAQHTq1EmTOWweeOABzJgxAz/99BPuvfdeu2LuvfdeeHp64v7778eTTz6J4uJifPDBBwgODraaxK158sknsXDhQgwfPhzPP/88mjZtihUrVsDb2xvA398e6XQ6fPjhh+jXrx86duyIMWPGoFmzZjh58iQ2btwIvV6Pb7/9FsDlzjgA+Oc//4lhw4bBw8MD999/v/lCLTMzE7fffrv5tne6TIYOMoeIkguraY5HE3vzlEhOmTVrFjZu3IiYmBiMGzcOHTp0wIULF7B79278+OOPuHDhgubPtSatW7fG66+/jilTpuDo0aNITEyEn58fjhw5gm+++Qbjx4/Hiy++CA8PD7z++ut48skncffdd2Po0KE4cuQIPv7441rnYAMudz726tULt9xyC8aPH4+WLVvi6NGjWLduHXJycgDUfj6/0uTJk/HZZ5+hX79+eO655xAYGIjly5fjyJEj+Oqrr1RPS0Ha0SLPXK6HuYaA7777Dvv370dVVRXy8vKwYcMGZGZmokWLFlizZo35s6QWHnvsMXzxxRd46qmnsHHjRtx+++0wGo3Yv38/vvjiC3z//ffVFpC5mtbnep1Oh8WLF+P+++9HVFQUxowZg6ZNm2L//v3Yu3evuQNo0aJF6NWrFzp37oxx48ahVatWyMvLQ3Z2Nk6cOIFff/21xuM88MAD+Oc//2kxp9qKFSvg5uaGAQMGWI0ZOHAg/vnPf2LlypVITk4276+oqEDfvn0xZMgQHDhwAO+99x569eplXuxs+fLleO+99/Dggw+idevWKCoqwgcffAC9Xm++y03kevFq9957L5o3b46xY8di0qRJcHNzw9KlSxEUFFTty57o6GgsXrwYr7/+Otq0aYPg4GDcfffdmDRpEtasWYP77rsPo0ePRnR0NEpKSvD777/jyy+/xNGjR2sdVllQUGAeYns1a3OX20urPHjmzBn89ttveOaZZ1S35ZriEFFh7GCrZx544AH8/vvvmDt3Ln744QcsXboUkiShRYsWGDBgAJ566qkah4qY6HQ6rFmzBtOmTcPnn3+Ojz/+GBEREZg9ezZeeOEFi7LTpk3D2bNn8eWXX+KLL75Av3798N133zk0oanpBLtixQqsXr0ad999N9atW1dtXgWttW/fHp988gmmTZuG5ORkdOjQAZ9++inS09OxadMmi7Iffvghnn32WUycOBEVFRVISUnRpIMtOjoaXbp0wRdffGF3B1u7du3w5ZdfYurUqXjxxRcRGhqKp59+GkFBQXj88cftqsPX1xcbNmzAs88+i7fffhu+vr4YOXIkevbsiUGDBll8OOrTpw+ys7MxY8YMLFy4EMXFxQgNDUVMTAyefPJJc7lbb70VM2bMQFpaGjIyMiDLMo4cOYKGDRuioKAAP/zwg0N3O96ojIoEo+JYMnI0nqi+E8lT9uaUkJAQbN++Ha+99hq+/vprvPfee2jcuDE6duyIN998sy6fntnkyZNx8803Y/78+Zg+fTqAy3MM3XvvvRarPo8fPx5GoxGzZ8/GpEmT0LlzZ6xZs8bmZNpX6tq1K7Zu3YpXX30VixcvRllZGVq0aIEhQ4aYy9R0Pr9aSEgItmzZgpdffhnvvvsuysrK0KVLF3z77bc2LwKpbmmRZ0z1EE2bNg0A4OnpicDAQHTu3BkLFizAmDFjqk2A7yidTofVq1dj/vz5+OSTT/DNN9+gQYMGaNWqFZ5//nm75t1yxrk+Pj4eGzduxPTp0zF37lzIsozWrVtj3Lhx5jIdOnTAzp07MX36dCxbtgznz59HcHAwunXrZn4Na/LYY49h8uTJWLNmDR599FFUVlZi1apV6NmzJwIDA63GdOrUCS1btsS///1viw62hQsXYsWKFZg2bRoqKysxfPhwvPPOO+Yv1Hv37o3t27dj5cqVyMvLg7+/P3r06IEVK1aYJ+QXycNX8/DwwDfffIN//OMfePXVVxEaGooJEyagUaNG1YazTps2DceOHcNbb72FoqIi9O7dG3fffTcaNGiAn376Cf/617+watUqfPLJJ9Dr9bj55psxffr0WlfRBi7PE/jYY49ZfcyRDjat8uDXX38NLy8vi3x8PZFkBdJVc4GrqcOVSApnoCXS3KeffopnnnkGubm5dTbBty0LFizAxIkTceLEiVpXNhKt96233sLhw4c1mRz0RlBYWAh/f398+ktnNPBTv1AGAJQWGfFYt99RUFBQbeUoIiJyTVrmGYC5hqiujR07Fn/++Sf+85//XOumUB3o1q0b+vTpg/nz51/rpggx5ZqzG2+B3texXFNYbETQXbtdJs/wHn8iJxgxYgSaN2+ORYsW1elxL126ZPFzWVkZ3n//fbRt21bTzrXKykrMmzcPU6dOZeeaFcb/re7m6EZERGSNVnmGuYaobqWkpGDHjh3V5oemG09GRgYOHjyIKVOmXOumqCcbtdlcCIeIEjmBTqerdUU3Z3jooYfQvHlzREVFmeck2L9/P1asWKHpcTw8PKrNr0B/kxUdZAdXd5N5czEREdmgRZ65XA9zDVFdat68OcrKyq51M6gOJCQkWF1Q7rqiGAHHRohersOFsION6AYSHx+PDz/8ECtWrIDRaESHDh2wcuVKDB069Fo3jYiIiIiIiOiGxQ42ohvIhAkTMGHChGvdDJenxbAbI1d2IyIiG7Qa3slcQ0REtkiKDMnBxXAkxdFb4K4vnHiBiEhjMv5e4U3tpjYVLVq0CBEREfD29kZMTAy2b99us+zevXsxaNAgREREQJIkLFiwwOE6iYjI+bTIM47kGiIicgGcg00YO9iIiG4Qn3/+OZKTk5GSkoLdu3eja9euiI+Px5kzZ6yWLy0tRatWrTBr1iyEhoZqUicREREREZEruiGGiMqyjFOnTsHPzw+S5NgtjETkmhRFQVFREcLCwqDTObhAAXSQHfz+Qk38vHnzMG7cOIwZMwYAkJaWhnXr1mHp0qWYPHlytfK33norbr31VgCw+riaOm9kzDVE5Ij6lmdM9YhatGgRZs+eDYPBgK5du+Ldd99Fjx49rJbdu3cvpk2bhl27duHYsWOYP38+p7KoAfMMETlKy1wDWQZkB89FsmvdK31DdLCdOnUK4eHh17oZRHQDOH78OG666SaH6jAqOhgdXN3NFF9YWGix38vLC15eXtXKV1RUYNeuXRZLget0OsTFxSE7O1tVG5xR5/WMuYaItFBf8oypHhGmu5rT0tIQExODBQsWID4+HgcOHEBwcHC18qY7pQcPHoyJEyc63N4bHfMMEWlFi1zDDjZxN0QHm5+fHwDg2O4I6H3t/6BQLIsvkVwgVwnHFMpuwjHFsqeK41S/6K79OD7CMaWKh3BMmSL+fCoV8ddNUfFh04i6+4bQXRIfg+6hIsZbqhCO8dOVC8f46i4Jx/jrxP/umriJP59gN7G/h6JiGW2jT5rPJ/XF1R+0U1JSkJqaWq3cuXPnYDQaERISYrE/JCQE+/fvV3VsZ9R5PTO9Nw7uagY/gVxz0Sj+t1WmYt7xQ5WBKo4jfj5Xo0hFfio0NhSOcZfEc/QlFW3zUXG+9NZVCscAgE7FLFluUt1MXK9TMUG+mufjqSIPtvU4KxwT4SH+9+Al2R9TWCyjxS1H612eEeGMO6Xpb3+/N3whCXw+bdwgUvhYhRWnhGM23tlGOGbv6WbCMam5J4Vj2snibbunqfg5LOXYd8IxMR7xwjE+OvHL9IfCxT9jA4DeS/xzdgMP8ZiskyG1F7rK7nzxfLulbIVwzF0+I4VjHgoXfw0eef5z4ZjNS/sLlS81VmJEzrrrOtdcz26IDjbTLdR6Xx30fvZf9Ohk8c4YuY5iFBUxRhUdebKKGEUWf9tIiniMu4oONrmed7B5qLjdX02MtyR+AdPATfzCtKFO/Hfkq+JWZT838Ri9ihgAmgzJkCFBdvB9ZYo/fvw49Hq9eb+1u9eobpjeG36CuabKKP5e9FDRP9KgUvzvUafiPKtGlVE8B1SoiPFQ8WenJqf56FR88aFT1+lVnzvY3FS0TafiHOup4vfq66Eib6iI8ZLEY+pLnjHVA9h3tzTvanY+03tDgiT0PtFJKj6bq3jv+rqLH6eBm/iX7Gqej7skfhw152U1r5uatnmoeA183NTdKdTATfx1aKgixksn/jq4q8pn4udGNb8jHxUfofQ+4m1r6Kbuy1Atco0ky1BxWVmtDlfitEUORFedW7VqFSIjI+Ht7Y3OnTtj/fr1zmoaEZFTmYbuOLoBgF6vt9hsdbA1adIEbm5uyMvLs9ifl5dncwGD2jijTi0xzxCRq9Iqz5hyTXh4OPz9/c3bzJkzqx2zpruaDQZDnTzvusY8Q0QuTZa12VyIUzrYRFed27JlC4YPH46xY8fil19+QWJiIhITE7Fnzx5nNI+I6Ibj6emJ6OhoZGVlmffJsoysrCzExsbWmzq1wjxDRKSd48ePo6CgwLxdeZeaq2KeISIiUU7pYLtyfoYOHTogLS0NDRo0wNKlS62Wf/vtt5GQkIBJkyahffv2mDFjBm655RYsXLjQGc0jInIqI3SabKKSk5PxwQcfYPny5di3bx+efvpplJSUmOfKGTlypMVFU0VFBXJycpCTk4OKigqcPHkSOTk5OHTokN11XivMM0TkyrTKM6ZcY8/d0vX9rmatMc8QkcvjHWzCNO9gM83PEBcX9/dBapmfITs726I8AMTHx9ssX15ejsLCQouNiKi+kBVJk03U0KFDMWfOHEybNg1RUVHIyclBRkaGeThPbm4uTp8+bS5/6tQpdOvWDd26dcPp06cxZ84cdOvWDU888YTddV4LdZFnAOYaIqq/tMozIrmmPt/VrDXmGSIisINNBc0XOVCz6pzBYBCaz2HmzJmYPn26Ng0mIrqBJCUlISkpyepjmzZtsvg5IiICilL75LE11Xkt1EWeAZhriIiulpycjFGjRqF79+7o0aMHFixYUO1O6WbNmpnncKuoqMAff/xh/rfpTmlfX1+0aSO+6mNdYZ4hIiI1nLbIgTNNmTLFYp6I48ePX+smERGZyRoM2ZGvz9PzDYW5hojqKy3yjJpc44w7pV0Z8wwR1WuKEZAd3BTxldevZ5rfwaZmfobQ0FCh8taWDiciqi9kRQdZcayDzNH4G1ld5BmAuYaI6i8t8oypHlHOuFO6vmGeISICJFmG5OAIT8nFhohqfgWnZn6G2NhYi/IAkJmZecPN50BERI5jniEiImdiniEiIjU0v4MNEJ+f4fnnn0fv3r0xd+5cDBgwACtXrsTOnTuxZMkSZzSPiMipjJBghPgiBVfXQbYxzxCRK9Miz5jqIeuYZ4jI5cky4OgNaC52B5tTOtiGDh2Ks2fPYtq0aTAYDIiKiqo2P4NO9/fNcz179kR6ejqmTp2KV155BW3btsXq1avRqVMnZzSPiMipOETU+ZhniMiVXcshoq6CeYaIXB472IRJyvU4McJVCgsL4e/vj4t/toLez/4PCgXyJeFjFcjik/QVyW7CMfmy+HwMRbKPcEyJiuOUyJ7CMWWKeEylIv66qYmpS24Q/3PzkKqEYxroyoVjGuoqhGP8dOJ/Q43dSoRjAlW0LcRN7D1XWCSjWeQJFBQUQK/XCx8P+PtcNH1bHLx9Hfv+oqy4CikxPzrUHtKW6fd7dH9ToVxTqYh/sDhU6S0cYzD6C8d4S5XCMRUqzrNnq8Tfw24qJv0okz2EY9RQc44tVZFvAcDPrUw4Rs3vtUgWf8+peR3UtK2xW7FwjJ+KvNHCXTxH++vs/+xVWCSj0c1/1Zs8AzDX1Dem3+89DZ6Ah2T/55iM0n8LH+v7HvcKx/R+5FvhmAFTHheO+alijXDMhJCHhGNmn/pQOEZRxM9hIQ1jhGNWdgkWjnnvj5uEYwDgrXu2Ccc0aZsrHPNU2hDhGD8Vaf1iufi5vJ2/eEx+hfgXFFPv+0E45q8/WwuVL6mqRN8tP2iSay6kB0LfwLEvYgpLZQQ+csFl8oxT7mAjInJlRjg+7Ma11tshIiIRWuQZUz1ERERWyYrjd6DJ1/39XELYwUZEpDEOESUiImfiEFEiInI6WdFgiKhrdbAxqxIRERERERERETmAd7AREWnMqOhgdPCuAEfjiYjoxqVFnjHVQ0REZJUsA7KD0xG42B1s7GAjItKYAgmyg3PjKBrMrUNERDcmLfKMqR4iIiKr2MEmjF9bEREREREREREROYB3sBERaYxDRImIyJk4RJSIiJyOixwIYwcbEZHGZEWCrDh2O7Wj8UREdOPSIs+Y6iEiIrJKkQFH84TiWh1s/NqKiIiIiIiIiIjIAbyDjYhIY0boYHTw+wtH44mI6MalRZ4x1UNERGSVosEQURe7g40dbEREGuMQUSIiciYOESUiIqfjHGzC+LUVERERERERERGRA3gHWx0wom6+HVRzHDUxsop+WTXfkFYqbiqOI962uvr9AAAko3CITsXrXamI/2lXKuJtU/NeUPV7FY4AKiH2fCod/nrmbzJ0ql6bq+ug+slX8oKvZP/v57DxkvAxdJL4+zHIrVA4xlAVIByjhpuK53OiIlA4JthD/DXILW8sHBOi4jhqfqcAkFfpXyfHcoP4N8wNdOXCMWWKh3DMWaNeOKZEFm+bt5QvHHPOWGx32eLK+pVnTPVQ/XNKKYAb7P9bebvNcOFjFFfY/941uW3yEOGYpIgK4Zg/j3cSjvnpgvjzOfNEc+GY2PR2wjGr7ygSjnlks49wTJx4ugAAtP3mqHCMolQJxxjlNOGY2a3GiseU5AjHbDwvHIJYXbRwTPTKcOGYIfpWQuXLZfG/OZt4B5swdrAREWnMqEgwOjjsxtF4IiK6cWmRZ0z1EBERWaPIlzdH63Al/NqKiIiIiIiIiIjIAbyDjYhIY1zkgIiInImLHBARkdNxiKgwdrAREWlMUXSq5gO8ug4iIiJrtMgzpnqIiIiskqFBB5sWDbl+MKsSERERERERERE5gHewERFpzAjJ4dVp63R1WyIiuq5okWdM9RAREVnFO9iEsYONiEhjsuL4vDYuNl0BEREJ0CLPmOohIiKySvnf5mgdLoRDRImIiIiIiIiIiBygeQfbzJkzceutt8LPzw/BwcFITEzEgQMHaoxZtmwZJEmy2Ly9vbVuGhFRnZD/N/m0oxtZxzxDRK5OqzzDXGMd8wwREaDIkiabK9E8q/7000945plnsHXrVmRmZqKyshL33nsvSkpKaozT6/U4ffq0eTt27JjWTSMiqhMyJE02so55hohcnVZ5hrnGOuYZIiL8PQebo5sL0XwOtoyMDIufly1bhuDgYOzatQt33nmnzThJkhAaGqp1c4iI6AbDPENERM7EPENERGo4/b7wgoICAEBgYGCN5YqLi9GiRQuEh4fjgQcewN69e22WLS8vR2FhocVGRFRfGBVJk43s44w8AzDXEFH9pVWeYa6xD/MMEbkkRQJkBzcXyzNOXUVUlmVMmDABt99+Ozp16mSzXLt27bB06VJ06dIFBQUFmDNnDnr27Im9e/fipptuqlZ+5syZmD59ujObbpNRxSoYalZ5qlTEfzVGFfNoqDlOhYoYNcepVNyEY9TMJaLmdVNLlsSPpSZGTde5h1IlHFOmeNRRTIVwTKUidj9ylWD5mmgxrw3nxbGPs/IMYDvXGIylKDHa//spkj3tLmui5u+krt4zas7NRUYf4ZiWXmeFY/KNDYRj/N1LhWPKVOS0gkrxtgGAt65SOMZDMgrH6CTxc2Cp7CUco+a9EOKRLxyjg/jfUKks/nsNcxfInTrtLjK0mj+NuaZ21yLPvHNLPnzd7X8PR93/jd1lTc7ntBWOiTzaWzjGUCZ+PvKV/YVjnm8tfg5bkHGPcIyXckY4pnPG98IxwQ27C8f8WqAXjgEAo7FAOEaB+O9VksTPy38WiceMChB/7eaeWi4cA99o4ZDjxRuEYzLlIKHyRkX8c4MtWsyhpvYSa9GiRZg9ezYMBgO6du2Kd999Fz169LBZftWqVXj11Vdx9OhRtG3bFm+++Sb69+8PAKisrMTUqVOxfv16/PXXX/D390dcXBxmzZqFsLAwcx0XLlzAs88+i2+//RY6nQ6DBg3C22+/DV9fX7vb7dSs+swzz2DPnj1YuXJljeViY2MxcuRIREVFoXfv3vj6668RFBSE999/32r5KVOmoKCgwLwdP37cGc0nIqJ6zll5BmCuISIi5hkiorr2+eefIzk5GSkpKdi9eze6du2K+Ph4nDljvYN7y5YtGD58OMaOHYtffvkFiYmJSExMxJ49ewAApaWl2L17N1599VXs3r0bX3/9NQ4cOICBAwda1DNixAjs3bsXmZmZWLt2LTZv3ozx48cLtd1pHWxJSUlYu3YtNm7caPNbG1s8PDzQrVs3HDp0yOrjXl5e0Ov1FhsRUX0hQ4KsOLipnHh60aJFiIiIgLe3N2JiYrB9+/Yay69atQqRkZHw9vZG586dsX79eovHR48eXW1VtISEBFVt05oz8wzAXENE9ZcmecaBXOMqmGeIyKU5OjzUtAmaN28exo0bhzFjxqBDhw5IS0tDgwYNsHTpUqvl3377bSQkJGDSpElo3749ZsyYgVtuuQULFy4EAPj7+yMzMxNDhgxBu3btcNttt2HhwoXYtWsXcnNzAQD79u1DRkYGPvzwQ8TExKBXr1549913sXLlSpw6dcrutmvewaYoCpKSkvDNN99gw4YNaNmypXAdRqMRv//+O5o2bap184iInE7RYFU3RcVFj9bf9pgkJCRYrIr22WefqXpdtMI8Q0SuTos8ozbXuALmGSIiXJ4/TYsNqDbfZHl5udVDVlRUYNeuXYiLizPv0+l0iIuLQ3Z2ttWY7Oxsi/IAEB8fb7M8cHluTUmSEBAQYK4jICAA3bv/PcQ4Li4OOp0O27Zts+vlApzQwfbMM8/g3//+N9LT0+Hn5weDwQCDwYBLly6Zy4wcORJTpkwx//zaa6/hhx9+wF9//YXdu3fj0UcfxbFjx/DEE09o3TwiohuW1t/2mHh5eSE0NNS8NWrUqC6ejk3MM0RE5EzMM0RE2goPD4e/v795mzlzptVy586dg9FoREhIiMX+kJAQGAwGqzEGg0GofFlZGV5++WUMHz7cfOewwWBAcHCwRTl3d3cEBgbarMcazRc5WLx4MQCgT58+Fvs//vhjjB49GgCQm5sLne7vvr2LFy9i3LhxMBgMaNSoEaKjo7FlyxZ06NBB6+YRETmdaeiNo3UAqLaimJeXF7y8qk8sbvq258oP+/Z825OcnGyxLz4+HqtXr7bYt2nTJgQHB6NRo0a4++678frrr6Nx48ZqnpYmmGeIyNVpkWdM9VB1zDNERNoucnD8+HGLYfDWrmfqQmVlJYYMGQJFUcznei1p3sGmKLUvs7lp0yaLn+fPn4/58+dr3RQiomtCy1VEw8PDLfanpKQgNTW1Wvmavu3Zv3+/1WPY821PQkICHnroIbRs2RKHDx/GK6+8gn79+iE7OxtubuKrSWqBeYaIXB1XEXUu5hkiIgCyTtUcapZ1XD6f2jvPZJMmTeDm5oa8vDyL/Xl5eQgNDbUaExoaald5U+fasWPHsGHDBov2hIaGVptWp6qqChcuXLB5XGuYVYmI6rHjx49brDB25R1qdWHYsGEYOHAgOnfujMTERKxduxY7duyodmFBRERERETkCE9PT0RHRyMrK8u8T5ZlZGVlITY21mpMbGysRXkAyMzMtChv6lw7ePAgfvzxx2qjcWJjY5Gfn49du3aZ923YsAGyLCMmJsbu9mt+BxsRkavTcohoffi250qtWrVCkyZNcOjQIfTt27fWdhERkfY4RJSIiJxO5SqglnWIhyQnJ2PUqFHo3r07evTogQULFqCkpARjxowBcHkOzGbNmpnncXv++efRu3dvzJ07FwMGDMDKlSuxc+dOLFmyBMDlzrWHH34Yu3fvxtq1a2E0Gs0jdgIDA+Hp6Yn27dsjISEB48aNQ1paGiorK5GUlIRhw4YhLCzM7rbzDjYiIo1psbKbLLiym7O+7bnaiRMncP78ea6KRkR0DWmVZ0RzDRERuQ5FkTTZRA0dOhRz5szBtGnTEBUVhZycHGRkZJintsnNzcXp06fN5Xv27In09HQsWbIEXbt2xZdffonVq1ejU6dOAICTJ09izZo1OHHiBKKiotC0aVPztmXLFnM9K1asQGRkJPr27Yv+/fujV69e5k46e/EONiKiG4TW3/YUFxdj+vTpGDRoEEJDQ3H48GG89NJLaNOmDeLj46/Z8yQiIiIiohtXUlISkpKSrD5mbaqawYMHY/DgwVbLR0RE2DW3ZmBgINLT04XaeTV2sBERaUzLIaIihg4dirNnz2LatGkwGAyIioqq9m3PlSuemb7tmTp1Kl555RW0bdvW4tseNzc3/Pbbb1i+fDny8/MRFhaGe++9FzNmzLhmK/8QERGHiBIRUR3QcJEDV8EONiIijV2rDjZA2297fHx88P3336tqBxEROQ872IiIyNkUGVAc7GBT2MHmOmQ7bhPUglHF/BZqYioV8V9npeJWJzFlKtpWLnsIx6hpm7EOl6h3k8RnefSSqpzQkurcVMxA6SaJ/w15S5XCMSUq3j+lSrlgedc6+ZN6bv/b7OWh4u9eD7H3LwDkKz7CMWrOSWpiQjzyhWNOVDSuvdBVPCSjcEylLH5+8dCJn5e9deLnPkBdjtJB/HxWpiLn/lnZUDgm0ueUcEypLH7HbGOPYuGYEkX8NSiR7f+9lrjYRQapV1ruDclo//tx/w89hY/xypZI4Ridis+KP58Vv6apUvHZN+di7QtCXW3dxbzaC10lXGoiHHPC52bhmCF+0cIx2QUFwjEA0LhhV+GYIDQXjjlauav2QldJbC7+O1p/IkQ4xstD/DOHuyT+3tbp/IRjzklieVNG3Vw7knUu3cFGROQM1/IONiIiuvHxDjYiInI6RYNVRF0sz7CDjYhIY+xgIyIiZ2IHGxEROZvaVUCvrsOV1N3YOCIiIiIiIiIiohsQ72AjItKYAkBWMY/i1XUQERFZo0WeMdVDRERklay7vDlUhzZNuV6wg42ISGMcIkpERM7EIaJERORsiixpsIqoa+UZDhElIiIiIiIiIiJyAO9gIyLSGO9gIyIiZ+IdbERE5Gxc5EAcO9iIiDTGDjYiInImdrAREZHTcQ42YRwiSkRERERERERE5ADewUZEpDHewUZERM7EO9iIiMjZuMiBOHawERFpjPMVEBGRM2mRZ0z1EBERWcNrGnEcIkpEREREREREROQA3sEmqBLiPbCVipuKGPFfjZrjlMkewjGlsqd4jNFLOKZcrpvXoC6HR+gkRTimUlLz/hGPMap4b6vhIVXVSUxDwZhiDW9fliFBdvD1dDSenEev84ReZ//3Uxdko/AxDEY/4Rg3SXwW2Yo6yk9uKma4VXNOKqjyFY7RQfy8XFDpIxyjlppcqOb1VpOf/N0vCceUKeKfIcpVfFY5rIQIx0R4nBWOKdJV2F22WNFupmct8oypHqp/Ru7NhSTw+e/Dm9sLH+PT0d8Jx9z2cRfhmA66m4Rjjlf+KhzTpZFeOGaeYYNwTJ53K+GYmxEtHLPQ8L5wTNuG/YRjAOBSVb5wzBk38fNZO/fbhWOG7d0pHLOkbYxwTGZxV+GYCPGPHECxeIgRlULlZYhfN9mujIsciGIHGxGRxjgHGxERORPnYCMiImfjHGziOESUiIiIiIiIiIjIAZp3sKWmpkKSJIstMjKyxphVq1YhMjIS3t7e6Ny5M9avX691s4iI6oxpQlBHN7KOeYaIXJ1WeYa5xjbmGiJydcwz4pxyB1vHjh1x+vRp8/bf//7XZtktW7Zg+PDhGDt2LH755RckJiYiMTERe/bscUbTiIiczjR0x9GNbGOeISJXplWeYa6pGXMNEbk0Rff3PGxqN8W1Bk065dm6u7sjNDTUvDVp0sRm2bfffhsJCQmYNGkS2rdvjxkzZuCWW27BwoULndE0IiK6ATDPEBGRszHXEBGRCKd0sB08eBBhYWFo1aoVRowYgdzcXJtls7OzERcXZ7EvPj4e2dnZNmPKy8tRWFhosRER1Re8ndr5nJ1nAOYaIqq/OES0bvCahohcmWmRA0c3V6J5B1tMTAyWLVuGjIwMLF68GEeOHMEdd9yBoqIiq+UNBgNCQiyXUg8JCYHBYLB5jJkzZ8Lf39+8hYeHa/ociIgcoWgwZIcXPbbVRZ4BmGuIqP7SIs8w19SM1zRE5OoURYsvdK71s6hbmnew9evXD4MHD0aXLl0QHx+P9evXIz8/H1988YVmx5gyZQoKCgrM2/HjxzWrm4iI6re6yDMAcw0RkSvjNQ0REYlyd/YBAgICcPPNN+PQoUNWHw8NDUVeXp7Fvry8PISGhtqs08vLC15eXpq2k4hIKwrg8Lc1LvZlj0OckWcA5hoiqr+0yDOmesg+vKYhIpejxRBPDhHVVnFxMQ4fPoymTZtafTw2NhZZWVkW+zIzMxEbG+vsphEROYUMSZON7MM8Q0SuRqs8w1xjP+YaInI1iqLTZHMlmj/bF198ET/99BOOHj2KLVu24MEHH4SbmxuGDx8OABg5ciSmTJliLv/8888jIyMDc+fOxf79+5GamoqdO3ciKSlJ66YREdENgHmGiIicjbmGiIhEaT5E9MSJExg+fDjOnz+PoKAg9OrVC1u3bkVQUBAAIDc3Fzrd3/16PXv2RHp6OqZOnYpXXnkFbdu2xerVq9GpUyetm0ZEVCe0WJmNE0/bxjxDRK5OqxVAmWtsY64hIpcnS44P8XSxIaKSolz/6zoUFhbC398fF/9sBb2f/TflnTOWCB/rrFH8DXJWbiAcc8HoKxxzvko8psAo3rYio7dwTKnsKRxzyeghHFOluAnHGFV+uJRV3O6qk2ThGA8VMV66SuEYHzfxGD+3MuGYRu7if3eN3YqFY0Ld84XKlxTJ6NflKAoKCqDX64WPB/x9Lur0xSS4NXBsThVjaTn2DJntUHtIW6bf774/guEnkGuKVJxj8lWcMyvVnP9U3MiuJj8dr2gsHFNg9BGOUfMaVMriMeWy+PeThVXizwcAvHRVquJEqRkq6OcungPUCPEoFI7xVZGf1Gjucd7usqVFRgyO2l9v8gzAXFPfmH6/33a/Hw3d7f8c/NGBm4SP9Xv5OeEYH0X8PfdR76PCMZVV4tcAj2SLv3/P46RwTHd0E44J9hbPGScviX8u/036TTgGADwk8Wu7vLK9wjFNvG4WjmmIAOEYN+dPMw8AOFK+TThmdsv7hGM+PSGWz4xKBX4p+0yTXHP4sXbw8xT/nHSlogojWn96wGXyjGsNiCUiIiIiIiIiItIYO9iIiDSmKNpsRERE1miVZ9TkmkWLFiEiIgLe3t6IiYnB9u3bayy/atUqREZGwtvbG507d8b69etVPmsiIqpLyv9WEXV0cyXsYCMi0phpbhxHNyIiImu0yjOiuebzzz9HcnIyUlJSsHv3bnTt2hXx8fE4c+aM1fJbtmzB8OHDMXbsWPzyyy9ITExEYmIi9uzZo8XLQERETsRVRMW51rMlIiIiIiJV5s2bh3HjxmHMmDHo0KED0tLS0KBBAyxdutRq+bfffhsJCQmYNGkS2rdvjxkzZuCWW27BwoUL67jlREREzscONiIijfEONiIiciat72ArLCy02MrLy6sds6KiArt27UJcXJx5n06nQ1xcHLKzs622Mzs726I8AMTHx9ssT0RE9QeHiIpjBxsRkcZkRdJkIyIiskarPGPKNeHh4fD39zdvM2fOrHbMc+fOwWg0IiQkxGJ/SEgIDAaD1XYaDAah8kREVH/wpgFx7GAjIrqBaD35tKIomDZtGpo2bQofHx/ExcXh4MGDznwKRERUx44fP46CggLzNmXKlGvdJCIiousOO9iIiDR2rVZ2c8bk02+99RbeeecdpKWlYdu2bWjYsCHi4+NRVlam9uUhIiIHab2KqF6vt9i8vLyqHbNJkyZwc3NDXl6exf68vDyEhoZabWdoaKhQeSIiqj94B5s4drAREWns8kWLo8lI/LhaTz6tKAoWLFiAqVOn4oEHHkCXLl3wySef4NSpU1i9erUDrxARETlCmzwjlms8PT0RHR2NrKws8z5ZlpGVlYXY2FirMbGxsRblASAzM9NmeSIiqj8URYM52NjBRkRE9YU9E08Dzpl8+siRIzAYDBZl/P39ERMTwwmqiYhcUHJyMj744AMsX74c+/btw9NPP42SkhKMGTMGADBy5EiL4aXPP/88MjIyMHfuXOzfvx+pqanYuXMnkpKSrtVTICIichr3a90AIqIbjRa3Q5viw8PDLfanpKQgNTW1WvmaJp/ev3+/1WPUNvm06f+coJqIqH7RatiNaB1Dhw7F2bNnMW3aNBgMBkRFRSEjI8OcJ3Jzc6HT/f39fc+ePZGeno6pU6filVdeQdu2bbF69Wp06tTJ4bYTEZFzKYoOiuLYPVmKmmE51zF2sBERaUz53+ZoHcDliaf1er15v7V5cYiIyLVokWdM9YhKSkqyeQfapk2bqu0bPHgwBg8erOJIRER0LZmGeTpahytx6Q42WUVMpYpRtZWKm3BMmewhHFMqi194l8qewjHFRvHjlKiIKTeKvz3LZfGYKgd75UXoVHyU1UniMV468fdPuVwpHKPmvW2so9fbTRL7Cy81Gp3UEseYJpyujTMmnzb9Py8vD02bNrUoExUVJfI0bijekg7ekv3v4yIV39zJKv5O8uUGwjFlKnKAocpfOOZCVUPhGDX5SU0OqFARU1wl3rZSFTEA4O1WJRyjEzz/AUCZUTxvFFZ6C8foPcQXSHFT8YlNzeeoQPdi4RiRv4dLRvHfJbmmj/4Mg4dk/zlDVpFniqVC4ZjDxj+FY6ZnxwvHfHtpjXBMlbFEOEYniV+fHPdsIRxz6pJ4nskp/Uw45t4G44VjAOCnirXCMSHeHYVjenuIx3iouGz4vixHOCavVDxGVsTz2YRDnwjHTAp7Qqh8uVyBX04LH4Y0wjnYiIg0di1W3HHG5NMtW7ZEaGioRZnCwkJs27aNE1QTEV1DWuUZV5t8moiI7Mc8I86l72AjInIKLceICkhOTsaoUaPQvXt39OjRAwsWLKg2+XSzZs0wc+ZMAJcnn+7duzfmzp2LAQMGYOXKldi5cyeWLFkCAJAkCRMmTMDrr7+Otm3bomXLlnj11VcRFhaGxMREB58gERGpdi3HiBIRkUvQcl5pV8EONiKiG4QzJp9+6aWXUFJSgvHjxyM/Px+9evVCRkYGvL3Fh4YRERERERHdqNjBRkSkNS1uh1YZr/Xk05Ik4bXXXsNrr72mqj1EROQEWg27cbE7C4iIyH6K7PgiBYqaie+vY+xgIyLSmKJc3hytg4iIyBot8oypHiIiIms4RFQcFzkgIiIiIiIiIiJyAO9gIyLSGL/tISIiZ9JqZTbmGiIiskVRdFAUx+7JcjT+esMONiIirSmS4/Pa8KKHiIhs0SLPmOohIiKyQlYkyA7mCUfjrzeadydGRERAkqRq2zPPPGO1/LJly6qV5ep0RERkC/MMERE5G3MNERGJ0vwOth07dsBoNJp/3rNnD+65554aV6nT6/U4cOCA+WdJcq1eTiK6sXCRA+diniEiV8dFDpyPuYaIXJ4sObyKKByNv85o3sEWFBRk8fOsWbPQunVr9O7d22aMJEkIDQ3VuilERNeG8r/N0TrIKuYZInJ5WuQZUz1kFXMNEbk6zistzqkzzlVUVODf//43Hn/88Rq/wSkuLkaLFi0QHh6OBx54AHv37q2x3vLychQWFlpsRETkepyVZwDmGiIiuozXNEREZA+nLnKwevVq5OfnY/To0TbLtGvXDkuXLkWXLl1QUFCAOXPmoGfPnti7dy9uuukmqzEzZ87E9OnTHW6fUcV98ZUqVsEoUzyEY0pkL+GYIqP4PA8FVT7CMYVV4scpqRJ/PmVG8bdnhSweUyWr62dWM2GjThJ/z6mJ8dRVCcdcchN/n5areb3d6+dKMpeM4q+ZLfy2p+44K88A2uWafNlTOMYI8d9/Y12JcMxRo3gOKKhqIBzjrasUjjlf2VA45pJR/LU+Xy7+fNScl0urxNsGqMtrdcVdkoVjLhnFc41REX8vFBvFP3eoEeJRYHdZo4YrqXEV0bpV19c0gZ6Ap87+381z3X+1u6xJ1A+HhGP+uK+5cMzSncIhKCs4LRzzXfdE4ZgJ+8Q/+7XWNRGO+UU5KBxzc8P7hWN2KTuEYwDATSeeny5UHhWOWWc8JxzTCl2EY9TcQqQo5cIxfXxGC8fsUjYLxyzP3y1UXlZ4TXMtOfVK96OPPkK/fv0QFhZms0xsbCxGjhyJqKgo9O7dG19//TWCgoLw/vvv24yZMmUKCgoKzNvx48ed0XwiIvUUBzeyi7PyDMBcQ0T1nKN5hrnGbrymISJXZOpgc3RzJU77WvTYsWP48ccf8fXXXwvFeXh4oFu3bjh0yPa3Kl5eXvDyqptvJomIqH5yZp4BmGuIiIjXNEREZD+n3cH28ccfIzg4GAMGDBCKMxqN+P3339G0aVMntYyIyLn4bU/dYJ4hIlelVZ5hrqkdcw0RuSpZ0WmyuRKn3MEmyzI+/vhjjBo1Cu7ulocYOXIkmjVrhpkzZwIAXnvtNdx2221o06YN8vPzMXv2bBw7dgxPPPGEM5pGROR8XEXU6ZhniMilcRXROsFcQ0SuTFEkKDLnYBPhlA62H3/8Ebm5uXj88cerPZabmwud7u9ezIsXL2LcuHEwGAxo1KgRoqOjsWXLFnTo0MEZTSMiohsA8wwRETkbcw0REYlwSgfbvffeC8XGCp2bNm2y+Hn+/PmYP3++M5pBRHSNSP/bHK2DbGGeISLXpkWeMdVDtjDXEJEr4yqi4lxrQCwRUV3QYmU3DtshIiJbtMozzDVERGTDtZzrc9GiRYiIiIC3tzdiYmKwffv2GsuvWrUKkZGR8Pb2RufOnbF+/XqLx7/++mvce++9aNy4MSRJQk5OTrU6+vTpA0mSLLannnpKqN3sYCMiIiIiIiIiomvu888/R3JyMlJSUrB792507doV8fHxOHPmjNXyW7ZswfDhwzF27Fj88ssvSExMRGJiIvbs2WMuU1JSgl69euHNN9+s8djjxo3D6dOnzdtbb70l1HanDBElInJpXOSAiIiciYscEBGRk8mKBNnBIZ5q4ufNm4dx48ZhzJgxAIC0tDSsW7cOS5cuxeTJk6uVf/vtt5GQkIBJkyYBAGbMmIHMzEwsXLgQaWlpAIDHHnsMAHD06NEaj92gQQOEhoYKt9mEd7AREWlNkbTZiIiIrNEqzzDXEBGRDVoOES0sLLTYysvLrR6zoqICu3btQlxcnHmfTqdDXFwcsrOzrcZkZ2dblAeA+Ph4m+VrsmLFCjRp0gSdOnXClClTUFpaKhTPO9iIiIiIiIiIiMgpwsPDLX5OSUlBampqtXLnzp2D0WhESEiIxf6QkBDs37/fat0Gg8FqeYPBINTGRx55BC1atEBYWBh+++03vPzyyzhw4AC+/vpru+tgBxsRkcYU5fLmaB1ERETWaJFnTPUQERFZo+UqosePH4derzfv9/LycqheZxg/frz53507d0bTpk3Rt29fHD58GK1bt7arDpfuYDOqiKlU3IRjSmTxN0+R7C0cU2wUP05hlfhxCip9hGOKK8XbVm4Uf3uWV4nHGFWeNNSMJ9dJ4p9k1bTOw0383e3lViUcU6bmdySL/w2p+buTBV+5sspK4WPYxDnYbmiVUFAp8AtqrLN+C3xNDMYGwjF7y5sJx6j523KTZOGYY2WNhWMKK8Xzk5qYCqP4a1BUIZ7TGvuIDTEwUZPX1ORPNarkuplpJNBL/LWr0Im/Br5u4n+rfm72vxfKVOQ/mzgH2w2tjb4S3jr7P8d0+u4X4WOEN4wVjnkhq61wTEMVp6O5rccKx/TbuUQ4xk3nLxxzwqOJcEyVfEk45ukmDwrHjO5ULBwDAOl/iL8X3j6zWjgmv3xP7YWu0tS3l3DMLyU7hGOGBoyvvdBVVua/LxwzqdmTwjHt9GI58JKxAs/+uU34ONZoOQebXq+36GCzpUmTJnBzc0NeXp7F/ry8PJtzo4WGhgqVt1dMTAwA4NChQ3Z3sHEONiIiIiIiIiIiuqY8PT0RHR2NrKws8z5ZlpGVlYXYWOudwbGxsRblASAzM9NmeXvl5OQAAJo2bWp3jEvfwUZE5BRaTBzNiaeJiMgWrRYoYK4hIiIbLk9H4OgQUfGY5ORkjBo1Ct27d0ePHj2wYMEClJSUmFcVHTlyJJo1a4aZM2cCAJ5//nn07t0bc+fOxYABA7By5Urs3LkTS5b8fWfrhQsXkJubi1OnTgEADhw4AODy3W+hoaE4fPgw0tPT0b9/fzRu3Bi//fYbJk6ciDvvvBNdunSxu+3sYCMi0pikXN4crYOIiMgaLfKMqR4iIiJrtJyDTcTQoUNx9uxZTJs2DQaDAVFRUcjIyDAvZJCbmwud7u/BmD179kR6ejqmTp2KV155BW3btsXq1avRqVMnc5k1a9aYO+gAYNiwYQD+XmzB09MTP/74o7kzLzw8HIMGDcLUqVOF2s4ONiIiIiIiIiIiqheSkpKQlJRk9bFNmzZV2zd48GAMHjzYZn2jR4/G6NGjbT4eHh6On376SbSZ1bCDjYhIa1zkgIiInImLHBARkZMpGixy4OgdcNcbdrAREWmNc7AREZEzcQ42IiJysms1RPR6xlVEiYiIiIiIiIiIHMA72IiItMYhokRE5EwcIkpERE7GO9jEsYONiEhr7GAjIiJnYgcbERE5mazBHGyOxl9vOESUiIiIiIiIiIjIAexgIyLSmqLR5kQXLlzAiBEjoNfrERAQgLFjx6K4uLjGmLKyMjzzzDNo3LgxfH19MWjQIOTl5VmUkSSp2rZy5UpnPhUiItejVZ7hHWxERGSDaYioo5srYQcbEZHWTKu7Obo50YgRI7B3715kZmZi7dq12Lx5M8aPH19jzMSJE/Htt99i1apV+Omnn3Dq1Ck89NBD1cp9/PHHOH36tHlLTEx00rMgInJRWuUZF7vwISIi+5mGiDq6uRKXnoOtUsW3diWKp3BMkdFHOKagqoFwTL6KmIsV4jGFFd7CMcUVXsIxFUY34ZjKKvEYo8o/elkW75+WJPE3nZoYNxUxHu5G4ZhSd/G/h9Iq8Zgyo4dwTJUi9l6oKK8QPsb1at++fcjIyMCOHTvQvXt3AMC7776L/v37Y86cOQgLC6sWU1BQgI8++gjp6em4++67AVzuSGvfvj22bt2K2267zVw2ICAAoaGhdfNkrgG9zhN6nf1//xVKufAxjCq+/1ITc7oyQDjmVJl4zMUK8TxYXCmeN4rU5Joq8Y9Cas7Lx/MDhGMAoEpFrvFwEz+fu+nEn1NJhfj5XI1LVeI5IKRBkXDMoZIg4ZjzlQ3tLltR4jp5hhwz9cg3kCT7P58+HTxa+Bi5JeLnie/LvxWO8arSC8f8frqjcMwtPo8Ix+TrLgrH3OndSjimSMVF56cFW4Rj3v5xr3AMAPT0jhCO8fe8STimhXtf4ZjvSj4VjhnoO1Y4ZmX++8Ix70eOFI559fhO4Rj3fLHPNrJSJXwM0g7vYCMi0pikaLMBQGFhocVWXi7eWXO17OxsBAQEmDvXACAuLg46nQ7btm2zGrNr1y5UVlYiLi7OvC8yMhLNmzdHdna2RdlnnnkGTZo0QY8ePbB06VIoCscgERFpSas8o6KvmIiIXIQCSZPNlbj0HWxERE6h4Sqi4eHhFrtTUlKQmprqUNUGgwHBwcEW+9zd3REYGAiDwWAzxtPTEwEBARb7Q0JCLGJee+013H333WjQoAF++OEH/OMf/0BxcTGee+45h9pMRERX4CqiRETkZFrMocY52GqxefNm3H///QgLC4MkSVi9erXF44qiYNq0aWjatCl8fHwQFxeHgwcP1lrvokWLEBERAW9vb8TExGD79u2iTSMiuuEcP34cBQUF5m3KlCk2y06ePNnqIgNXbvv373dqe1999VXcfvvt6NatG15++WW89NJLmD17tlAdzDNERORMzDNEROQMwh1sJSUl6Nq1KxYtWmT18bfeegvvvPMO0tLSsG3bNjRs2BDx8fEoKyuzWefnn3+O5ORkpKSkYPfu3ejatSvi4+Nx5swZ0eYREd1Q9Hq9xeblZXsehhdeeAH79u2rcWvVqhVCQ0OrnV+rqqpw4cIFm3OnhYaGoqKiAvn5+Rb78/LyapxvLSYmBidOnBAa2so8Q0REzsQ8Q0RUOy5yIE54iGi/fv3Qr18/q48pioIFCxZg6tSpeOCBBwAAn3zyCUJCQrB69WoMGzbMaty8efMwbtw4jBkzBgCQlpaGdevWYenSpZg8ebJoE4mIrikJjs9royYVBQUFISio9km6Y2NjkZ+fj127diE6OhoAsGHDBsiyjJiYGKsx0dHR8PDwQFZWFgYNGgQAOHDgAHJzcxEbG2vzWDk5OWjUqFGNHYNXY54hIqqZFnnGVI8rYp4hIqodh4iK03SRgyNHjsBgMFhMgu3v74+YmJhqk2CbVFRUYNeuXRYxOp0OcXFxNmPKy8urTfxNRET2ad++PRISEjBu3Dhs374dP//8M5KSkjBs2DDzCqInT55EZGSkeXiLv78/xo4di+TkZGzcuBG7du3CmDFjEBsba15B9Ntvv8WHH36IPXv24NChQ1i8eDH+9a9/4dlnn9Ws7XWVZwDmGiIiV8Q8Q0REamnawWaa6DokJMRi/9WTYF/p3LlzMBqNQjEzZ86Ev7+/ebt6EnAiomtKkbTZnGjFihWIjIxE37590b9/f/Tq1QtLliwxP15ZWYkDBw6gtLTUvG/+/Pm47777MGjQINx5550IDQ3F119/bX7cw8MDixYtQmxsLKKiovD+++9j3rx5SElJ0azddZVnAOYaIqrHtMozLnZngT2YZ4iILpOhwRBRF7tX+rpcRXTKlClITk42/1xYWMiERET1h4ariDpLYGAg0tPTbT4eEREBRbFshLe3NxYtWmRzzpqEhAQkJCRo2s5ribmGiOotriJ6Q2CeIaL6jENExWl6B5tpouu8vDyL/TVNgt2kSRO4ubkJxXh5eVWb+JuIiG58dZVnAOYaIiJXxDxDRERqadrB1rJlS4SGhiIrK8u8r7CwENu2bbM5Cbanpyeio6MtYmRZRlZWVo0TZxMR1VuKRhtVwzxDRATt8gxzTTXMM0REl8mQNNlcifAQ0eLiYhw6dMj885EjR5CTk4PAwEA0b94cEyZMwOuvv462bduiZcuWePXVVxEWFobExERzTN++ffHggw8iKSkJAJCcnIxRo0ahe/fu6NGjBxYsWICSkhLzKjxERNcTSdFgFVEXvuhhniEiqpkWecZUjytiniEisoMGQ0Rdba5P4Q62nTt34q677jL/bJo3YNSoUVi2bBleeukllJSUYPz48cjPz0evXr2QkZEBb29vc8zhw4dx7tw5889Dhw7F2bNnMW3aNBgMBkRFRSEjI6PaRKFERHTjY54hIiJnYp4hIiJnkJSrZ7G+DhUWFsLf3x8X/2wFvZ/9o17/rCwRPtbBysbiMeW2516w5WhZE+EYQ5n4vA3nyxoKxxSVewnHlFZ4CMdUVoqvwWGsEh/1LKvsVVfkuumNl1QcRqeTxWPcxGM8PIzCMd4eVcIxDT0rhGMCvC4Jla8sqUBGvw9QUFCgeg4U07ko4vU3oLviQ7gaclkZjk79p0PtIW2Zfr/H94cJ5Zo8o/h7fkeZ+CTX542+wjE5Rc3Fj1PeQDimtMpTOOZsiXh+qqgSzxs6FbfwXLok/nzU3iqk5jxbXi6ec9V8w+zlLX5ulmXxPO3jJX6cxg1Lay90lXIV759Ab/uPU9/yDMBcU9+Yfr8dfQbDTbL/77itu/j1yYVK8b+r81KRcMyzzcVzxqY88Zj0i+8Lxyy8eZRwzI7z4n93h0rFPpMCgL+beJ5ZX7JMOAYAFt/8iHDMGyePCsc86NteOGZz4QXhGDV+K1srHPP9rXHCMQv2ine471RyhMrLShXOlm7TJNd8EfUwGrip+ExxhVJjJYbkfOkyeea6XEWUiKheuw5WESUiousYVxElIiIn4yqi4jRd5ICIiIiIiIiIiMjV8A42IiKNcZEDIiJyJi5yQEREzib/b3O0DlfCDjYiIq0pkuMr5rjY7dRERCRAizxjqoeIiMgKDhEVxyGiREREREREREREDuAdbEREWuMiB0RE5Exc5ICIiJxMVgDZwTvQZBfLM+xgIyLSGOdgIyIiZ+IcbERE5GwKJChwcIiog/HXGw4RJSIiIiIiIiIicgDvYCMi0hqHiBIRkTNxiCgRETmZrEgaDBF1rTvY2MFGRKQ1LYbu8KKHiIhs0WiIKHMNERHZcnkONsfrcCUcIkpEREREREREROQA3sFGRKQ1DhElIiJn4hBRIiJyMi5yII53sBERERERERERETnApe9gq1TE+xeLjD7CMRerGgrHXKhoIBxzvkz8OPmXxJ9PSZmncExFhfhbTa5wE45RqlT0kBtV9qrX1YSNKiZZMarpOncTP06lh1E4ptxD/L1Q5iUeU24Ue/8YS8uFj2ET72C7oRXLVZBk+//IKlTkGm9dpXDM6UsBwjHlsvh5trRKPAfkFfkJxxSVeAvH6FScLyvLVHwUklWc/1X+TVeqyVHuKg6mE48prVDxO3KXhWOqKsXfp4VF4p+jPDyrhGMqBHKNsaSe5RlTPVTvvNGhAg0F/o4X/iH+i2zV0Es4ZmvhD8IxT/1ZIBwjSeJ5c+HNo4RjHonPFI6Zu7SjcMzYkObCMTkXxV+DoAZdhGMA4Oez4teDpy/9Khzzb/m8cExxRZ5wjKyIn2tluUg4poGn+HH+0e6ccEzagSih8pWoQAa2CR/HGi5yIM6lO9iIiJxB0mDyaU0mryYiohuSFnnGVA8REZE1inJ5c7QOV8IhokRERERERERERA7gHWxERERERERERGSmQILMRQ6E8A42IiKtKRptRERE1miVZ5yYay5cuIARI0ZAr9cjICAAY8eORXFxcY0xS5YsQZ8+faDX6yFJEvLz853XQCIiqpGiSJpsroQdbEREREREpKkRI0Zg7969yMzMxNq1a7F582aMHz++xpjS0lIkJCTglVdeqaNWEhERaYdDRImINMZFDoiIyJnq+yIH+/btQ0ZGBnbs2IHu3bsDAN599130798fc+bMQVhYmNW4CRMmAAA2bdrknIYREZHduIqoON7BRkTkDPV0yA4REd0gNBweWlhYaLGVl5c71LTs7GwEBASYO9cAIC4uDjqdDtu2bXOobiIiqhv1fCaCeokdbERERERELiw8PBz+/v7mbebMmQ7VZzAYEBwcbLHP3d0dgYGBMBgMDtVNRERUXwl3sG3evBn3338/wsLCIEkSVq9ebX6ssrISL7/8Mjp37oyGDRsiLCwMI0eOxKlTp2qsMzU1FZIkWWyRkZHCT4aIqF7g1z0OYZ4hIqqFxoscHD9+HAUFBeZtypQpVg87efLkaufSq7f9+/c77WlrhXmGiKh2piGijm6uRHgOtpKSEnTt2hWPP/44HnroIYvHSktLsXv3brz66qvo2rUrLl68iOeffx4DBw7Ezp07a6y3Y8eO+PHHH/9umDunhyOi6xPnYHMM8wwRUc20noNNr9dDr9fXWv6FF17A6NGjayzTqlUrhIaG4syZMxb7q6qqcOHCBYSGhqptrmaYZ4iIaif/b3O0DlcifNbv168f+vXrZ/Uxf39/ZGZmWuxbuHAhevTogdzcXDRv3tx2Q9zd60XCJSKia4t5hoiofgoKCkJQUFCt5WJjY5Gfn49du3YhOjoaALBhwwbIsoyYmBhnN7NWzDNEROQMTp+DraCgAJIkISAgoMZyBw8eRFhYGFq1aoURI0YgNzfXZtny8vJqk7ESEdUbHCJap5yRZwDmGiKqxzQeIqq19u3bIyEhAePGjcP27dvx888/IykpCcOGDTOvIHry5ElERkZi+/bt5jiDwYCcnBwcOnQIAPD7778jJycHFy5ccE5D7cQ8Q0SuSFEkTTZX4tT7lsvKyvDyyy9j+PDhNd52HhMTg2XLlqFdu3Y4ffo0pk+fjjvuuAN79uyBn59ftfIzZ87E9OnTHW+f4iYck29sIBxzvsJXOOZcmXjMhVIf4ZjiUm/hmMpLHsIxSrl4X65UKR6jqxL/A5aMwiGXyXV0slAxBkRR0XWu4s8Bsof4gWQP8dNOVYV4TIVgjFyq4gWwgUNE646z8gxgO9c0dvOB3s3+936RUmZ3WZMKFX+QZ1XkmvwK8Zx2urD2YWRXKysXzxtylfj5xXhJu7/jmuhKxI8jGdXlDMVd/GQgqRiPoebzr+Ip3jbZS7xxcqWKxqnIg7K3eFCBQFljqXafG7QeIuoMK1asQFJSEvr27QudTodBgwbhnXfeMT9eWVmJAwcOoLS01LwvLS3N4rx75513AgA+/vjjWoemOsu1yDPDfsuBJNn/ftwU297usiYFlxoKx/xnb1fhmL+M/xWOmdtqkHDMl8eFQ/DeR7cKx9zhLX6H4lt5G4VjPmwbJRyT5BsiHAMAY389KhwT7zNYOEbNnT3fY7VwzDutH6q90FVOXvIUjvH12Scc82Ou7Ttgbdmp/C5UXlaqhI9huy7H51DjHGwaqaysxJAhQ6AoChYvXlxj2Stv0e7SpQtiYmLQokULfPHFFxg7dmy18lOmTEFycrL558LCQoSHh2vXeCIiqvecmWcA5hoiIkcEBgYiPT3d5uMRERFQFMsevtTUVKSmpjq5ZfZjniEiIhFOGSJqSkbHjh1DZmamXZOmXikgIAA333yz+fbwq3l5eZknY7V3UlYiojpTj4ftmFy4cAEjRoyAXq9HQEAAxo4di+Li4hpjlixZgj59+kCv10OSJOTn52tSrxrOzjMAcw0R1WP1fIjojYB5hohcHdOMOM072EzJ6ODBg/jxxx/RuHFj4TqKi4tx+PBhNG3aVOvmERE533WQjUaMGIG9e/ciMzMTa9euxebNmzF+/PgaY0pLS5GQkIBXXnlF03pFMc8QkctjB5tTMc8QEf09RNTRzZUIDxEtLi62+CbmyJEjyMnJQWBgIJo2bYqHH34Yu3fvxtq1a2E0GmEwGABcvk3c0/Py2Oa+ffviwQcfRFJSEgDgxRdfxP33348WLVrg1KlTSElJgZubG4YPH67FcyQioivs27cPGRkZ2LFjB7p37w4AePfdd9G/f3/MmTPHPAH11SZMmAAA2LRpk6b1Xo15hoiInIl5hoiInEG4g23nzp246667zD+b5g0YNWoUUlNTsWbNGgBAVFSURdzGjRvRp08fAMDhw4dx7tw582MnTpzA8OHDcf78eQQFBaFXr17YunWrXcuAExHVN1oucnD1imJeXl7w8vJyqO7s7GwEBASYO8EAIC4uDjqdDtu2bcODDz54TetlniEiqtn1sMhBfcY8Q0RUO/l/m6N1uBLhDrY+ffpUm5D0SjU9ZnL06FGLn1euXCnaDCKi+kuLYTf/i796suOUlBSHJ4A2GAwIDg622Ofu7o7AwEDzt/TXsl7mGSKiWmg1vNNFO9iYZ4iIaqcoEhQHh3g6Gn+9cdoqokRE5Ljjx49bTHpc091rkydPxptvvlljffv2iS8pTkRERERERDVjBxsRkdY0vINNZFWxF154AaNHj66xTKtWrRAaGoozZ85Y7K+qqsKFCxcQGhqqprUA4LR6iYjoKryDjYiInEyB40M8XS3NsIONiEhjWs7BJiIoKMiuuV5iY2ORn5+PXbt2ITo6GgCwYcMGyLKMmJgY8QM7uV4iIrLEOdiIiMjZFGgwRBSuNURUd60bQEREdat9+/ZISEjAuHHjsH37dvz8889ISkrCsGHDzCt9njx5EpGRkdi+fbs5zmAwICcnx7zy2u+//46cnBxcuHDB7nqJiIiIiIhuROxgIyLSmqLR5kQrVqxAZGQk+vbti/79+6NXr15YsmSJ+fHKykocOHAApaWl5n1paWno1q0bxo0bBwC488470a1bN/Nqa/bUS0REGtAqz/AONiIiskFWtNlcCTvYiIg0Zhq64+jmTIGBgUhPT0dRUREKCgqwdOlS+Pr6mh+PiIiAoijo06ePeV9qaioURam2XTnvW231EhGR47TKMxwiSkREtlzL73EWLVqEiIgIeHt7IyYmxmJUjTWrVq1CZGQkvL290blzZ6xfv97i8a+//hr33nsvGjduDEmSkJOTU62OsrIyPPPMM2jcuDF8fX0xaNAg5OXlCbXbpedgK1E8hWPOVfkJxxjKxGPOlohfkBYWNRCOqSrxEI6RLon3y7qVi8foKoVDoKsSj5GM6saFS47O+GgnRVLRPhVd57Kb+OlPcXcTP46H+HFkL/EnVOEl1jb5Eq8yyDn+qgwUjtl76SbhmIsV4jngdJF9C2hcqbjIWzhGLhc/V+gKxT+i6FT8GesqxM+xbmUqzssqTzFqcpQintqhZooVRUXegKIiQakIMXqpyDUq3gvlIvVfqqMPDnTd89B5Q5LsP2+O2xEgfAxPFSeKk3K2cExvr4eFY+69+Q/hmM15XYVjvh61QzhmxNJ+wjEvhtwpHHN71GbhmH0HbhaOAYD1fc8Kx8zaEiEcU2YUPy9HKLcKxxhVJLQH2xwSjvnmQKRwTEvf0toLXeXCqSNC5RXl+s81n3/+OZKTk5GWloaYmBgsWLAA8fHxOHDgAIKDg6uV37JlC4YPH46ZM2fivvvuQ3p6OhITE7F792506tQJAFBSUoJevXphyJAh5tE4V5s4cSLWrVuHVatWwd/fH0lJSXjooYfw888/2912l+5gIyJyCi2G3bC/j4iIbNFqeCdzDRER2SArEmQHFzlQEz9v3jyMGzcOY8aMAXB5mpp169Zh6dKlmDx5crXyb7/9NhISEjBp0iQAwIwZM5CZmYmFCxciLS0NAPDYY48BAI4ePWr1mAUFBfjoo4+Qnp6Ou+++GwDw8ccfo3379ti6dStuu+02u9rOIaJERFrjvDhERORMnIONiIicTNZoA4DCwkKLrbzc+j3gFRUV2LVrF+Li4sz7dDod4uLikJ1t/S7a7Oxsi/IAEB8fb7O8Nbt27UJlZaVFPZGRkWjevLlQPexgIyIiIiIiIiIipwgPD4e/v795mzlzptVy586dg9FoREhIiMX+kJAQGAwGqzEGg0GovK06PD09ERAQ4FA9HCJKRKQx6X+bo3UQERFZo0WeMdVDRERkjaJIUBwcImqKP378OPT6v+f+9fLycqje+oodbEREWuMcbERE5Eycg42IiJzsyiGejtQBAHq93qKDzZYmTZrAzc2t2uqdeXl5CA0NtRoTGhoqVN5WHRUVFcjPz7e4i020Hg4RJSIiIiIiIiKia8rT0xPR0dHIysoy75NlGVlZWYiNjbUaExsba1EeADIzM22WtyY6OhoeHh4W9Rw4cAC5ublC9fAONiIijUnK5c3ROoiIiKzRIs+Y6iEiIrJGUS5vjtYhKjk5GaNGjUL37t3Ro0cPLFiwACUlJeZVRUeOHIlmzZqZ53F7/vnn0bt3b8ydOxcDBgzAypUrsXPnTixZssRc54ULF5Cbm4tTp04BuNx5Bly+cy00NBT+/v4YO3YskpOTERgYCL1ej2effRaxsbF2ryAKsIONiEh7HCJKRETOxCGiRETkZDIkyA7O1qkmfujQoTh79iymTZsGg8GAqKgoZGRkmBcyyM3NhU7392DMnj17Ij09HVOnTsUrr7yCtm3bYvXq1ejUqZO5zJo1a8wddAAwbNgwAEBKSgpSU1MBAPPnz4dOp8OgQYNQXl6O+Ph4vPfee0JtZwcbERERERERERHVC0lJSUhKSrL62KZNm6rtGzx4MAYPHmyzvtGjR2P06NE1HtPb2xuLFi3CokWLRJpqgR1sRETOwLsCiIjImZhniIjIiWTl8uZoHa6EHWxERBrjHGxERORMnIONiIicToM52FztyyCuIkpEREREREREROQAl76DLd/YQDjGUO4vHlOiF47JLxRvW1Whp3CMW5GbeEyZcAjcysQnN9RViR9HVykeI8niMY7EiVLUzCupIkZxEw+SVZxBZA8Vx/EU/+rD6C32/YFcpuHpkIsc3NB0kKBzcMLX2pQaxc/np4rF89PFgobCMXKp+N+Ke754jJoc4FEk/ntRVHzV6F4qHiN7iMcAdZcLZfGPA5C96ub1VpMH3S6JB1X4i5945SKB9/alepZnTPVQvdPQLQg6yf73S4gifv5v4C7+R5+ntBCOGdhU/E32jw3thWPS4nKEY55bcb9wzOpZacIxD04ZJxzzlFeFcMwrv4lfcwJAr0ZhwjGzH/5OOGbfHvHf63O7xN/bK08YhWMA8fd2l0b5wjEfHwoQjunp3l+ofJVSgf9UfSx8HGuu1SIH1zOX7mAjInIGDhElIiJn4hBRIiJyNkWDIaIODzG9zgh/j7h582bcf//9CAsLgyRJWL16tcXjo0ePhiRJFltCQkKt9S5atAgRERHw9vZGTEwMtm/fLto0IiK6ATDPEBGRMzHPEBGRMwh3sJWUlKBr1641Ll2akJCA06dPm7fPPvusxjo///xzJCcnIyUlBbt370bXrl0RHx+PM2fOiDaPiOjaUzTaXBTzDBFRLbTKMy6aa5hniIhqJ2u0uRLhIaL9+vVDv379aizj5eWF0NBQu+ucN28exo0bhzFjxgAA0tLSsG7dOixduhSTJ08WbSIR0TXFIaKOYZ4hIqoZh4g6hnmGiKh2snJ5c7QOV+KUVUQ3bdqE4OBgtGvXDk8//TTOnz9vs2xFRQV27dqFuLi4vxul0yEuLg7Z2dlWY8rLy1FYWGixERGR63B2ngGYa4iIXBnzDBERidK8gy0hIQGffPIJsrKy8Oabb+Knn35Cv379YDRaX83j3LlzMBqNCAkJsdgfEhICg8FgNWbmzJnw9/c3b+Hh4Vo/DSIi9Thsx6nqIs8AzDVEVI9xiKhTMc8QETHNqKH5KqLDhg0z/7tz587o0qULWrdujU2bNqFv376aHGPKlClITk42/1xYWMiERET1hxbZxNWykYC6yDMAcw0R1WNaXbUw11jFPENEZBoiKjlchytxyhDRK7Vq1QpNmjTBoUOHrD7epEkTuLm5IS8vz2J/Xl6ezXkPvLy8oNfrLTYiInJNzsgzAHMNERFdxjxDRET2cHoH24kTJ3D+/Hk0bdrU6uOenp6Ijo5GVlaWeZ8sy8jKykJsbKyzm0dEpDnT5NOObmQf5hkicjVa5RnmGvswzxCRK1IUbTZXItzBVlxcjJycHOTk5AAAjhw5gpycHOTm5qK4uBiTJk3C1q1bcfToUWRlZeGBBx5AmzZtEB8fb66jb9++WLhwofnn5ORkfPDBB1i+fDn27duHp59+GiUlJeZVeIiIriucsMAhzDNERLXgHGwOYZ4hIqqdrNHmSoTnYNu5cyfuuusu88+meQNGjRqFxYsX47fffsPy5cuRn5+PsLAw3HvvvZgxYwa8vLzMMYcPH8a5c+fMPw8dOhRnz57FtGnTYDAYEBUVhYyMjGoThRIR0Y2PeYaIiJyJeYaIiJxBuIOtT58+UGq4z+/777+vtY6jR49W25eUlISkpCTR5hAR1TuSokBy8H5oR+OvZ8wzREQ10yLPmOpxRcwzRES102KIp6ulGc1XEb2enK0Sn0g0t7SRcMyZfF/hGONFr9oLXcUzX3xKPfdi8VVB3MuEQ6ArF49xqxD/a5Ssr55eI52KGAD1eliFomJ2RVUxKs4gRg/x95zsJR5T5S1W3lju2Ao5FriK6A2tSC4DZPv/YI5WiK8Id/JSgHDMucKGwjHGIg/hGI8LbsIxbhUqck2xcAjcKlTElIv/salZUMsrXzwGAIye6uJEuakYw6FcUnEgFa+d0VM8yCj+MQpeRhW5xtf+c4FcpuHUx1xF9IaW4NMRnjr738SrS3cIH+Mxv+7CMf/JPy8cM+2EQThmZrj4vHXtvs0WjkluGiUcM/LVJ4VjBt4kfrLski5+52N6VL5wDADclf2JcMzcNPHj3O7TWzjmqLRbOOYOt57CMRMOpwvHNG3QTTimoYrEOaVlgFD5S8ZK/OeA8GGs0mKIp6sNEXX6IgdEREREREREREQ3Mpe+g42IyBm0WJmNK7sREZEtWq0AylxDRES2KAogc4ioEHawERFpjUNEiYjImThElIiInIyXNOI4RJSIiIiIiIiIiMgBvIONiEhjHCJKRETOxCGiRETkbLIGQ0Qdjb/esIONiEhrvJ+aiIiciUNEiYjIyRTF8TnUXG0ONg4RJSJyQRcuXMCIESOg1+sREBCAsWPHori4uMaYJUuWoE+fPtDr9ZAkCfn5+dXKREREQJIki23WrFlOehZERERERET1AzvYiIg0Zhq64+jmTCNGjMDevXuRmZmJtWvXYvPmzRg/fnyNMaWlpUhISMArr7xSY7nXXnsNp0+fNm/PPvuslk0nInJ5WuUZDhElIiJbZI02V8IhokREWqvnQ0T37duHjIwM7NixA927dwcAvPvuu+jfvz/mzJmDsLAwq3ETJkwAAGzatKnG+v38/BAaGqplk4mI6EocIkpERE7GOdjE8Q42IqJ6rLCw0GIrLy93uM7s7GwEBASYO9cAIC4uDjqdDtu2bXO4/lmzZqFx48bo1q0bZs+ejaqqKofrJCIiIiIiqs94BxsRkRNoNewmPDzc4ueUlBSkpqY6VKfBYEBwcLDFPnd3dwQGBsJgMDhU93PPPYdbbrkFgYGB2LJlC6ZMmYLTp09j3rx5DtVLRESWOLyTiIicqZ4PyqmX2MFGRKQ1DZfcOX78OPR6vXm3l5eXzZDJkyfjzTffrLHaffv2OdauWiQnJ5v/3aVLF3h6euLJJ5/EzJkza2w7EREJ0CLPmOohIiKygkNExbl0B9uR8iDxmAuBwjFVZ3yEY7zPugnHeBQKh8CjWPwd714mHuNWIR6jUzGqTFclfhxJ7V99fT5ZSOIhik48SPZQEeMuHmP0FA5BlbfYcYwq3qN1Qa/XW3Sw1eSFF17A6NGjayzTqlUrhIaG4syZMxb7q6qqcOHCBc3nTouJiUFVVRWOHj2Kdu3aaVr39eLgpRDhmL1nxX8P5efEc43XWfGPAR41LzZrlWehilxTKn4cVTlAxZ++rlJNrhE/jlqK+EcIVc9JTd5Qk59Ez+cAUOkjHqPmdasqtf84xnIVT55cUmEl4CFwchrse6vwMT4t2CEco5PEc0Y39BCOef3kfuGYV256WjjmzqZ5wjFHC/2FY77K9RCOGdeki3DMT6fUfZZ9LvQZ4ZhFZ/4tHDOyhXAILpbfJhzTodF54ZiNf4h/7uoutReO+b+Sj4RjXjvWV6i8rFQKH4O049IdbEREzqDFymxq4oOCghAUVPsXB7GxscjPz8euXbsQHR0NANiwYQNkWUZMTIz4gWuQk5MDnU5XbUgqERGpp9UKoBxmSkREtmg4KMdlsIONiEhr9XzCgvbt2yMhIQHjxo1DWloaKisrkZSUhGHDhplXED158iT69u2LTz75BD16XP722WAwwGAw4NChQwCA33//HX5+fmjevDkCAwORnZ2Nbdu24a677oKfnx+ys7MxceJEPProo2jUqJHznhARkavhKqJERORk8v82R+twJVxFlIjIBa1YsQKRkZHo27cv+vfvj169emHJkiXmxysrK3HgwAGUlv49Ti8tLQ3dunXDuHHjAAB33nknunXrhjVr1gC4PD/cypUr0bt3b3Ts2BFvvPEGJk6caFEvERERERHRjYh3sBERaUySHZ9vydnzNQUGBiI9Pd3m4xEREVCuuqc7NTW1xhVMb7nlFmzdulWrJhIRkQ1a5BlTPURERNbI0GCRA01acv1gBxsRkdbq+RBRIiK6znGIKBERORkvacRxiCgREREREREREZEDeAcbEZHGrtUqokRE5Bq4iigRETmbojg+xJOriBIRkWO4pjURETmTFnnGVA8REZEViqLBEFEXSzPCQ0Q3b96M+++/H2FhYZAkCatXr7Z4XJIkq9vs2bNt1pmamlqtfGRkpPCTISKi6x/zDBERORPzDBEROYPwHWwlJSXo2rUrHn/8cTz00EPVHj99+rTFz9999x3Gjh2LQYMG1Vhvx44d8eOPP/7dMHfeXEdE1ycOEXUM8wwRUc04RNQxzDNERLWT4fgQUa4iWot+/fqhX79+Nh8PDQ21+Pn//u//cNddd6FVq1Y1N8TdvVosEdF1iUvuOIR5hoioFlxF1CHMM0REtZMVQHYwUcgulmecuopoXl4e1q1bh7Fjx9Za9uDBgwgLC0OrVq0wYsQI5Obm2ixbXl6OwsJCi42IiFyPs/IMwFxDRETMM0REZD+n3re8fPly+Pn5Wb31+koxMTFYtmwZ2rVrh9OnT2P69Om44447sGfPHvj5+VUrP3PmTEyfPt3h9u2+GC4cU3pMLxzje1y8H9P7nHhXr2ex+A2Y7qXiMW7l4jG6CqNwjGQUfw0ko3jbVA+PqM8zNkqScIgiHgLFXfy9rbiJx8ie4jFVPm5i5SvF36O2cIho3XFWngFs55qGOi/46ux/T+ZcvMnusiZFx/yFY3xP1k2u8SgVj3ErF49xv6RiUIGK87KuUkWMilwjqzj3AYCk4qtfSU1+UpFz1eQaNSoCPIRjvArEn0+Vj/jvyOhp/2tgrNRuoAyHiNada5Fnsip+hiTZ/znmhUa97C5rMlS6VTjGQ8UbpnnDSuGY8ItdhGN2XhA/TlOfRsIx7506LxzTShciHGO4JH4++uDcR8IxAODn1UI45navh4VjDJfEz+UnS8U+zwOAt5v4Z6gFLWOFY5448G/hmCH6J4Rj/qg8K1TeqIj/LdjCQTninHoH29KlSzFixAh4e3vXWK5fv34YPHgwunTpgvj4eKxfvx75+fn44osvrJafMmUKCgoKzNvx48ed0XwiInVMq7s5ulGtnJVnAOYaIqrHtMozzDW1Yp4hIlclK9psrsRpd7D95z//wYEDB/D5558LxwYEBODmm2/GoUOHrD7u5eUFLy8vR5tIRETXMWfmGYC5hojI1THPEBGRCKfdwfbRRx8hOjoaXbt2FY4tLi7G4cOH0bRpUye0jIjIuUxDdxzdqGbMM0TkqrTKM8w1NWOeISJXpmj0nysR7mArLi5GTk4OcnJyAABHjhxBTk6OxSSehYWFWLVqFZ54wvoY4759+2LhwoXmn1988UX89NNPOHr0KLZs2YIHH3wQbm5uGD58uGjziIiuPUWjzUUxzxAR1UKrPOOiuYZ5hoiodhwiKk54iOjOnTtx1113mX9OTk4GAIwaNQrLli0DAKxcuRKKothMKIcPH8a5c+fMP584cQLDhw/H+fPnERQUhF69emHr1q0ICgoSbR4REV3nmGeIiMiZmGeIiMgZhDvY+vTpA6WWCVHHjx+P8ePH23z86NGjFj+vXLlStBlERPUWVxF1DPMMEVHNuIqoY5hniIhqJ/9vc7QOV+LUVUSJiFwS76cmIiJn0irPODHXXLhwASNGjIBer0dAQADGjh2L4uLiGss/++yzaNeuHXx8fNC8eXM899xzKCgocFobiYjINkVRNNlcCTvYiIiIiIhIUyNGjMDevXuRmZmJtWvXYvPmzTXeEXbq1CmcOnUKc+bMwZ49e7Bs2TJkZGRg7NixddhqIiIi9YSHiBIRUS20mDjatb7sISIiEVotUOCkXLNv3z5kZGRgx44d6N69OwDg3XffRf/+/TFnzhyEhYVVi+nUqRO++uor88+tW7fGG2+8gUcffRRVVVVwd+dlCxFRXeIQUXG8g42ISGMS/p4fR/V2rZ8EERHVW5rkmStyTWFhocVWXl7uUPuys7MREBBg7lwDgLi4OOh0Omzbts3uegoKCqDX69m5RkR0DXCIqDh2sBERERERubDw8HD4+/ubt5kzZzpUn8FgQHBwsMU+d3d3BAYGwmAw2FXHuXPnMGPGjBqHlRIREdUn/DqIiEhrinJ5c7QOIiIia7TIM6Z6ABw/fhx6vd6828vLy2rxyZMn480336yxyn379jncrMLCQgwYMAAdOnRAamqqw/UREZE4BY4P8XS1KxqX7mA7kNNcOKbJbvGBWw1Pi99m71FYIRyjK6sUjpHKq4RjYDSKH6dKPEbVB0djHY7yrs8dIJKKAYZqYnRqYsRvnFXc3YRjPH08hcpXGR0bDnMl09AbR+ug+slgvIQSo/3v49zdzYSPEbRHOAQ+Z8VzgEepeA5wL1Dxt1Ilfm6WVOQaVdTkJxXnMcgq85OHio9qFSo+D5SJf+5QGniriLHecVMTt2Lxthl9xXIAALiXiue0yob2/36qKrX7jKJFnjHVAwB6vd6ig82WF154AaNHj66xTKtWrRAaGoozZ85Y7K+qqsKFCxcQGhpaY3xRURESEhLg5+eHb775Bh4eHrW260az40Ej/ATewo0iPxE+xi/f9RaOOVkQIBzzU16gcMyCx1YLx+TuayMc46YT/5t0k24Wjrkl9KhwzEf7WgvHzIwYJRwDAIvPHhaOeaSZ+Alo7DvfCse8PPoB4ZiPTuULx0gqBvYVTPIRjjGWrRGO0b0hdhdvYWEZbgr7qvaCdpAVBbKDXWRyfb5mdgKX7mAjIiIiIiL7BAUFISgoqNZysbGxyM/Px65duxAdHQ0A2LBhA2RZRkxMjM24wsJCxMfHw8vLC2vWrIG3t3gnLhER0bXCOdiIiLSmaLQRERFZo1WecVKuad++PRISEjBu3Dhs374dP//8M5KSkjBs2DDzCqInT55EZGQktm/fDuBy59q9996LkpISfPTRRygsLITBYIDBYICxru5oJSIiM0Wj/1wJ72AjItKYpCiQHLwd2tF4IiK6cWmRZ0z1OMuKFSuQlJSEvn37QqfTYdCgQXjnnXfMj1dWVuLAgQMoLS0FAOzevdu8wmibNpbD/Y4cOYKIiAintZWIiKqT4fgcbHU4gVO9wA42IiIiIiLSVGBgINLT020+HhERAeWKDr4+ffpY/ExERHS9YQcbEZHW+HUPERE5kxZ5xlQPERGRFTI0WOTAxYaIcg42IiKNmYbuOLoRERFZo1WeYa4hIiJbZEXRZFNj0aJFiIiIgLe3N2JiYszzddqyatUqREZGwtvbG507d8b69estHlcUBdOmTUPTpk3h4+ODuLg4HDx40KJMREQEJEmy2GbNmiXUbnawERERERERERHRNff5558jOTkZKSkp2L17N7p27Yr4+HicOXPGavktW7Zg+PDhGDt2LH755RckJiYiMTERe/bsMZd566238M477yAtLQ3btm1Dw4YNER8fj7KyMou6XnvtNZw+fdq8Pfvss0JtZwcbEZHW6vHKbkREdAOo56uIEhHR9e9arSI6b948jBs3DmPGjEGHDh2QlpaGBg0aYOnSpVbLv/3220hISMCkSZPQvn17zJgxA7fccgsWLlx4+XkoChYsWICpU6figQceQJcuXfDJJ5/g1KlTWL16tUVdfn5+CA0NNW8NGzYUajs72IiItKYo2mxERETWaJVnmGuIiMgG0xxsjm4AUFhYaLGVl5dbPWZFRQV27dqFuLg48z6dToe4uDhkZ2dbjcnOzrYoDwDx8fHm8keOHIHBYLAo4+/vj5iYmGp1zpo1C40bN0a3bt0we/ZsVFVVCb1mXOSAiIiIiIiIiIicIjw83OLnlJQUpKamVit37tw5GI1GhISEWOwPCQnB/v37rdZtMBisljcYDObHTftslQGA5557DrfccgsCAwOxZcsWTJkyBadPn8a8efPse5LgHWxERJqTFG02Z7pw4QJGjBgBvV6PgIAAjB07FsXFxTWWf/bZZ9GuXTv4+PigefPmeO6551BQUGBRLjc3FwMGDECDBg0QHByMSZMmCX/zQ0RENdMqzzg71xAR0fVLyzvYjh8/joKCAvM2ZcqUa/zsqktOTkafPn3QpUsXPPXUU5g7dy7effddm3fbWcM72IiItKbFsBsnD9sZMWIETp8+jczMTFRWVmLMmDEYP3480tPTrZY/deoUTp06hTlz5qBDhw44duwYnnrqKZw6dQpffvklAMBoNGLAgAEIDQ3Fli1bcPr0aYwcORIeHh7417/+5dTnQ0TkUrQa3skhokREZIPaOdSurgMA9Ho99Hp9reWbNGkCNzc35OXlWezPy8tDaGio1ZjQ0NAay5v+n5eXh6ZNm1qUiYqKstmWmJgYVFVV4ejRo2jXrl2tbQdusA62B2/uDHfJw+7ybbDVia2pe/K1bgDRdUxWKq91E+rMvn37kJGRgR07dqB79+4AgHfffRf9+/fHnDlzEBYWVi2mU6dO+Oqrr8w/t27dGm+88QYeffRRVFVVwd3dHT/88AP++OMP/PjjjwgJCUFUVBRmzJiBl19+GampqfD09Kyz5+hMyf0Gw13nZXf5Nmd+FT6GXFoqHCN5iL++krf9z8NMFs82Or2fcExV3lnhGDXcAgPEg4x1mHF1knCI8WJB7YU0oOa1ky6IH0fnLv5xVaem46hCPA94NfK3u2yVbP834OTaSosbws3D/vf9ntXxwse4KztROCby+VeFYw6t7Scc83+ZfYVjNhrE88wHn3wpHNPW11B7oat49j4kHNOmYX/hmF+KGwnHAMCpSvHPKWP/+ZP4gc6KD56bf3qJcIxOJzYpPQDc7T1UOKbHwtuFY4qki8Ixf7WZLlS+4tL1/cWJp6cnoqOjkZWVhcTERACALMvIyspCUlKS1ZjY2FhkZWVhwoQJ5n2ZmZmIjY0FALRs2RKhoaHIysoyd6gVFhZi27ZtePrpp222JScnBzqdDsHBwXa3n0NEiYg0JsnabID9E4KKyM7ORkBAgLlzDQDi4uKg0+mwbds2u+spKCiAXq+H+/8ufrOzs9G5c2eL+Q3i4+NRWFiIvXv3OtxuIiK6TKs8Y8o1REREV1M0GB6q5g645ORkfPDBB1i+fDn27duHp59+GiUlJRgzZgwAYOTIkRZDTJ9//nlkZGRg7ty52L9/P1JTU7Fz505zh5wkSZgwYQJef/11rFmzBr///jtGjhyJsLAwcydednY2FixYgF9//RV//fUXVqxYgYkTJ+LRRx9Fo0b2d14LdbDNnDkTt956K/z8/BAcHIzExEQcOHDAokxZWRmeeeYZNG7cGL6+vvj/9u49KKrz4OP4b0G5NHIJFUQmqKhJ0Nhoi4o0NrWRAiGTiQlN1SFtzDjSC5jxNo6ZiZeqKWPqNBlTL5O3KdaJ1NZ0NNFpSYlWbIxiiq9pbA1jUxuNuF4DCxi57Xn/4N2NGy6ye86ywH4/Mzsju+c8PPtw4Od59rnk5eV1GK73ZYZhaNWqVRo+fLgiIyOVmZmpM2fOeFM1AOg7LNzZLTk5WTExMe5HcXGx6erZ7fYOn8QMGjRIcXFxHgt9dufq1atat26dCgoKPMrtbPFQ12s9Qc4AQA+wi6gpZA0A3J7T5rTk4a3Zs2dr48aNWrVqlSZNmqSTJ0+qrKzMfV9x7tw5Xbx40X38N7/5TZWWlurVV1/VxIkT9cYbb2jv3r2aMGGC+5jly5dr4cKFKigo0JQpU9TQ0KCysjJFRERIksLDw7Vr1y59+9vf1n333acXXnhBixcv1quvejeK0qsOtoqKChUWFurYsWPudXuysrLU2NjoPmbx4sXat2+fdu/erYqKCtXU1OiJJ57ottwXX3xRmzZt0rZt21RZWak77rhD2dnZunnzpldvBgAGGm8WBF2xYoVsNlu3j6523/GGw+HQI488ovHjx3e6+48Z5AwAwN/IGgDo24qKivTJJ5+oqalJlZWVSk9Pd7926NAhbd++3eP4J598UtXV1WpqatKpU6eUm+s5zdpms2nt2rWy2+26efOm3nnnHd1zzz3u17/xjW/o2LFjqq2t1eeff65//etfeu655xQe7t1yKl4talFWVubx9fbt25WQkKCqqio9+OCDqqur02uvvabS0lI99NBDkqSSkhKNGzdOx44d07Rp0zqUaRiGXn75ZT3//PN67LHHJEk7duzQsGHDtHfvXs2ZM8erNwQAAWf8/8NsGer5gqCStHTpUs2bN6/bY0aPHq3ExERdvnzZ4/nW1lZdv369y8VDXerr65WTk6OoqCjt2bNHgwd/se5lYmKijh8/7nG869P+25XrQs4AQA9YkTOucoIQWQMAt+eUIZvJoHAGWdCYWoOtrq59Ed24uDhJUlVVlVpaWpSZmek+JjU1VSNGjNDRo0c7LePs2bOy2+0e58TExCg9Pb3Lc5qamjqsSwQAfYXNMCx5eCs+Pl6pqandPsLCwpSRkaHa2lpVVVW5zz148KCcTqfHp0Nf5nA4lJWVpbCwML311lvuIdUuGRkZ+vDDDz0678rLyxUdHa3x48d7/X6kwOWMRNYA6LusyhlfsmYg4p4GADoyvwJb+yOY+NzB5nQ6tWjRIj3wwAPuua12u11hYWGKjY31OHbYsGFdrr/jer6zdXu6Oqe4uNhjTaLk5GRf3wYABJ1x48YpJydHCxYs0PHjx3XkyBEVFRVpzpw57h1EL1y4oNTUVPeINFfnWmNjo1577TU5HA7Z7XbZ7Xa1tbVJkrKysjR+/Hj94Ac/0AcffKC3335bzz//vAoLC70eXi0FNmcksgYAggH3NAAAq/jcwVZYWKhTp05p165dVtanR5577jmPNYnOnz/f63UAgC71g4Wnd+7cqdTUVM2cOVO5ubmaPn26xyKeLS0tqq6u1o0bNyRJJ06cUGVlpT788EONHTtWw4cPdz9cf4NDQ0O1f/9+hYaGKiMjQ0899ZR++MMfau3atT7VMZA5I5E1APowNjmwDPc0ANA5p8T4NS95tQabS1FRkfbv36/Dhw/rrrvucj+fmJio5uZm1dbWenzic+nSpS7X33E9f+nSJQ0fPtzjnEmTJnV6Tnh4uE+jIQCgVxiS6TTx8z1PXFycSktLu3x91KhRMm658ZoxY4bH110ZOXKk/vSnP5muX6BzRiJrAPRhVuSMq5wgFuisIWcA9GVOm1M2H3YB9SgjyLrYvBrBZhiGioqKtGfPHh08eFApKSker6elpWnw4ME6cOCA+7nq6mqdO3dOGRkZnZaZkpKixMREj3McDocqKyu7PAcAMDCRMwAAfyNrAAD+4NUItsLCQpWWlurNN99UVFSUez2BmJgYRUZGKiYmRvPnz9eSJUsUFxen6OhoLVy4UBkZGR677aSmpqq4uFiPP/64bDabFi1apPXr1+vuu+9WSkqKVq5cqaSkJM2aNcvSNwsAvcGKhaODdeFpcgYAbs+qDQrIGrIGALrilFM2kyPQgm0Em1cdbFu3bpXUPlXoViUlJZo3b54k6aWXXlJISIjy8vLU1NSk7OxsbdmyxeP46upq9249krR8+XI1NjaqoKBAtbW1mj59usrKyjrsUAcA/YIh8+vaBOc9DzkDAD1hRc64yglCZA0A3B4dbN7zqoOtJ+vvREREaPPmzdq8eXOPy7HZbFq7dq3PC2G7ymtVS9D+RwGAOa1qkdSzv3Pwn76aM7eW2eps9uo8p+Hd8e3ntHh9js2w9co5Mrz/j1KIl20mSa0+tIEvDB/q5ksb+Mzp/c+orS+3nQ9sTu/b26e/5b783jmbenys628HORN4fTVrXOU1tLR5dV5jq/fXrsNxw+tz6pu9/1286cPfic/bvD+n2YvfRRfHDR/+tti8+9n8/1len+HL/wPafPj/hiQZPmSa43Mf/o7ZvD/H8KHtfPkb2+pD27XJ+5+RU61en+NtW9ffbD+erAkMnzY56Gvq6+slSe/K/MLaAIJbfX29YmJizBVixc5shGKf48qaQ+f/J8A16YIvfSq90w8jNfbS9/HFtUBXoB+j7aTPvD+lz+SMqxz0Ga6cmV72v16e+Xfvv1nsm96f45Nf99L38V7pk76cZbe6Gp36z40/98r38dVXfxToGnTNlw82//r5a36oiTWGLvftPCuyxop9QINtH9EB0cGWlJSk8+fPKyoqSjab5ye9DodDycnJOn/+vKKjowNUw8CiDWgDiTaQum8DwzBUX1+vpKQk89/IKcmHgUEdykCf0lXW8LtFG7jQDrSB1HUb9LmccZWDPoN7mu7RBrSBRBtIvXdPwy6i3hsQHWwhISEeW2t3Jjo6Omh/AV1oA9pAog2krtvA9IgCDGi3yxp+t2gDF9qBNpA6bwNyBt3hnqZnaAPaQKINJO5p+qIB0cEGAH0Ju4gCAPyJXUQBAP5myGl6BBpTRAEA5rAGGwDAn1iDDQDgZ4baZCjEdBnBxFxr9QPh4eFavXq1wsPDA12VgKENaAOJNpBoA/gH1xVt4EI70AYSbQD/4LqiDSTaQKINJNqgL7MZ7N8KAJZwOByKiYnRzPHLNCjUXOC1tjXpwL82qq6uLujXlwAAtLMyZySyBgDQkStrRt7xXYXYBpsqy2m06JPG8qDJGaaIAoDVmCIKAPAnpogCAPzMKUNmt5tuLyN4DPgpogAAAAAAAIA/MYINAKzmlGSzoAwAADpjRc64ygEAoBPtmxyYC5tg2+SADjYAsJjNMGQzOe3G7PkAgIHLipxxlQMAQGeccsr8FNHg+iRnQE8R3bx5s0aNGqWIiAilp6fr+PHjga5Sr1qzZo1sNpvHIzU1NdDV8qvDhw/r0UcfVVJSkmw2m/bu3evxumEYWrVqlYYPH67IyEhlZmbqzJkzgamsn9yuDebNm9fhusjJyQlMZf2kuLhYU6ZMUVRUlBISEjRr1ixVV1d7HHPz5k0VFhbqq1/9qoYMGaK8vDxdunQpQDVGfxbMWUPOkDPkDDkD/yNngitnJLJGImvImf5pwHaw/f73v9eSJUu0evVqnThxQhMnTlR2drYuX74c6Kr1qvvuu08XL150P959991AV8mvGhsbNXHiRG3evLnT11988UVt2rRJ27ZtU2Vlpe644w5lZ2fr5s2bvVxT/7ldG0hSTk6Ox3Xxu9/9rhdr6H8VFRUqLCzUsWPHVF5erpaWFmVlZamxsdF9zOLFi7Vv3z7t3r1bFRUVqqmp0RNPPGFNBVyLT5t9oM8ja8iZLyNn2pEz/SRnyJo+j5wJvpyRyBqJrAl4zkgy5LTkEUxshjEwkzU9PV1TpkzRr371K0mS0+lUcnKyFi5cqBUrVgS4dr1jzZo12rt3r06ePBnoqgSEzWbTnj17NGvWLEntn/QkJSVp6dKlWrZsmSSprq5Ow4YN0/bt2zVnzpwA1tY/vtwGUvunPbW1tR0+BRrIrly5ooSEBFVUVOjBBx9UXV2d4uPjVVpaqu9973uSpI8++kjjxo3T0aNHNW3aNJ++j2tL68wxizQoNNxUnVvbmvTOxy8HzZbW/VWwZw05Q86QM+36Y85IZE1/QM4Ed85IZI1E1ki9lzPSF1kz7I5vKsRmblUxp9GqS43vBU3ODMgRbM3NzaqqqlJmZqb7uZCQEGVmZuro0aMBrFnvO3PmjJKSkjR69Gjl5+fr3Llzga5SwJw9e1Z2u93juoiJiVF6enrQXReHDh1SQkKC7r33Xv3kJz/RtWvXAl0lv6qrq5MkxcXFSZKqqqrU0tLicS2kpqZqxIgRQXctwHdkTTty5gvkzBfIGXIG5pEz7cgZT2TNF4Ipa8iZ/mFAdrBdvXpVbW1tGjZsmMfzw4YNk91uD1Ctel96erq2b9+usrIybd26VWfPntW3vvUt1dfXB7pqAeH62Qf7dZGTk6MdO3bowIED2rBhgyoqKvTwww+rrW1g7vDidDq1aNEiPfDAA5owYYKk9mshLCxMsbGxHsdadi0wbScokDXkzJeRM+3ImX6UM2RNn0bOkDOdIWvaBVPWBCRnxBRRX7CL6AD28MMPu/99//33Kz09XSNHjtQf/vAHzZ8/P4A1QyDdOmz8a1/7mu6//36NGTNGhw4d0syZMwNYM/8oLCzUqVOnenm9DituWrjpQd9HzqAz5ExvsKpzjKxB30bOoCvBlDWByRnJabRJsllQRvAYkCPYhg4dqtDQ0A47aFy6dEmJiYkBqlXgxcbG6p577tG///3vQFclIFw/e64LT6NHj9bQoUMH5HVRVFSk/fv3669//avuuusu9/OJiYlqbm5WbW2tx/HBfi3AO2RNR+QMOdMZcuYLwX4twDvkTEfBnjMSWdOVgZo15Ez/MiA72MLCwpSWlqYDBw64n3M6nTpw4IAyMjICWLPAamho0Mcff6zhw4cHuioBkZKSosTERI/rwuFwqLKyMqivi08//VTXrl0bUNeFYRgqKirSnj17dPDgQaWkpHi8npaWpsGDB3tcC9XV1Tp37pw11wLTdoICWdMROUPOdIacadcnc4as6dPImY6CPWcksqYrAy1rAp4zYoqoLwbsFNElS5bo6aef1uTJkzV16lS9/PLLamxs1DPPPBPoqvWaZcuW6dFHH9XIkSNVU1Oj1atXKzQ0VHPnzg101fymoaHB41OLs2fP6uTJk4qLi9OIESO0aNEirV+/XnfffbdSUlK0cuVKJSUleexI09911wZxcXH62c9+pry8PCUmJurjjz/W8uXLNXbsWGVnZwew1tYqLCxUaWmp3nzzTUVFRbnXIYiJiVFkZKRiYmI0f/58LVmyRHFxcYqOjtbChQuVkZFhascdN6ch09NunNz09AfBnjXkDDkjkTP9Nmfc5aAvI2eCL2ckskYiawKeM3J1sJmb4kkH2wAxe/ZsXblyRatWrZLdbtekSZNUVlbWYTHIgezTTz/V3Llzde3aNcXHx2v69Ok6duyY4uPjA101v/n73/+u73znO+6vlyxZIkl6+umntX37di1fvlyNjY0qKChQbW2tpk+frrKyMkVERASqypbrrg22bt2qf/zjH/rtb3+r2tpaJSUlKSsrS+vWrVN4eHigqmy5rVu3SpJmzJjh8XxJSYnmzZsnSXrppZcUEhKivLw8NTU1KTs7W1u2bOnlmqK/C/asIWfIGYmcuRU5A6uRM8GXMxJZI5E15Ez/ZDMMxoYDgBUcDodiYmKUOeKnGhRiLtxbnU1659wW1dXVKTo62qIaAgD6MytzRiJrAAAdubLmzsiJstlCTZVlGG367PMPgiZnBuwINgAIGCvWteGzDwBAV6xaP42sAQB0oX16p7ldRINtiuiA3OQAAAAAAAAA6C2MYAMAq7HJAQDAn9jkAADgZ4ZhboMDq8roT+hgAwCrMUUUAOBPTBEFAPiZU07ZmCLqFaaIAgAAAAAAACYwgg0ArGbIghFsltQEADAQWZEzrnIAAOiEYViwyYERXCPY6GADAKsxRRQA4E9MEQUA+JkhC9Zgs6CM/oQpogAQhK5fv678/HxFR0crNjZW8+fPV0NDQ7fHL1y4UPfee68iIyM1YsQIPfvss6qrq/M4zmazdXjs2rXL328HAAAAAAKKEWwAYDWnUzK7oKfTv8Op8/PzdfHiRZWXl6ulpUXPPPOMCgoKVFpa2unxNTU1qqmp0caNGzV+/Hh98skn+vGPf6yamhq98cYbHseWlJQoJyfH/XVsbKw/3woABB8rcsZdDgAAHRmGIbNZYwTZSGk62ADAan18iujp06dVVlam999/X5MnT5YkvfLKK8rNzdXGjRuVlJTU4ZwJEyboj3/8o/vrMWPG6IUXXtBTTz2l1tZWDRr0RZzExsYqMTHRb/UHgKDHFFEAgJ9ZsQMou4gCAPoMh8Ph8WhqajJd5tGjRxUbG+vuXJOkzMxMhYSEqLKyssfl1NXVKTo62qNzTZIKCws1dOhQTZ06Vb/5zW+C7pMrAAAAAMGHEWwAYDULR7AlJyd7PL169WqtWbPGVNF2u10JCQkezw0aNEhxcXGy2+09KuPq1atat26dCgoKPJ5fu3atHnroIX3lK1/RX/7yF/30pz9VQ0ODnn32WVN1BgDcghFsAAA/M4w2md1uml1EAQDmOA2ZDaP2MqTz588rOjra/XR4eHiXp6xYsUIbNmzottjTp0+bq5faR9U98sgjGj9+fIfOvpUrV7r//fWvf12NjY36xS9+QQcbAFjJipxxlwMAQEdWdI7RwQYA6DOio6M9Oti6s3TpUs2bN6/bY0aPHq3ExERdvnzZ4/nW1lZdv379tmun1dfXKycnR1FRUdqzZ48GDx7c7fHp6elat26dmpqauu0cBAAAAID+jA42ALCYYThNf1rjy/nx8fGKj4+/7XEZGRmqra1VVVWV0tLSJEkHDx6U0+lUenp6l+c5HA5lZ2crPDxcb731liIiIm77vU6ePKk777yTzjUAsJAVOeMqBwCAzrDJgffoYAMAqxmG+Wk3flwXZ9y4ccrJydGCBQu0bds2tbS0qKioSHPmzHHvIHrhwgXNnDlTO3bs0NSpU+VwOJSVlaUbN27o9ddfd2+6ILV37IWGhmrfvn26dOmSpk2bpoiICJWXl+vnP/+5li1b5rf3AgBByYqccZUDAEAn+CDHe3SwAUAQ2rlzp4qKijRz5kyFhIQoLy9PmzZtcr/e0tKi6upq3bhxQ5J04sQJ9w6jY8eO9Sjr7NmzGjVqlAYPHqzNmzdr8eLFMgxDY8eO1S9/+UstWLCg994YAAAAAAQAHWwAYDXDgsWn/TyqIC4uTqWlpV2+PmrUKBm31GHGjBkeX3cmJydHOTk5ltURANAFK3LGXQ4AAB0xRdR7dLABgNWcTslmMkyCbDg1AMALVuSMRNYAALpkGG0y+2FOsE0RDQl0BQAAAAAAAID+jBFsAGC1fjBFFADQjzFFFADgd4ZkeopncOUMHWwAYDHD6ZRhcupOsA2nBgD0nBU5I5E1AICutWeEzWQZwdXBxhRRAAAAAAAAwARGsAGA1ZgiCgDwJ6aIAgD8rH0HUJMj2JgiCgAwxWlINjrYAAB+YkXOSGQNAKAb5jvYgm0NNqaIAgAAAAAAACYwgg0ArGZYsOMOowoAAF2xImfc5QAA0AkLNjkItpyhgw0ALGY4DRkmp+4E2447AICesyJnJLIGANA11mDzHlNEAQAAAFjq+vXrys/PV3R0tGJjYzV//nw1NDR0e86PfvQjjRkzRpGRkYqPj9djjz2mjz76qJdqDACAOXSwAYDVDKc1DwAAOmNVzvgxa/Lz8/XPf/5T5eXl2r9/vw4fPqyCgoJuz0lLS1NJSYlOnz6tt99+W4ZhKCsrS21tbX6rJwCgK06LHsGDKaIAYDGmiAIA/KmvTxE9ffq0ysrK9P7772vy5MmSpFdeeUW5ubnauHGjkpKSOj3v1g64UaNGaf369Zo4caL++9//asyYMX6pKwCgK4YFm4AG1z0NI9gAAACAIOZwODweTU1Npso7evSoYmNj3Z1rkpSZmamQkBBVVlb2qIzGxkaVlJQoJSVFycnJpuoDAEBvoIMNACzWajSp1WnyYZi7uQEADFyW5MwtWZOcnKyYmBj3o7i42FT97Ha7EhISPJ4bNGiQ4uLiZLfbuz13y5YtGjJkiIYMGaI///nPKi8vV1hYmKn6AAB8YciQ09Qj2EawMUUUACwSFhamxMREvWv/kyXlJSYmclMBAHCzOmek9qz54IMPFBER4X4uPDy802NXrFihDRs2dFve6dOnTdUnPz9f3/3ud3Xx4kVt3LhR3//+93XkyBGP+gEA/MeVNbf7QKSngumexmaw0A8AWObmzZtqbm62pKywsDBuKAAAHqzMGcm7rLly5YquXbvW7TGjR4/W66+/rqVLl+qzzz5zP9/a2qqIiAjt3r1bjz/+eI++X3Nzs+688079+te/1ty5c3t0DgDAPO5pfMMINgCwUERERNAECACg9wUyZ+Lj4xUfH3/b4zIyMlRbW6uqqiqlpaVJkg4ePCin06n09PQefz/DMGQYhuk14QAA3uGexjeswQYAAADAMuPGjVNOTo4WLFig48eP68iRIyoqKtKcOXPcO4heuHBBqampOn78uCTpP//5j4qLi1VVVaVz587pvffe05NPPqnIyEjl5uYG8u0AANAjdLABAAAAsNTOnTuVmpqqmTNnKjc3V9OnT9err77qfr2lpUXV1dW6ceOGpPbREn/729+Um5ursWPHavbs2YqKitJ7773XYcMEAAD6ItZgAwAAAAAAAExgBBsAAAAAAABgAh1sAAAAAAAAgAl0sAEAAAAAAAAm0MEGAAAAAAAAmEAHGwAAAAAAAGACHWwAAAAAAACACXSwAQAAAAAAACbQwQYAAAAAAACYQAcbAAAAAAAAYAIdbAAAAAAAAIAJdLABAAAAAAAAJvwfONu0CvfqKFsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oE2qXd363h7I"
      },
      "execution_count": 79,
      "outputs": []
    }
  ]
}